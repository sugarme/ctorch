// THIS FILE IS AUTOMATICALLY GENERATED, DO NOT EDIT BY HAND!

tensor atg___and__(tensor self, scalar other);
tensor atg___and__tensor_(tensor self, tensor other);
tensor atg___iand__(tensor self, scalar other);
tensor atg___iand__tensor_(tensor self, tensor other);
tensor atg___ilshift__(tensor self, scalar other);
tensor atg___ilshift__tensor_(tensor self, tensor other);
tensor atg___ior__(tensor self, scalar other);
tensor atg___ior__tensor_(tensor self, tensor other);
tensor atg___irshift__(tensor self, scalar other);
tensor atg___irshift__tensor_(tensor self, tensor other);
tensor atg___ixor__(tensor self, scalar other);
tensor atg___ixor__tensor_(tensor self, tensor other);
tensor atg___lshift__(tensor self, scalar other);
tensor atg___lshift__scalar_out_(tensor out, tensor self, scalar other);
tensor atg___lshift__tensor_(tensor self, tensor other);
tensor atg___lshift__tensor_out_(tensor out, tensor self, tensor other);
tensor atg___or__(tensor self, scalar other);
tensor atg___or__tensor_(tensor self, tensor other);
tensor atg___rshift__(tensor self, scalar other);
tensor atg___rshift__scalar_out_(tensor out, tensor self, scalar other);
tensor atg___rshift__tensor_(tensor self, tensor other);
tensor atg___rshift__tensor_out_(tensor out, tensor self, tensor other);
tensor atg___xor__(tensor self, scalar other);
tensor atg___xor__tensor_(tensor self, tensor other);
tensor atg__adaptive_avg_pool2d(tensor self, int64_t *output_size_data, int output_size_len);
tensor atg__adaptive_avg_pool2d_backward(tensor grad_output, tensor self);
tensor atg__adaptive_avg_pool2d_backward_out(tensor out, tensor grad_output, tensor self);
tensor atg__adaptive_avg_pool2d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len);
tensor atg__adaptive_avg_pool3d(tensor self, int64_t *output_size_data, int output_size_len);
tensor atg__adaptive_avg_pool3d_backward(tensor grad_output, tensor self);
tensor atg__adaptive_avg_pool3d_backward_out(tensor out, tensor grad_output, tensor self);
tensor atg__adaptive_avg_pool3d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len);
tensor atg__add_batch_dim(tensor self, int64_t batch_dim, int64_t level);
tensor atg__add_relu(tensor self, tensor other);
tensor atg__add_relu_(tensor self, tensor other);
tensor atg__add_relu_out(tensor out, tensor self, tensor other);
tensor atg__add_relu_scalar(tensor self, scalar other);
tensor atg__add_relu_scalar_(tensor self, scalar other);
tensor atg__add_relu_scalar_out(tensor out, tensor self, scalar other);
tensor atg__addmm_activation(tensor self, tensor mat1, tensor mat2, int use_gelu);
tensor atg__addmm_activation_out(tensor out, tensor self, tensor mat1, tensor mat2, int use_gelu);
tensor *atg__aminmax(tensor self);
tensor *atg__aminmax_dim(tensor self, int64_t dim, int keepdim);
tensor *atg__aminmax_dim_out(tensor out0, tensor out1, tensor self, int64_t dim, int keepdim);
tensor *atg__aminmax_out(tensor out0, tensor out1, tensor self);
tensor *atg__amp_update_scale(tensor self, tensor growth_tracker, tensor found_inf, double scale_growth_factor, double scale_backoff_factor, int64_t growth_interval);
tensor atg__amp_update_scale_(tensor self, tensor growth_tracker, tensor found_inf, double scale_growth_factor, double scale_backoff_factor, int64_t growth_interval);
tensor atg__amp_update_scale_out(tensor out, tensor self, tensor growth_tracker, tensor found_inf, double scale_growth_factor, double scale_backoff_factor, int64_t growth_interval);
tensor atg__autocast_to_full_precision(tensor self, int cuda_enabled, int cpu_enabled);
tensor atg__autocast_to_reduced_precision(tensor self, int cuda_enabled, int cpu_enabled, int cuda_dtype, int cpu_dtype);
tensor atg__cast_byte(tensor self, int non_blocking);
tensor atg__cast_char(tensor self, int non_blocking);
tensor atg__cast_double(tensor self, int non_blocking);
tensor atg__cast_float(tensor self, int non_blocking);
tensor atg__cast_half(tensor self, int non_blocking);
tensor atg__cast_int(tensor self, int non_blocking);
tensor atg__cast_long(tensor self, int non_blocking);
tensor atg__cast_short(tensor self, int non_blocking);
tensor atg__cdist_backward(tensor grad, tensor x1, tensor x2, double p, tensor cdist);
tensor atg__cdist_backward_out(tensor out, tensor grad, tensor x1, tensor x2, double p, tensor cdist);
tensor atg__cholesky_solve_helper(tensor self, tensor A, int upper);
tensor atg__cholesky_solve_helper_out(tensor out, tensor self, tensor A, int upper);
tensor atg__coalesce(tensor self);
tensor atg__coalesce_out(tensor out, tensor self);
tensor atg__coalesced(tensor self, int coalesced);
tensor atg__coalesced_(tensor self, int coalesced);
tensor atg__coalesced_out(tensor out, tensor self, int coalesced);
tensor atg__compute_linear_combination(tensor input, tensor coefficients);
tensor atg__compute_linear_combination_out(tensor out, tensor input, tensor coefficients);
tensor atg__conj(tensor self);
tensor atg__conj_copy(tensor self);
tensor atg__conj_copy_out(tensor out, tensor self);
tensor atg__conj_physical(tensor self);
tensor atg__conj_physical_out(tensor out, tensor self);
tensor atg__conv_depthwise2d(tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len);
tensor atg__conv_depthwise2d_out(tensor out, tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len);
tensor atg__convert_indices_from_coo_to_csr(tensor self, int64_t size, int out_int32);
tensor atg__convert_indices_from_coo_to_csr_out(tensor out, tensor self, int64_t size, int out_int32);
tensor atg__convert_indices_from_csr_to_coo(tensor crow_indices, tensor col_indices, int out_int32, int transpose);
tensor atg__convert_indices_from_csr_to_coo_out(tensor out, tensor crow_indices, tensor col_indices, int out_int32, int transpose);
tensor atg__convolution(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int transposed, int64_t *output_padding_data, int output_padding_len, int64_t groups, int benchmark, int deterministic, int cudnn_enabled, int allow_tf32);
tensor atg__convolution_deprecated(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int transposed, int64_t *output_padding_data, int output_padding_len, int64_t groups, int benchmark, int deterministic, int cudnn_enabled);
tensor atg__convolution_mode(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, char* padding_ptr, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg__convolution_out(tensor out, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int transposed, int64_t *output_padding_data, int output_padding_len, int64_t groups, int benchmark, int deterministic, int cudnn_enabled, int allow_tf32);
tensor atg__copy_from(tensor self, tensor dst, int non_blocking);
tensor atg__copy_from_and_resize(tensor self, tensor dst);
tensor atg__copy_from_and_resize_out(tensor out, tensor self, tensor dst);
tensor atg__copy_from_out(tensor out, tensor self, tensor dst, int non_blocking);
tensor atg__cslt_compress(tensor input);
tensor atg__cslt_sparse_mm(tensor compressed_A, tensor dense_B, tensor bias, int transpose_result);
tensor *atg__ctc_loss(tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, int64_t blank, int zero_infinity);
tensor atg__ctc_loss_backward(tensor grad, tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, tensor neg_log_likelihood, tensor log_alpha, int64_t blank, int zero_infinity);
tensor atg__ctc_loss_backward_out(tensor out, tensor grad, tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, tensor neg_log_likelihood, tensor log_alpha, int64_t blank, int zero_infinity);
tensor atg__ctc_loss_backward_tensor(tensor grad, tensor log_probs, tensor targets, tensor input_lengths, tensor target_lengths, tensor neg_log_likelihood, tensor log_alpha, int64_t blank, int zero_infinity);
tensor *atg__ctc_loss_out(tensor out0, tensor out1, tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, int64_t blank, int zero_infinity);
tensor *atg__ctc_loss_tensor(tensor log_probs, tensor targets, tensor input_lengths, tensor target_lengths, int64_t blank, int zero_infinity);
tensor *atg__ctc_loss_tensor_out(tensor out0, tensor out1, tensor log_probs, tensor targets, tensor input_lengths, tensor target_lengths, int64_t blank, int zero_infinity);
tensor *atg__cudnn_ctc_loss(tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, int64_t blank, int deterministic, int zero_infinity);
tensor *atg__cudnn_ctc_loss_out(tensor out0, tensor out1, tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, int64_t blank, int deterministic, int zero_infinity);
tensor *atg__cudnn_ctc_loss_tensor(tensor log_probs, tensor targets, tensor input_lengths, tensor target_lengths, int64_t blank, int deterministic, int zero_infinity);
tensor atg__cudnn_init_dropout_state(double dropout, int train, int64_t dropout_seed, int options_kind, int options_device);
tensor atg__cudnn_init_dropout_state_out(tensor out, double dropout, int train, int64_t dropout_seed);
tensor *atg__cudnn_rnn(tensor input, tensor *weight_data, int weight_len, int64_t weight_stride0, tensor weight_buf, tensor hx, tensor cx, int64_t mode, int64_t hidden_size, int64_t proj_size, int64_t num_layers, int batch_first, double dropout, int train, int bidirectional, int64_t *batch_sizes_data, int batch_sizes_len, tensor dropout_state);
tensor atg__cudnn_rnn_flatten_weight(tensor *weight_arr_data, int weight_arr_len, int64_t weight_stride0, int64_t input_size, int64_t mode, int64_t hidden_size, int64_t proj_size, int64_t num_layers, int batch_first, int bidirectional);
tensor atg__cudnn_rnn_flatten_weight_out(tensor out, tensor *weight_arr_data, int weight_arr_len, int64_t weight_stride0, int64_t input_size, int64_t mode, int64_t hidden_size, int64_t proj_size, int64_t num_layers, int batch_first, int bidirectional);
tensor *atg__cudnn_rnn_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor out4, tensor input, tensor *weight_data, int weight_len, int64_t weight_stride0, tensor weight_buf, tensor hx, tensor cx, int64_t mode, int64_t hidden_size, int64_t proj_size, int64_t num_layers, int batch_first, double dropout, int train, int bidirectional, int64_t *batch_sizes_data, int batch_sizes_len, tensor dropout_state);
int64_t atg__debug_has_internal_overlap(tensor self);
tensor atg__dim_arange(tensor like, int64_t dim);
int64_t atg__dimi(tensor self);
int64_t atg__dimv(tensor self);
tensor atg__dirichlet_grad(tensor x, tensor alpha, tensor total);
tensor atg__dirichlet_grad_out(tensor out, tensor x, tensor alpha, tensor total);
tensor *atg__efficient_attention_backward(tensor grad_out_, tensor query, tensor key, tensor value, tensor bias, tensor out, tensor cu_seqlens_q, tensor cu_seqlens_k, int64_t max_seqlen_k, int64_t max_seqlen_q, tensor logsumexp, double dropout_p, tensor philox_seed, tensor philox_offset, int64_t custom_mask_type, int bias_requires_grad, double scale_v, uint8_t scale_null, int64_t num_splits_key_v, uint8_t num_splits_key_null);
tensor atg__efficientzerotensor(int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg__efficientzerotensor_out(tensor out, int64_t *size_data, int size_len);
tensor *atg__embedding_bag(tensor weight, tensor indices, tensor offsets, int scale_grad_by_freq, int64_t mode, int sparse, tensor per_sample_weights, int include_last_offset, int64_t padding_idx);
tensor atg__embedding_bag_backward(tensor grad, tensor indices, tensor offsets, tensor offset2bag, tensor bag_size, tensor maximum_indices, int64_t num_weights, int scale_grad_by_freq, int64_t mode, int sparse, tensor per_sample_weights, int64_t padding_idx);
tensor atg__embedding_bag_dense_backward(tensor grad, tensor indices, tensor offset2bag, tensor bag_size, tensor maximum_indices, int64_t num_weights, int scale_grad_by_freq, int64_t mode, tensor per_sample_weights, int64_t padding_idx);
tensor atg__embedding_bag_dense_backward_out(tensor out, tensor grad, tensor indices, tensor offset2bag, tensor bag_size, tensor maximum_indices, int64_t num_weights, int scale_grad_by_freq, int64_t mode, tensor per_sample_weights, int64_t padding_idx);
tensor *atg__embedding_bag_forward_only(tensor weight, tensor indices, tensor offsets, int scale_grad_by_freq, int64_t mode, int sparse, tensor per_sample_weights, int include_last_offset, int64_t padding_idx);
tensor *atg__embedding_bag_forward_only_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor weight, tensor indices, tensor offsets, int scale_grad_by_freq, int64_t mode, int sparse, tensor per_sample_weights, int include_last_offset, int64_t padding_idx);
tensor *atg__embedding_bag_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor weight, tensor indices, tensor offsets, int scale_grad_by_freq, int64_t mode, int sparse, tensor per_sample_weights, int include_last_offset, int64_t padding_idx);
tensor atg__embedding_bag_per_sample_weights_backward(tensor grad, tensor weight, tensor indices, tensor offsets, tensor offset2bag, int64_t mode, int64_t padding_idx);
tensor atg__embedding_bag_per_sample_weights_backward_out(tensor out, tensor grad, tensor weight, tensor indices, tensor offsets, tensor offset2bag, int64_t mode, int64_t padding_idx);
tensor atg__embedding_bag_sparse_backward(tensor grad, tensor indices, tensor offsets, tensor offset2bag, tensor bag_size, int64_t num_weights, int scale_grad_by_freq, int64_t mode, tensor per_sample_weights, int64_t padding_idx);
tensor atg__empty_affine_quantized(int64_t *size_data, int size_len, int options_kind, int options_device, double scale, int64_t zero_point);
tensor atg__empty_affine_quantized_out(tensor out, int64_t *size_data, int size_len, double scale, int64_t zero_point);
tensor atg__empty_per_channel_affine_quantized(int64_t *size_data, int size_len, tensor scales, tensor zero_points, int64_t axis, int options_kind, int options_device);
tensor atg__empty_per_channel_affine_quantized_out(tensor out, int64_t *size_data, int size_len, tensor scales, tensor zero_points, int64_t axis);
tensor atg__euclidean_dist(tensor x1, tensor x2);
tensor atg__euclidean_dist_out(tensor out, tensor x1, tensor x2);
tensor atg__fake_quantize_learnable_per_channel_affine(tensor self, tensor scale, tensor zero_point, int64_t axis, int64_t quant_min, int64_t quant_max, double grad_factor);
tensor *atg__fake_quantize_learnable_per_channel_affine_backward(tensor grad, tensor self, tensor scale, tensor zero_point, int64_t axis, int64_t quant_min, int64_t quant_max, double grad_factor);
tensor atg__fake_quantize_learnable_per_channel_affine_out(tensor out, tensor self, tensor scale, tensor zero_point, int64_t axis, int64_t quant_min, int64_t quant_max, double grad_factor);
tensor atg__fake_quantize_learnable_per_tensor_affine(tensor self, tensor scale, tensor zero_point, int64_t quant_min, int64_t quant_max, double grad_factor);
tensor *atg__fake_quantize_learnable_per_tensor_affine_backward(tensor grad, tensor self, tensor scale, tensor zero_point, int64_t quant_min, int64_t quant_max, double grad_factor);
tensor atg__fake_quantize_learnable_per_tensor_affine_out(tensor out, tensor self, tensor scale, tensor zero_point, int64_t quant_min, int64_t quant_max, double grad_factor);
tensor *atg__fake_quantize_per_tensor_affine_cachemask_tensor_qparams(tensor self, tensor scale, tensor zero_point, tensor fake_quant_enabled, int64_t quant_min, int64_t quant_max);
tensor *atg__fake_quantize_per_tensor_affine_cachemask_tensor_qparams_out(tensor out0, tensor out1, tensor self, tensor scale, tensor zero_point, tensor fake_quant_enabled, int64_t quant_min, int64_t quant_max);
tensor atg__fft_c2c(tensor self, int64_t *dim_data, int dim_len, int64_t normalization, int forward);
tensor atg__fft_c2c_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int64_t normalization, int forward);
tensor atg__fft_c2r(tensor self, int64_t *dim_data, int dim_len, int64_t normalization, int64_t last_dim_size);
tensor atg__fft_c2r_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int64_t normalization, int64_t last_dim_size);
tensor atg__fft_r2c(tensor self, int64_t *dim_data, int dim_len, int64_t normalization, int onesided);
tensor atg__fft_r2c_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int64_t normalization, int onesided);
tensor atg__fill_mem_eff_dropout_mask_(tensor self, double dropout_p, int64_t seed, int64_t offset);
tensor *atg__flash_attention_backward(tensor grad_out, tensor query, tensor key, tensor value, tensor out, tensor logsumexp, tensor cum_seq_q, tensor cum_seq_k, int64_t max_q, int64_t max_k, double dropout_p, int is_causal, tensor philox_seed, tensor philox_offset, double scale_v, uint8_t scale_null);
tensor atg__foobar(tensor self, int arg1, int arg2, int arg3);
tensor atg__foobar_out(tensor out, tensor self, int arg1, int arg2, int arg3);
tensor atg__functional_assert_async(tensor self, char* assert_msg_ptr, int assert_msg_len, tensor dep_token);
tensor atg__functional_sym_constrain_range(scalar size, int64_t min_v, uint8_t min_null, int64_t max_v, uint8_t max_null, tensor dep_token);
tensor atg__functional_sym_constrain_range_for_size(scalar size, int64_t min_v, uint8_t min_null, int64_t max_v, uint8_t max_null, tensor dep_token);
tensor *atg__fused_dropout(tensor self, double p);
tensor *atg__fused_dropout_out(tensor out0, tensor out1, tensor self, double p);
tensor *atg__fused_moving_avg_obs_fq_helper(tensor self, tensor observer_on, tensor fake_quant_on, tensor running_min, tensor running_max, tensor scale, tensor zero_point, double averaging_const, int64_t quant_min, int64_t quant_max, int64_t ch_axis, int per_row_fake_quant, int symmetric_quant);
tensor *atg__fused_moving_avg_obs_fq_helper_functional(tensor self, tensor observer_on, tensor fake_quant_on, tensor running_min, tensor running_max, tensor scale, tensor zero_point, double averaging_const, int64_t quant_min, int64_t quant_max, int64_t ch_axis, int per_row_fake_quant, int symmetric_quant);
tensor *atg__fused_moving_avg_obs_fq_helper_out(tensor out0, tensor out1, tensor self, tensor observer_on, tensor fake_quant_on, tensor running_min, tensor running_max, tensor scale, tensor zero_point, double averaging_const, int64_t quant_min, int64_t quant_max, int64_t ch_axis, int per_row_fake_quant, int symmetric_quant);
int64_t atg__fused_sdp_choice(tensor query, tensor key, tensor value, tensor attn_mask, double dropout_p, int is_causal, double scale_v, uint8_t scale_null);
tensor atg__fw_primal(tensor self, int64_t level);
tensor atg__fw_primal_copy(tensor self, int64_t level);
tensor atg__fw_primal_copy_out(tensor out, tensor self, int64_t level);
tensor atg__gather_sparse_backward(tensor self, int64_t dim, tensor index, tensor grad);
tensor atg__grid_sampler_2d_cpu_fallback(tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode, int align_corners);
tensor *atg__grid_sampler_2d_cpu_fallback_backward(tensor grad_output, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode, int align_corners);
tensor atg__grid_sampler_2d_cpu_fallback_out(tensor out, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode, int align_corners);
int atg__has_compatible_shallow_copy_type(tensor self, tensor from);
int atg__has_same_storage_numel(tensor self, tensor other);
tensor atg__histogramdd_from_bin_cts(tensor out, tensor self, int64_t *bins_data, int bins_len, double *range_data, int range_len, tensor weight, int density);
tensor atg__histogramdd_from_bin_tensors(tensor self, tensor *bins_data, int bins_len, tensor weight, int density);
tensor atg__histogramdd_from_bin_tensors_out(tensor out, tensor self, tensor *bins_data, int bins_len, tensor weight, int density);
tensor atg__index_put_impl(tensor self, tensor *indices_data, int indices_len, tensor values, int accumulate, int unsafe);
tensor atg__index_put_impl_(tensor self, tensor *indices_data, int indices_len, tensor values, int accumulate, int unsafe);
tensor atg__index_put_impl_out(tensor out, tensor self, tensor *indices_data, int indices_len, tensor values, int accumulate, int unsafe);
tensor atg__indices(tensor self);
tensor atg__indices_copy(tensor self);
tensor atg__indices_copy_out(tensor out, tensor self);
tensor atg__int_mm(tensor self, tensor mat2);
tensor atg__int_mm_out(tensor out, tensor self, tensor mat2);
tensor atg__is_all_true(tensor self);
tensor atg__is_any_true(tensor self);
int atg__is_zerotensor(tensor self);
tensor *atg__linalg_det(tensor A);
tensor *atg__linalg_det_result(tensor result, tensor LU, tensor pivots, tensor A);
tensor *atg__linalg_eigh(tensor A, char* UPLO_ptr, int UPLO_len, int compute_v);
tensor *atg__linalg_eigh_eigenvalues(tensor eigenvalues, tensor eigenvectors, tensor A, char* UPLO_ptr, int UPLO_len, int compute_v);
tensor *atg__linalg_slogdet(tensor A);
tensor *atg__linalg_slogdet_sign(tensor sign, tensor logabsdet, tensor LU, tensor pivots, tensor A);
tensor *atg__linalg_solve_ex(tensor A, tensor B, int left, int check_errors);
tensor *atg__linalg_solve_ex_result(tensor result, tensor LU, tensor pivots, tensor info, tensor A, tensor B, int left, int check_errors);
tensor *atg__linalg_svd(tensor A, int full_matrices, int compute_uv, char* driver_ptr, int driver_len);
tensor *atg__linalg_svd_u(tensor U, tensor S, tensor Vh, tensor A, int full_matrices, int compute_uv, char* driver_ptr, int driver_len);
tensor atg__log_softmax(tensor self, int64_t dim, int half_to_float);
tensor atg__log_softmax_backward_data(tensor grad_output, tensor output, int64_t dim, int input_dtype);
tensor atg__log_softmax_backward_data_out(tensor out, tensor grad_output, tensor output, int64_t dim, int input_dtype);
tensor atg__log_softmax_out(tensor out, tensor self, int64_t dim, int half_to_float);
tensor atg__logcumsumexp(tensor self, int64_t dim);
tensor atg__logcumsumexp_out(tensor out, tensor self, int64_t dim);
tensor *atg__lstm_mps(tensor input, tensor *hx_data, int hx_len, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
tensor *atg__lstm_mps_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor out4, tensor out5, tensor input, tensor *hx_data, int hx_len, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
tensor *atg__lu_with_info(tensor self, int pivot, int check_errors);
tensor atg__make_dep_token(int options_kind, int options_device);
tensor atg__make_dual(tensor primal, tensor tangent, int64_t level);
tensor atg__make_dual_copy(tensor primal, tensor tangent, int64_t level);
tensor atg__make_dual_copy_out(tensor out, tensor primal, tensor tangent, int64_t level);
tensor atg__make_per_channel_quantized_tensor(tensor self, tensor scale, tensor zero_point, int64_t axis);
tensor atg__make_per_channel_quantized_tensor_out(tensor out, tensor self, tensor scale, tensor zero_point, int64_t axis);
tensor atg__make_per_tensor_quantized_tensor(tensor self, double scale, int64_t zero_point);
tensor atg__make_per_tensor_quantized_tensor_out(tensor out, tensor self, double scale, int64_t zero_point);
tensor atg__masked_scale(tensor self, tensor mask, double scale);
tensor atg__masked_scale_out(tensor out, tensor self, tensor mask, double scale);
tensor atg__masked_softmax(tensor self, tensor mask, int64_t dim_v, uint8_t dim_null, int64_t mask_type_v, uint8_t mask_type_null);
tensor atg__masked_softmax_backward(tensor grad_output, tensor output, tensor mask, int64_t dim_v, uint8_t dim_null);
tensor atg__masked_softmax_backward_out(tensor out, tensor grad_output, tensor output, tensor mask, int64_t dim_v, uint8_t dim_null);
tensor atg__masked_softmax_out(tensor out, tensor self, tensor mask, int64_t dim_v, uint8_t dim_null, int64_t mask_type_v, uint8_t mask_type_null);
tensor atg__mkldnn_reshape(tensor self, int64_t *shape_data, int shape_len);
tensor atg__mkldnn_reshape_out(tensor out, tensor self, int64_t *shape_data, int shape_len);
tensor atg__mkldnn_transpose(tensor self, int64_t dim0, int64_t dim1);
tensor atg__mkldnn_transpose_(tensor self, int64_t dim0, int64_t dim1);
tensor atg__mkldnn_transpose_out(tensor out, tensor self, int64_t dim0, int64_t dim1);
tensor atg__mps_convolution(tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg__mps_convolution_out(tensor out, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg__mps_convolution_transpose(tensor self, tensor weight, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg__mps_convolution_transpose_out(tensor out, tensor self, tensor weight, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor *atg__native_batch_norm_legit(tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double momentum, double eps);
tensor *atg__native_batch_norm_legit_functional(tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double momentum, double eps);
tensor *atg__native_batch_norm_legit_no_stats(tensor input, tensor weight, tensor bias, int training, double momentum, double eps);
tensor *atg__native_batch_norm_legit_no_stats_out(tensor out, tensor save_mean, tensor save_invstd, tensor input, tensor weight, tensor bias, int training, double momentum, double eps);
tensor *atg__native_batch_norm_legit_no_training(tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, double momentum, double eps);
tensor *atg__native_batch_norm_legit_no_training_out(tensor out0, tensor out1, tensor out2, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, double momentum, double eps);
tensor *atg__native_batch_norm_legit_out(tensor out, tensor save_mean, tensor save_invstd, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double momentum, double eps);
tensor *atg__native_multi_head_attention(tensor query, tensor key, tensor value, int64_t embed_dim, int64_t num_head, tensor qkv_weight, tensor qkv_bias, tensor proj_weight, tensor proj_bias, tensor mask, int need_weights, int average_attn_weights, int64_t mask_type_v, uint8_t mask_type_null);
tensor *atg__native_multi_head_attention_out(tensor out0, tensor out1, tensor query, tensor key, tensor value, int64_t embed_dim, int64_t num_head, tensor qkv_weight, tensor qkv_bias, tensor proj_weight, tensor proj_bias, tensor mask, int need_weights, int average_attn_weights, int64_t mask_type_v, uint8_t mask_type_null);
tensor atg__neg_view(tensor self);
tensor atg__neg_view_copy(tensor self);
tensor atg__neg_view_copy_out(tensor out, tensor self);
tensor atg__nested_from_padded(tensor padded, tensor cpu_nested_shape_example, int fuse_transform_0213);
tensor atg__nested_from_padded_and_nested_example(tensor padded, tensor nt_example);
tensor atg__nested_from_padded_and_nested_example_out(tensor out, tensor padded, tensor nt_example);
tensor atg__nested_from_padded_out(tensor out, tensor padded, tensor cpu_nested_shape_example, int fuse_transform_0213);
tensor atg__nested_select_backward(tensor grad_output, tensor self, int64_t dim, int64_t index);
tensor atg__nested_sum_backward(tensor grad, tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg__nested_view_from_buffer(tensor self, tensor nested_size, tensor nested_strides, tensor offsets);
tensor atg__nested_view_from_buffer_copy(tensor self, tensor nested_size, tensor nested_strides, tensor offsets);
tensor atg__nested_view_from_buffer_copy_out(tensor out, tensor self, tensor nested_size, tensor nested_strides, tensor offsets);
tensor atg__new_zeros_with_same_feature_meta(tensor self, tensor other, int64_t self_num_batch_dims);
tensor atg__new_zeros_with_same_feature_meta_out(tensor out, tensor self, tensor other, int64_t self_num_batch_dims);
int atg__nnpack_available();
tensor atg__nnpack_spatial_convolution(tensor input, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len);
tensor atg__nnpack_spatial_convolution_out(tensor out, tensor input, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len);
int64_t atg__nnz(tensor self);
tensor *atg__pack_padded_sequence(tensor input, tensor lengths, int batch_first);
tensor atg__pack_padded_sequence_backward(tensor grad, int64_t *input_size_data, int input_size_len, tensor batch_sizes, int batch_first);
tensor *atg__pack_padded_sequence_out(tensor out0, tensor out1, tensor input, tensor lengths, int batch_first);
tensor atg__pad_circular(tensor self, int64_t *pad_data, int pad_len);
tensor atg__pad_enum(tensor self, int64_t *pad_data, int pad_len, int64_t mode, double value_v, uint8_t value_null);
tensor *atg__pad_packed_sequence(tensor data, tensor batch_sizes, int batch_first, scalar padding_value, int64_t total_length);
tensor atg__pdist_backward(tensor grad, tensor self, double p, tensor pdist);
tensor atg__pdist_backward_out(tensor out, tensor grad, tensor self, double p, tensor pdist);
tensor atg__pin_memory(tensor self, int device);
tensor atg__pin_memory_out(tensor out, tensor self, int device);
tensor atg__prelu_kernel(tensor self, tensor weight);
tensor *atg__prelu_kernel_backward(tensor grad_output, tensor self, tensor weight);
void atg__propagate_xla_data(tensor input, tensor output);
tensor atg__remove_batch_dim(tensor self, int64_t level, int64_t batch_size, int64_t out_dim);
tensor atg__reshape_alias(tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len);
tensor atg__reshape_alias_copy(tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len);
tensor atg__reshape_alias_copy_out(tensor out, tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len);
tensor atg__reshape_copy(tensor self, int64_t *size_data, int size_len);
tensor atg__reshape_from_tensor(tensor self, tensor shape);
tensor atg__resize_output(tensor self, int64_t *size_data, int size_len, int device);
tensor atg__resize_output_(tensor self, int64_t *size_data, int size_len, int device);
tensor atg__resize_output_out(tensor out, tensor self, int64_t *size_data, int size_len, int device);
tensor *atg__rowwise_prune(tensor weight, tensor mask, int compressed_indices_dtype);
tensor atg__sample_dirichlet(tensor self);
tensor atg__sample_dirichlet_out(tensor out, tensor self);
tensor atg__saturate_weight_to_fp16(tensor weight);
tensor *atg__scaled_dot_product_attention_math(tensor query, tensor key, tensor value, tensor attn_mask, double dropout_p, int is_causal, tensor dropout_mask, double scale_v, uint8_t scale_null);
tensor *atg__scaled_dot_product_efficient_attention(tensor query, tensor key, tensor value, tensor attn_bias, int compute_log_sumexp, double dropout_p, int is_causal, double scale_v, uint8_t scale_null);
tensor *atg__scaled_dot_product_flash_attention_backward(tensor grad_out, tensor query, tensor key, tensor value, tensor out, tensor logsumexp, tensor cum_seq_q, tensor cum_seq_k, int64_t max_q, int64_t max_k, double dropout_p, int is_causal, tensor philox_seed, tensor philox_offset, double scale_v, uint8_t scale_null);
tensor *atg__scaled_mm(tensor self, tensor mat2, tensor bias, int out_dtype, tensor scale_a, tensor scale_b, tensor scale_result);
tensor *atg__scaled_mm_out(tensor out, tensor out_amax, tensor self, tensor mat2, tensor bias, int out_dtype, tensor scale_a, tensor scale_b, tensor scale_result);
tensor atg__scatter_reduce(tensor self, int64_t dim, tensor index, tensor src, char* reduce_ptr, int reduce_len, int include_self);
tensor atg__scatter_reduce_(tensor self, int64_t dim, tensor index, tensor src, char* reduce_ptr, int reduce_len, int include_self);
tensor atg__scatter_reduce_two_out(tensor out, tensor self, int64_t dim, tensor index, tensor src, char* reduce_ptr, int reduce_len, int include_self);
tensor atg__segment_reduce_backward(tensor grad, tensor output, tensor data, char* reduce_ptr, int reduce_len, tensor lengths, tensor offsets, int64_t axis, scalar initial);
tensor atg__segment_reduce_backward_out(tensor out, tensor grad, tensor output, tensor data, char* reduce_ptr, int reduce_len, tensor lengths, tensor offsets, int64_t axis, scalar initial);
tensor atg__shape_as_tensor(tensor self);
tensor *atg__slow_conv2d_backward(tensor grad_input, tensor grad_weight, tensor grad_bias, tensor grad_output, tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
tensor *atg__sobol_engine_draw(tensor quasi, int64_t n, tensor sobolstate, int64_t dimension, int64_t num_generated, int dtype);
tensor atg__sobol_engine_ff_(tensor self, int64_t n, tensor sobolstate, int64_t dimension, int64_t num_generated);
tensor atg__sobol_engine_initialize_state_(tensor self, int64_t dimension);
tensor atg__sobol_engine_scramble_(tensor self, tensor ltm, int64_t dimension);
tensor atg__softmax(tensor self, int64_t dim, int half_to_float);
tensor atg__softmax_backward_data(tensor grad_output, tensor output, int64_t dim, int input_dtype);
tensor atg__softmax_backward_data_out(tensor grad_input, tensor grad_output, tensor output, int64_t dim, int input_dtype);
tensor atg__softmax_out(tensor out, tensor self, int64_t dim, int half_to_float);
tensor atg__sparse_addmm(tensor self, tensor mat1, tensor mat2);
tensor atg__sparse_addmm_out(tensor out, tensor self, tensor mat1, tensor mat2);
tensor atg__sparse_broadcast_to(tensor self, int64_t *size_data, int size_len);
tensor atg__sparse_broadcast_to_copy(tensor self, int64_t *size_data, int size_len);
tensor atg__sparse_broadcast_to_copy_out(tensor out, tensor self, int64_t *size_data, int size_len);
tensor atg__sparse_bsc_tensor_unsafe(tensor ccol_indices, tensor row_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg__sparse_bsr_tensor_unsafe(tensor crow_indices, tensor col_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg__sparse_compressed_tensor_unsafe(tensor compressed_indices, tensor plain_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg__sparse_coo_tensor_unsafe(tensor indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device, int is_coalesced);
tensor atg__sparse_coo_tensor_with_dims(int64_t sparse_dim, int64_t dense_dim, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg__sparse_coo_tensor_with_dims_and_tensors(int64_t sparse_dim, int64_t dense_dim, int64_t *size_data, int size_len, tensor indices, tensor values, int options_kind, int options_device, int is_coalesced);
tensor atg__sparse_coo_tensor_with_dims_and_tensors_out(tensor out, int64_t sparse_dim, int64_t dense_dim, int64_t *size_data, int size_len, tensor indices, tensor values, int is_coalesced);
tensor atg__sparse_coo_tensor_with_dims_out(tensor out, int64_t sparse_dim, int64_t dense_dim, int64_t *size_data, int size_len);
tensor atg__sparse_csc_tensor_unsafe(tensor ccol_indices, tensor row_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg__sparse_csr_prod(tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg__sparse_csr_prod_dim_dtype_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg__sparse_csr_sum(tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg__sparse_csr_sum_dim_dtype_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg__sparse_csr_tensor_unsafe(tensor crow_indices, tensor col_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg__sparse_log_softmax(tensor self, int64_t dim, int half_to_float);
tensor atg__sparse_log_softmax_backward_data(tensor grad_output, tensor output, int64_t dim, tensor self);
tensor atg__sparse_log_softmax_backward_data_out(tensor out, tensor grad_output, tensor output, int64_t dim, tensor self);
tensor atg__sparse_log_softmax_int(tensor self, int64_t dim, int dtype);
tensor atg__sparse_log_softmax_out(tensor out, tensor self, int64_t dim, int half_to_float);
tensor atg__sparse_mask_projection(tensor self, tensor mask, int accumulate_matches);
tensor atg__sparse_mask_projection_out(tensor out, tensor self, tensor mask, int accumulate_matches);
tensor atg__sparse_mm(tensor sparse, tensor dense);
tensor atg__sparse_mm_reduce(tensor sparse, tensor dense, char* reduce_ptr, int reduce_len);
tensor *atg__sparse_mm_reduce_impl(tensor self, tensor other, char* reduce_ptr, int reduce_len);
tensor atg__sparse_semi_structured_linear(tensor input, tensor weight, tensor meta, tensor bias, char* activation_ptr, int activation_len);
tensor atg__sparse_softmax(tensor self, int64_t dim, int half_to_float);
tensor atg__sparse_softmax_backward_data(tensor grad_output, tensor output, int64_t dim, tensor self);
tensor atg__sparse_softmax_backward_data_out(tensor out, tensor grad_output, tensor output, int64_t dim, tensor self);
tensor atg__sparse_softmax_int(tensor self, int64_t dim, int dtype);
tensor atg__sparse_softmax_out(tensor out, tensor self, int64_t dim, int half_to_float);
tensor atg__sparse_sparse_matmul(tensor self, tensor other);
tensor atg__sparse_sparse_matmul_out(tensor out, tensor self, tensor other);
tensor atg__sparse_sum(tensor self);
tensor atg__sparse_sum_backward(tensor grad, tensor self, int64_t *dim_data, int dim_len);
tensor atg__sparse_sum_backward_out(tensor out, tensor grad, tensor self, int64_t *dim_data, int dim_len);
tensor atg__sparse_sum_dim(tensor self, int64_t *dim_data, int dim_len);
tensor atg__sparse_sum_dim_dtype(tensor self, int64_t *dim_data, int dim_len, int dtype);
tensor atg__sparse_sum_dim_out(tensor out, tensor self, int64_t *dim_data, int dim_len);
tensor atg__sparse_sum_dtype(tensor self, int dtype);
tensor atg__spdiags(tensor diagonals, tensor offsets, int64_t *shape_data, int shape_len, int8_t layout);
tensor atg__spdiags_out(tensor out, tensor diagonals, tensor offsets, int64_t *shape_data, int shape_len, int8_t layout);
tensor atg__stack(tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg__stack_out(tensor out, tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg__standard_gamma(tensor self);
tensor atg__standard_gamma_grad(tensor self, tensor output);
tensor atg__standard_gamma_grad_out(tensor out, tensor self, tensor output);
tensor atg__standard_gamma_out(tensor out, tensor self);
tensor atg__test_ambiguous_defaults(tensor dummy, int64_t a, int64_t b);
tensor atg__test_ambiguous_defaults_b(tensor dummy, int64_t a, char* b_ptr, int b_len);
tensor atg__test_autograd_multiple_dispatch(tensor self);
tensor atg__test_autograd_multiple_dispatch_fullcoverage_out(tensor out, tensor self);
tensor atg__test_autograd_multiple_dispatch_ntonly(tensor self, int b);
tensor atg__test_autograd_multiple_dispatch_view(tensor self);
tensor atg__test_autograd_multiple_dispatch_view_copy(tensor self);
tensor atg__test_autograd_multiple_dispatch_view_copy_out(tensor out, tensor self);
tensor atg__test_check_tensor(tensor self);
tensor atg__test_functorch_fallback(tensor self, tensor other);
tensor atg__test_functorch_fallback_out(tensor out, tensor self, tensor other);
tensor atg__test_optional_filled_intlist(tensor values, int64_t *addends_data, int addends_len);
tensor atg__test_optional_filled_intlist_out(tensor out, tensor values, int64_t *addends_data, int addends_len);
tensor atg__test_optional_floatlist(tensor values, double *addends_data, int addends_len);
tensor atg__test_optional_floatlist_out(tensor out, tensor values, double *addends_data, int addends_len);
tensor atg__test_optional_intlist(tensor values, int64_t *addends_data, int addends_len);
tensor atg__test_optional_intlist_out(tensor out, tensor values, int64_t *addends_data, int addends_len);
tensor atg__test_serialization_subcmul(tensor self, tensor other);
tensor atg__test_string_default(tensor dummy, char* a_ptr, int a_len, char* b_ptr, int b_len);
tensor atg__test_warn_in_autograd(tensor self);
tensor atg__test_warn_in_autograd_out(tensor out, tensor self);
tensor atg__to_copy(tensor self, int options_kind, int options_device, int non_blocking);
tensor atg__to_copy_out(tensor out, tensor self, int non_blocking);
tensor *atg__to_cpu(tensor *tensors_data, int tensors_len);
tensor atg__to_dense(tensor self, int dtype, int masked_grad);
tensor atg__to_dense_out(tensor out, tensor self, int dtype, int masked_grad);
tensor atg__to_sparse(tensor self, int8_t layout, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_bsc(tensor self, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_bsc_out(tensor out, tensor self, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_bsr(tensor self, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_bsr_out(tensor out, tensor self, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_csc(tensor self, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_csc_out(tensor out, tensor self, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_csr(tensor self, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_csr_out(tensor out, tensor self, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg__to_sparse_out(tensor out, tensor self, int8_t layout, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor *atg__to_sparse_semi_structured(tensor dense);
tensor atg__to_sparse_sparse_dim(tensor self, int64_t sparse_dim);
tensor atg__to_sparse_sparse_dim_out(tensor out, tensor self, int64_t sparse_dim);
tensor *atg__transform_bias_rescale_qkv(tensor qkv, tensor qkv_bias, int64_t num_heads);
tensor *atg__transform_bias_rescale_qkv_out(tensor out0, tensor out1, tensor out2, tensor qkv, tensor qkv_bias, int64_t num_heads);
tensor atg__transformer_encoder_layer_fwd(tensor src, int64_t embed_dim, int64_t num_heads, tensor qkv_weight, tensor qkv_bias, tensor proj_weight, tensor proj_bias, int use_gelu, int norm_first, double eps, tensor norm_weight_1, tensor norm_bias_1, tensor norm_weight_2, tensor norm_bias_2, tensor ffn_weight_1, tensor ffn_bias_1, tensor ffn_weight_2, tensor ffn_bias_2, tensor mask, int64_t mask_type_v, uint8_t mask_type_null);
tensor atg__transformer_encoder_layer_fwd_out(tensor out, tensor src, int64_t embed_dim, int64_t num_heads, tensor qkv_weight, tensor qkv_bias, tensor proj_weight, tensor proj_bias, int use_gelu, int norm_first, double eps, tensor norm_weight_1, tensor norm_bias_1, tensor norm_weight_2, tensor norm_bias_2, tensor ffn_weight_1, tensor ffn_bias_1, tensor ffn_weight_2, tensor ffn_bias_2, tensor mask, int64_t mask_type_v, uint8_t mask_type_null);
tensor atg__trilinear(tensor i1, tensor i2, tensor i3, int64_t *expand1_data, int expand1_len, int64_t *expand2_data, int expand2_len, int64_t *expand3_data, int expand3_len, int64_t *sumdim_data, int sumdim_len, int64_t unroll_dim);
tensor atg__trilinear_out(tensor out, tensor i1, tensor i2, tensor i3, int64_t *expand1_data, int expand1_len, int64_t *expand2_data, int expand2_len, int64_t *expand3_data, int expand3_len, int64_t *sumdim_data, int sumdim_len, int64_t unroll_dim);
tensor atg__triton_multi_head_attention(tensor query, tensor key, tensor value, int64_t embed_dim, int64_t num_head, tensor qkv_weight, tensor qkv_bias, tensor proj_weight, tensor proj_bias, tensor mask);
tensor atg__triton_multi_head_attention_out(tensor out, tensor query, tensor key, tensor value, int64_t embed_dim, int64_t num_head, tensor qkv_weight, tensor qkv_bias, tensor proj_weight, tensor proj_bias, tensor mask);
tensor atg__triton_scaled_dot_attention(tensor q, tensor k, tensor v, double dropout_p);
tensor atg__triton_scaled_dot_attention_out(tensor out, tensor q, tensor k, tensor v, double dropout_p);
tensor *atg__unique(tensor self, int sorted, int return_inverse);
tensor *atg__unique2(tensor self, int sorted, int return_inverse, int return_counts);
tensor *atg__unique2_out(tensor out0, tensor out1, tensor out2, tensor self, int sorted, int return_inverse, int return_counts);
tensor *atg__unique_out(tensor out0, tensor out1, tensor self, int sorted, int return_inverse);
tensor *atg__unpack_dual(tensor dual, int64_t level);
tensor atg__unsafe_index(tensor self, tensor *indices_data, int indices_len);
tensor atg__unsafe_index_put(tensor self, tensor *indices_data, int indices_len, tensor values, int accumulate);
tensor atg__unsafe_view(tensor self, int64_t *size_data, int size_len);
tensor atg__unsafe_view_out(tensor out, tensor self, int64_t *size_data, int size_len);
tensor atg__upsample_bicubic2d_aa(tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_bicubic2d_aa_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_bicubic2d_aa_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_bicubic2d_aa_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_bicubic2d_aa_vec(tensor input, int64_t *output_size_data, int output_size_len, int align_corners, double *scale_factors_data, int scale_factors_len);
tensor atg__upsample_bilinear2d_aa(tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_bilinear2d_aa_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_bilinear2d_aa_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_bilinear2d_aa_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_bilinear2d_aa_vec(tensor input, int64_t *output_size_data, int output_size_len, int align_corners, double *scale_factors_data, int scale_factors_len);
tensor atg__upsample_nearest_exact1d(tensor self, int64_t *output_size_data, int output_size_len, double scales_v, uint8_t scales_null);
tensor atg__upsample_nearest_exact1d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_v, uint8_t scales_null);
tensor atg__upsample_nearest_exact1d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_v, uint8_t scales_null);
tensor atg__upsample_nearest_exact1d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, double scales_v, uint8_t scales_null);
tensor atg__upsample_nearest_exact1d_vec(tensor input, int64_t *output_size_data, int output_size_len, double *scale_factors_data, int scale_factors_len);
tensor atg__upsample_nearest_exact2d(tensor self, int64_t *output_size_data, int output_size_len, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_nearest_exact2d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_nearest_exact2d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_nearest_exact2d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_nearest_exact2d_vec(tensor input, int64_t *output_size_data, int output_size_len, double *scale_factors_data, int scale_factors_len);
tensor atg__upsample_nearest_exact3d(tensor self, int64_t *output_size_data, int output_size_len, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_nearest_exact3d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_nearest_exact3d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_nearest_exact3d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg__upsample_nearest_exact3d_vec(tensor input, int64_t *output_size_data, int output_size_len, double *scale_factors_data, int scale_factors_len);
int atg__use_cudnn_ctc_loss(tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, int64_t blank);
int atg__use_cudnn_ctc_loss_tensor(tensor log_probs, tensor targets, tensor input_lengths, tensor target_lengths, int64_t blank);
int atg__use_cudnn_rnn_flatten_weight();
tensor atg__values(tensor self);
tensor atg__values_copy(tensor self);
tensor atg__values_copy_out(tensor out, tensor self);
int64_t atg__version(tensor self);
tensor atg__weight_norm(tensor v, tensor g, int64_t dim);
tensor *atg__weight_norm_differentiable_backward(tensor grad_w, tensor saved_v, tensor saved_g, tensor saved_norms, int64_t dim);
tensor *atg__weight_norm_interface(tensor v, tensor g, int64_t dim);
tensor *atg__weight_norm_interface_backward(tensor grad_w, tensor saved_v, tensor saved_g, tensor saved_norms, int64_t dim);
tensor *atg__weight_norm_interface_backward_out(tensor out0, tensor out1, tensor grad_w, tensor saved_v, tensor saved_g, tensor saved_norms, int64_t dim);
tensor *atg__weight_norm_interface_out(tensor out0, tensor out1, tensor v, tensor g, int64_t dim);
tensor atg_abs(tensor self);
tensor atg_abs_(tensor self);
tensor atg_abs_out(tensor out, tensor self);
tensor atg_absolute(tensor self);
tensor atg_absolute_(tensor self);
tensor atg_absolute_out(tensor out, tensor self);
tensor atg_acos(tensor self);
tensor atg_acos_(tensor self);
tensor atg_acos_out(tensor out, tensor self);
tensor atg_acosh(tensor self);
tensor atg_acosh_(tensor self);
tensor atg_acosh_out(tensor out, tensor self);
tensor atg_adaptive_avg_pool1d(tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_adaptive_avg_pool2d(tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_adaptive_avg_pool2d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_adaptive_avg_pool3d(tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_adaptive_avg_pool3d_backward(tensor grad_input, tensor grad_output, tensor self);
tensor atg_adaptive_avg_pool3d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len);
tensor *atg_adaptive_max_pool1d(tensor self, int64_t *output_size_data, int output_size_len);
tensor *atg_adaptive_max_pool2d(tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_adaptive_max_pool2d_backward(tensor grad_output, tensor self, tensor indices);
tensor atg_adaptive_max_pool2d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor indices);
tensor *atg_adaptive_max_pool2d_out(tensor out, tensor indices, tensor self, int64_t *output_size_data, int output_size_len);
tensor *atg_adaptive_max_pool3d(tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_adaptive_max_pool3d_backward(tensor grad_output, tensor self, tensor indices);
tensor atg_adaptive_max_pool3d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor indices);
tensor *atg_adaptive_max_pool3d_out(tensor out, tensor indices, tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_add(tensor self, tensor other);
tensor atg_add_(tensor self, tensor other);
tensor atg_add_out(tensor out, tensor self, tensor other);
tensor atg_add_scalar(tensor self, scalar other);
tensor atg_add_scalar_(tensor self, scalar other);
tensor atg_add_scalar_out(tensor out, tensor self, scalar other);
tensor atg_addbmm(tensor self, tensor batch1, tensor batch2);
tensor atg_addbmm_(tensor self, tensor batch1, tensor batch2);
tensor atg_addbmm_out(tensor out, tensor self, tensor batch1, tensor batch2);
tensor atg_addcdiv(tensor self, tensor tensor1, tensor tensor2);
tensor atg_addcdiv_(tensor self, tensor tensor1, tensor tensor2);
tensor atg_addcdiv_out(tensor out, tensor self, tensor tensor1, tensor tensor2);
tensor atg_addcmul(tensor self, tensor tensor1, tensor tensor2);
tensor atg_addcmul_(tensor self, tensor tensor1, tensor tensor2);
tensor atg_addcmul_out(tensor out, tensor self, tensor tensor1, tensor tensor2);
tensor atg_addmm(tensor self, tensor mat1, tensor mat2);
tensor atg_addmm_(tensor self, tensor mat1, tensor mat2);
tensor atg_addmm_out(tensor out, tensor self, tensor mat1, tensor mat2);
tensor atg_addmv(tensor self, tensor mat, tensor vec);
tensor atg_addmv_(tensor self, tensor mat, tensor vec);
tensor atg_addmv_out(tensor out, tensor self, tensor mat, tensor vec);
tensor atg_addr(tensor self, tensor vec1, tensor vec2);
tensor atg_addr_(tensor self, tensor vec1, tensor vec2);
tensor atg_addr_out(tensor out, tensor self, tensor vec1, tensor vec2);
tensor atg_adjoint(tensor self);
tensor atg_affine_grid_generator(tensor theta, int64_t *size_data, int size_len, int align_corners);
tensor atg_affine_grid_generator_backward(tensor grad, int64_t *size_data, int size_len, int align_corners);
tensor atg_affine_grid_generator_out(tensor out, tensor theta, int64_t *size_data, int size_len, int align_corners);
tensor atg_alias(tensor self);
tensor atg_alias_copy(tensor self);
tensor atg_alias_copy_out(tensor out, tensor self);
tensor atg_align_as(tensor self, tensor other);
tensor *atg_align_tensors(tensor *tensors_data, int tensors_len);
tensor atg_all(tensor self);
tensor atg_all_all_out(tensor out, tensor self);
tensor atg_all_dim(tensor self, int64_t dim, int keepdim);
tensor atg_all_out(tensor out, tensor self, int64_t dim, int keepdim);
int atg_allclose(tensor self, tensor other, double rtol, double atol, int equal_nan);
tensor atg_alpha_dropout(tensor input, double p, int train);
tensor atg_alpha_dropout_(tensor self, double p, int train);
tensor atg_amax(tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_amax_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_amin(tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_amin_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor *atg_aminmax(tensor self, int64_t dim_v, uint8_t dim_null, int keepdim);
tensor *atg_aminmax_out(tensor min, tensor max, tensor self, int64_t dim_v, uint8_t dim_null, int keepdim);
tensor atg_angle(tensor self);
tensor atg_angle_out(tensor out, tensor self);
tensor atg_any(tensor self);
tensor atg_any_all_out(tensor out, tensor self);
tensor atg_any_dim(tensor self, int64_t dim, int keepdim);
tensor atg_any_out(tensor out, tensor self, int64_t dim, int keepdim);
tensor atg_arange(scalar end, int options_kind, int options_device);
tensor atg_arange_start(scalar start, scalar end, int options_kind, int options_device);
tensor atg_arange_start_step(scalar start, scalar end, scalar step, int options_kind, int options_device);
tensor atg_arccos(tensor self);
tensor atg_arccos_(tensor self);
tensor atg_arccos_out(tensor out, tensor self);
tensor atg_arccosh(tensor self);
tensor atg_arccosh_(tensor self);
tensor atg_arccosh_out(tensor out, tensor self);
tensor atg_arcsin(tensor self);
tensor atg_arcsin_(tensor self);
tensor atg_arcsin_out(tensor out, tensor self);
tensor atg_arcsinh(tensor self);
tensor atg_arcsinh_(tensor self);
tensor atg_arcsinh_out(tensor out, tensor self);
tensor atg_arctan(tensor self);
tensor atg_arctan2(tensor self, tensor other);
tensor atg_arctan2_(tensor self, tensor other);
tensor atg_arctan2_out(tensor out, tensor self, tensor other);
tensor atg_arctan_(tensor self);
tensor atg_arctan_out(tensor out, tensor self);
tensor atg_arctanh(tensor self);
tensor atg_arctanh_(tensor self);
tensor atg_arctanh_out(tensor out, tensor self);
tensor atg_argmax(tensor self, int64_t dim_v, uint8_t dim_null, int keepdim);
tensor atg_argmax_out(tensor out, tensor self, int64_t dim_v, uint8_t dim_null, int keepdim);
tensor atg_argmin(tensor self, int64_t dim_v, uint8_t dim_null, int keepdim);
tensor atg_argmin_out(tensor out, tensor self, int64_t dim_v, uint8_t dim_null, int keepdim);
tensor atg_argsort(tensor self, int64_t dim, int descending);
tensor atg_argsort_stable(tensor self, int stable, int64_t dim, int descending);
tensor atg_argsort_stable_out(tensor out, tensor self, int stable, int64_t dim, int descending);
tensor atg_argwhere(tensor self);
tensor atg_as_strided(tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int64_t storage_offset_v, uint8_t storage_offset_null);
tensor atg_as_strided_(tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int64_t storage_offset_v, uint8_t storage_offset_null);
tensor atg_as_strided_copy(tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int64_t storage_offset_v, uint8_t storage_offset_null);
tensor atg_as_strided_copy_out(tensor out, tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int64_t storage_offset_v, uint8_t storage_offset_null);
tensor atg_as_strided_scatter(tensor self, tensor src, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int64_t storage_offset_v, uint8_t storage_offset_null);
tensor atg_as_strided_scatter_out(tensor out, tensor self, tensor src, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int64_t storage_offset_v, uint8_t storage_offset_null);
tensor atg_asin(tensor self);
tensor atg_asin_(tensor self);
tensor atg_asin_out(tensor out, tensor self);
tensor atg_asinh(tensor self);
tensor atg_asinh_(tensor self);
tensor atg_asinh_out(tensor out, tensor self);
tensor atg_atan(tensor self);
tensor atg_atan2(tensor self, tensor other);
tensor atg_atan2_(tensor self, tensor other);
tensor atg_atan2_out(tensor out, tensor self, tensor other);
tensor atg_atan_(tensor self);
tensor atg_atan_out(tensor out, tensor self);
tensor atg_atanh(tensor self);
tensor atg_atanh_(tensor self);
tensor atg_atanh_out(tensor out, tensor self);
tensor atg_atleast_1d(tensor self);
tensor *atg_atleast_1d_sequence(tensor *tensors_data, int tensors_len);
tensor atg_atleast_2d(tensor self);
tensor *atg_atleast_2d_sequence(tensor *tensors_data, int tensors_len);
tensor atg_atleast_3d(tensor self);
tensor *atg_atleast_3d_sequence(tensor *tensors_data, int tensors_len);
tensor atg_avg_pool1d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
tensor atg_avg_pool2d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad, int64_t divisor_override_v, uint8_t divisor_override_null);
tensor atg_avg_pool2d_backward(tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad, int64_t divisor_override_v, uint8_t divisor_override_null);
tensor atg_avg_pool2d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad, int64_t divisor_override_v, uint8_t divisor_override_null);
tensor atg_avg_pool2d_out(tensor out, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad, int64_t divisor_override_v, uint8_t divisor_override_null);
tensor atg_avg_pool3d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad, int64_t divisor_override_v, uint8_t divisor_override_null);
tensor atg_avg_pool3d_backward(tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad, int64_t divisor_override_v, uint8_t divisor_override_null);
tensor atg_avg_pool3d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad, int64_t divisor_override_v, uint8_t divisor_override_null);
tensor atg_avg_pool3d_out(tensor out, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad, int64_t divisor_override_v, uint8_t divisor_override_null);
tensor atg_baddbmm(tensor self, tensor batch1, tensor batch2, scalar beta, scalar alpha);
tensor atg_baddbmm_(tensor self, tensor batch1, tensor batch2);
tensor atg_baddbmm_out(tensor out, tensor self, tensor batch1, tensor batch2);
tensor atg_bartlett_window(int64_t window_length, int options_kind, int options_device);
tensor atg_bartlett_window_out(tensor out, int64_t window_length);
tensor atg_bartlett_window_periodic(int64_t window_length, int periodic, int options_kind, int options_device);
tensor atg_bartlett_window_periodic_out(tensor out, int64_t window_length, int periodic);
tensor atg_batch_norm(tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double momentum, double eps, int cudnn_enabled);
tensor atg_batch_norm_backward_elemt(tensor grad_out, tensor input, tensor mean, tensor invstd, tensor weight, tensor sum_dy, tensor sum_dy_xmu, tensor count);
tensor atg_batch_norm_backward_elemt_out(tensor out, tensor grad_out, tensor input, tensor mean, tensor invstd, tensor weight, tensor sum_dy, tensor sum_dy_xmu, tensor count);
tensor *atg_batch_norm_backward_reduce(tensor grad_out, tensor input, tensor mean, tensor invstd, tensor weight, int input_g, int weight_g, int bias_g);
tensor *atg_batch_norm_backward_reduce_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor grad_out, tensor input, tensor mean, tensor invstd, tensor weight, int input_g, int weight_g, int bias_g);
tensor atg_batch_norm_elemt(tensor input, tensor weight, tensor bias, tensor mean, tensor invstd, double eps);
tensor atg_batch_norm_elemt_out(tensor out, tensor input, tensor weight, tensor bias, tensor mean, tensor invstd, double eps);
tensor *atg_batch_norm_gather_stats(tensor input, tensor mean, tensor invstd, tensor running_mean, tensor running_var, double momentum, double eps, int64_t count);
tensor *atg_batch_norm_gather_stats_out(tensor out0, tensor out1, tensor input, tensor mean, tensor invstd, tensor running_mean, tensor running_var, double momentum, double eps, int64_t count);
tensor *atg_batch_norm_gather_stats_with_counts(tensor input, tensor mean, tensor invstd, tensor running_mean, tensor running_var, double momentum, double eps, tensor counts);
tensor *atg_batch_norm_gather_stats_with_counts_out(tensor out0, tensor out1, tensor input, tensor mean, tensor invstd, tensor running_mean, tensor running_var, double momentum, double eps, tensor counts);
tensor *atg_batch_norm_stats(tensor input, double eps);
tensor *atg_batch_norm_stats_out(tensor out0, tensor out1, tensor input, double eps);
tensor *atg_batch_norm_update_stats(tensor input, tensor running_mean, tensor running_var, double momentum);
tensor *atg_batch_norm_update_stats_out(tensor out0, tensor out1, tensor input, tensor running_mean, tensor running_var, double momentum);
tensor atg_bernoulli(tensor self);
tensor atg_bernoulli_(tensor self, tensor p);
tensor atg_bernoulli_float_(tensor self, double p);
tensor atg_bernoulli_p(tensor self, double p);
tensor atg_bernoulli_tensor(tensor self, tensor p);
tensor atg_bilinear(tensor input1, tensor input2, tensor weight, tensor bias);
tensor atg_binary_cross_entropy(tensor self, tensor target, tensor weight, int64_t reduction);
tensor atg_binary_cross_entropy_backward(tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction);
tensor atg_binary_cross_entropy_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction);
tensor atg_binary_cross_entropy_out(tensor out, tensor self, tensor target, tensor weight, int64_t reduction);
tensor atg_binary_cross_entropy_with_logits(tensor self, tensor target, tensor weight, tensor pos_weight, int64_t reduction);
tensor atg_binary_cross_entropy_with_logits_out(tensor out, tensor self, tensor target, tensor weight, tensor pos_weight, int64_t reduction);
tensor atg_bincount(tensor self, tensor weights, int64_t minlength);
tensor atg_bincount_out(tensor out, tensor self, tensor weights, int64_t minlength);
tensor atg_binomial(tensor count, tensor prob);
tensor atg_binomial_out(tensor out, tensor count, tensor prob);
tensor atg_bitwise_and(tensor self, scalar other);
tensor atg_bitwise_and_(tensor self, scalar other);
tensor atg_bitwise_and_scalar_out(tensor out, tensor self, scalar other);
tensor atg_bitwise_and_scalar_tensor(scalar self_scalar, tensor other);
tensor atg_bitwise_and_scalar_tensor_out(tensor out, scalar self_scalar, tensor other);
tensor atg_bitwise_and_tensor(tensor self, tensor other);
tensor atg_bitwise_and_tensor_(tensor self, tensor other);
tensor atg_bitwise_and_tensor_out(tensor out, tensor self, tensor other);
tensor atg_bitwise_left_shift(tensor self, tensor other);
tensor atg_bitwise_left_shift_(tensor self, tensor other);
tensor atg_bitwise_left_shift_scalar_tensor(scalar self_scalar, tensor other);
tensor atg_bitwise_left_shift_scalar_tensor_out(tensor out, scalar self_scalar, tensor other);
tensor atg_bitwise_left_shift_tensor_out(tensor out, tensor self, tensor other);
tensor atg_bitwise_left_shift_tensor_scalar(tensor self, scalar other);
tensor atg_bitwise_left_shift_tensor_scalar_(tensor self, scalar other);
tensor atg_bitwise_left_shift_tensor_scalar_out(tensor out, tensor self, scalar other);
tensor atg_bitwise_not(tensor self);
tensor atg_bitwise_not_(tensor self);
tensor atg_bitwise_not_out(tensor out, tensor self);
tensor atg_bitwise_or(tensor self, scalar other);
tensor atg_bitwise_or_(tensor self, scalar other);
tensor atg_bitwise_or_scalar_out(tensor out, tensor self, scalar other);
tensor atg_bitwise_or_scalar_tensor(scalar self_scalar, tensor other);
tensor atg_bitwise_or_scalar_tensor_out(tensor out, scalar self_scalar, tensor other);
tensor atg_bitwise_or_tensor(tensor self, tensor other);
tensor atg_bitwise_or_tensor_(tensor self, tensor other);
tensor atg_bitwise_or_tensor_out(tensor out, tensor self, tensor other);
tensor atg_bitwise_right_shift(tensor self, tensor other);
tensor atg_bitwise_right_shift_(tensor self, tensor other);
tensor atg_bitwise_right_shift_scalar_tensor(scalar self_scalar, tensor other);
tensor atg_bitwise_right_shift_scalar_tensor_out(tensor out, scalar self_scalar, tensor other);
tensor atg_bitwise_right_shift_tensor_out(tensor out, tensor self, tensor other);
tensor atg_bitwise_right_shift_tensor_scalar(tensor self, scalar other);
tensor atg_bitwise_right_shift_tensor_scalar_(tensor self, scalar other);
tensor atg_bitwise_right_shift_tensor_scalar_out(tensor out, tensor self, scalar other);
tensor atg_bitwise_xor(tensor self, scalar other);
tensor atg_bitwise_xor_(tensor self, scalar other);
tensor atg_bitwise_xor_scalar_out(tensor out, tensor self, scalar other);
tensor atg_bitwise_xor_scalar_tensor(scalar self_scalar, tensor other);
tensor atg_bitwise_xor_scalar_tensor_out(tensor out, scalar self_scalar, tensor other);
tensor atg_bitwise_xor_tensor(tensor self, tensor other);
tensor atg_bitwise_xor_tensor_(tensor self, tensor other);
tensor atg_bitwise_xor_tensor_out(tensor out, tensor self, tensor other);
tensor atg_blackman_window(int64_t window_length, int options_kind, int options_device);
tensor atg_blackman_window_out(tensor out, int64_t window_length);
tensor atg_blackman_window_periodic(int64_t window_length, int periodic, int options_kind, int options_device);
tensor atg_blackman_window_periodic_out(tensor out, int64_t window_length, int periodic);
tensor atg_block_diag(tensor *tensors_data, int tensors_len);
tensor atg_block_diag_out(tensor out, tensor *tensors_data, int tensors_len);
tensor atg_bmm(tensor self, tensor mat2);
tensor atg_bmm_out(tensor out, tensor self, tensor mat2);
tensor *atg_broadcast_tensors(tensor *tensors_data, int tensors_len);
tensor atg_broadcast_to(tensor self, int64_t *size_data, int size_len);
tensor atg_bucketize(tensor self, tensor boundaries, int out_int32, int right);
tensor atg_bucketize_scalar(scalar self_scalar, tensor boundaries, int out_int32, int right);
tensor atg_bucketize_scalar_out(tensor out, scalar self_scalar, tensor boundaries, int out_int32, int right);
tensor atg_bucketize_tensor_out(tensor out, tensor self, tensor boundaries, int out_int32, int right);
int atg_can_cast(int from, int to);
tensor atg_cartesian_prod(tensor *tensors_data, int tensors_len);
tensor atg_cat(tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg_cat_out(tensor out, tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg_cauchy(tensor self, double median, double sigma);
tensor atg_cauchy_(tensor self, double median, double sigma);
tensor atg_cauchy_out(tensor out, tensor self, double median, double sigma);
tensor atg_ccol_indices(tensor self);
tensor atg_ccol_indices_copy(tensor self);
tensor atg_ccol_indices_copy_out(tensor out, tensor self);
tensor atg_cdist(tensor x1, tensor x2, double p, int64_t compute_mode_v, uint8_t compute_mode_null);
tensor atg_ceil(tensor self);
tensor atg_ceil_(tensor self);
tensor atg_ceil_out(tensor out, tensor self);
tensor atg_celu(tensor self);
tensor atg_celu_(tensor self);
tensor atg_celu_out(tensor out, tensor self);
tensor atg_chain_matmul(tensor *matrices_data, int matrices_len);
tensor atg_chain_matmul_out(tensor out, tensor *matrices_data, int matrices_len);
tensor atg_chalf(tensor self);
tensor atg_channel_shuffle(tensor self, int64_t groups);
tensor atg_channel_shuffle_out(tensor out, tensor self, int64_t groups);
tensor atg_cholesky(tensor self, int upper);
tensor atg_cholesky_inverse(tensor self, int upper);
tensor atg_cholesky_inverse_out(tensor out, tensor self, int upper);
tensor atg_cholesky_out(tensor out, tensor self, int upper);
tensor atg_cholesky_solve(tensor self, tensor input2, int upper);
tensor atg_cholesky_solve_out(tensor out, tensor self, tensor input2, int upper);
tensor *atg_choose_qparams_optimized(tensor input, int64_t numel, int64_t n_bins, double ratio, int64_t bit_width);
tensor *atg_chunk(tensor self, int64_t chunks, int64_t dim);
tensor atg_clamp(tensor self, scalar min, scalar max);
tensor atg_clamp_(tensor self, scalar min, scalar max);
tensor atg_clamp_max(tensor self, scalar max);
tensor atg_clamp_max_(tensor self, scalar max);
tensor atg_clamp_max_out(tensor out, tensor self, scalar max);
tensor atg_clamp_max_tensor(tensor self, tensor max);
tensor atg_clamp_max_tensor_(tensor self, tensor max);
tensor atg_clamp_max_tensor_out(tensor out, tensor self, tensor max);
tensor atg_clamp_min(tensor self, scalar min);
tensor atg_clamp_min_(tensor self, scalar min);
tensor atg_clamp_min_out(tensor out, tensor self, scalar min);
tensor atg_clamp_min_tensor(tensor self, tensor min);
tensor atg_clamp_min_tensor_(tensor self, tensor min);
tensor atg_clamp_min_tensor_out(tensor out, tensor self, tensor min);
tensor atg_clamp_out(tensor out, tensor self, scalar min, scalar max);
tensor atg_clamp_tensor(tensor self, tensor min, tensor max);
tensor atg_clamp_tensor_(tensor self, tensor min, tensor max);
tensor atg_clamp_tensor_out(tensor out, tensor self, tensor min, tensor max);
tensor atg_clip(tensor self, scalar min, scalar max);
tensor atg_clip_(tensor self, scalar min, scalar max);
tensor atg_clip_out(tensor out, tensor self, scalar min, scalar max);
tensor atg_clip_tensor(tensor self, tensor min, tensor max);
tensor atg_clip_tensor_(tensor self, tensor min, tensor max);
tensor atg_clip_tensor_out(tensor out, tensor self, tensor min, tensor max);
tensor atg_clone(tensor out, tensor self);
tensor atg_coalesce(tensor self);
tensor atg_col2im(tensor self, int64_t *output_size_data, int output_size_len, int64_t *kernel_size_data, int kernel_size_len, int64_t *dilation_data, int dilation_len, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len);
tensor atg_col2im_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, int64_t *kernel_size_data, int kernel_size_len, int64_t *dilation_data, int dilation_len, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len);
tensor atg_col_indices(tensor self);
tensor atg_col_indices_copy(tensor self);
tensor atg_col_indices_copy_out(tensor out, tensor self);
tensor atg_column_stack(tensor *tensors_data, int tensors_len);
tensor atg_column_stack_out(tensor out, tensor *tensors_data, int tensors_len);
tensor atg_combinations(tensor self, int64_t r, int with_replacement);
tensor atg_complex(tensor real, tensor imag);
tensor atg_complex_out(tensor out, tensor real, tensor imag);
tensor atg_concat(tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg_concat_out(tensor out, tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg_concatenate(tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg_concatenate_out(tensor out, tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg_conj(tensor self);
tensor atg_conj_physical(tensor self);
tensor atg_conj_physical_(tensor self);
tensor atg_conj_physical_out(tensor out, tensor self);
tensor atg_constant_pad_nd(tensor self, int64_t *pad_data, int pad_len);
tensor atg_constant_pad_nd_out(tensor out, tensor self, int64_t *pad_data, int pad_len);
tensor atg_contiguous(tensor self);
tensor atg_conv1d(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_conv1d_padding(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, char* padding_ptr, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_conv2d(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_conv2d_padding(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, char* padding_ptr, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_conv3d(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_conv3d_padding(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, char* padding_ptr, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_conv_depthwise3d(tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_conv_depthwise3d_out(tensor out, tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_conv_tbc(tensor self, tensor weight, tensor bias, int64_t pad);
tensor *atg_conv_tbc_backward(tensor self, tensor input, tensor weight, tensor bias, int64_t pad);
tensor atg_conv_tbc_out(tensor out, tensor self, tensor weight, tensor bias, int64_t pad);
tensor atg_conv_transpose1d(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t groups, int64_t *dilation_data, int dilation_len);
tensor atg_conv_transpose2d(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t groups, int64_t *dilation_data, int dilation_len);
tensor atg_conv_transpose3d(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t groups, int64_t *dilation_data, int dilation_len);
tensor atg_convolution(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int transposed, int64_t *output_padding_data, int output_padding_len, int64_t groups);
tensor atg_convolution_out(tensor out, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int transposed, int64_t *output_padding_data, int output_padding_len, int64_t groups);
tensor atg_convolution_overrideable(tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int transposed, int64_t *output_padding_data, int output_padding_len, int64_t groups);
tensor atg_convolution_overrideable_out(tensor out, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int transposed, int64_t *output_padding_data, int output_padding_len, int64_t groups);
tensor atg_copy(tensor self, tensor src, int non_blocking);
tensor atg_copy_out(tensor out, tensor self, tensor src, int non_blocking);
tensor atg_copy_sparse_to_sparse(tensor self, tensor src, int non_blocking);
tensor atg_copy_sparse_to_sparse_(tensor self, tensor src, int non_blocking);
tensor atg_copy_sparse_to_sparse_out(tensor out, tensor self, tensor src, int non_blocking);
tensor atg_copysign(tensor self, tensor other);
tensor atg_copysign_(tensor self, tensor other);
tensor atg_copysign_out(tensor out, tensor self, tensor other);
tensor atg_copysign_scalar(tensor self, scalar other);
tensor atg_copysign_scalar_(tensor self, scalar other);
tensor atg_copysign_scalar_out(tensor out, tensor self, scalar other);
tensor atg_corrcoef(tensor self);
tensor atg_cos(tensor self);
tensor atg_cos_(tensor self);
tensor atg_cos_out(tensor out, tensor self);
tensor atg_cosh(tensor self);
tensor atg_cosh_(tensor self);
tensor atg_cosh_out(tensor out, tensor self);
tensor atg_cosine_embedding_loss(tensor input1, tensor input2, tensor target, double margin, int64_t reduction);
tensor atg_cosine_similarity(tensor x1, tensor x2, int64_t dim, double eps);
tensor atg_count_nonzero(tensor self, int64_t dim_v, uint8_t dim_null);
tensor atg_count_nonzero_dim_intlist(tensor self, int64_t *dim_data, int dim_len);
tensor atg_count_nonzero_dim_intlist_out(tensor out, tensor self, int64_t *dim_data, int dim_len);
tensor atg_count_nonzero_out(tensor out, tensor self, int64_t dim_v, uint8_t dim_null);
tensor atg_cov(tensor self, int64_t correction, tensor fweights, tensor aweights);
tensor atg_cross(tensor self, tensor other, int64_t dim_v, uint8_t dim_null);
tensor atg_cross_entropy_loss(tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, double label_smoothing);
tensor atg_cross_out(tensor out, tensor self, tensor other, int64_t dim_v, uint8_t dim_null);
tensor atg_crow_indices(tensor self);
tensor atg_crow_indices_copy(tensor self);
tensor atg_crow_indices_copy_out(tensor out, tensor self);
tensor atg_ctc_loss(tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, int64_t blank, int64_t reduction, int zero_infinity);
tensor atg_ctc_loss_tensor(tensor log_probs, tensor targets, tensor input_lengths, tensor target_lengths, int64_t blank, int64_t reduction, int zero_infinity);
tensor atg_cudnn_affine_grid_generator(tensor theta, int64_t n, int64_t C, int64_t H, int64_t W);
tensor atg_cudnn_affine_grid_generator_backward(tensor grad, int64_t n, int64_t C, int64_t H, int64_t W);
tensor atg_cudnn_affine_grid_generator_backward_out(tensor out, tensor grad, int64_t n, int64_t C, int64_t H, int64_t W);
tensor atg_cudnn_affine_grid_generator_out(tensor out, tensor theta, int64_t n, int64_t C, int64_t H, int64_t W);
tensor *atg_cudnn_batch_norm(tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double exponential_average_factor, double epsilon);
tensor *atg_cudnn_batch_norm_backward(tensor input, tensor grad_output, tensor weight, tensor running_mean, tensor running_var, tensor save_mean, tensor save_var, double epsilon, tensor reserveSpace);
tensor *atg_cudnn_batch_norm_backward_out(tensor out0, tensor out1, tensor out2, tensor input, tensor grad_output, tensor weight, tensor running_mean, tensor running_var, tensor save_mean, tensor save_var, double epsilon, tensor reserveSpace);
tensor *atg_cudnn_batch_norm_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double exponential_average_factor, double epsilon);
tensor atg_cudnn_convolution(tensor self, tensor weight, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic, int allow_tf32);
tensor atg_cudnn_convolution_add_relu(tensor self, tensor weight, tensor z, scalar alpha, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_cudnn_convolution_add_relu_out(tensor out, tensor self, tensor weight, tensor z, scalar alpha, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_cudnn_convolution_out(tensor out, tensor self, tensor weight, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic, int allow_tf32);
tensor atg_cudnn_convolution_relu(tensor self, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_cudnn_convolution_relu_out(tensor out, tensor self, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_cudnn_convolution_transpose(tensor self, tensor weight, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic, int allow_tf32);
tensor atg_cudnn_convolution_transpose_out(tensor out, tensor self, tensor weight, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic, int allow_tf32);
tensor atg_cudnn_grid_sampler(tensor self, tensor grid);
tensor *atg_cudnn_grid_sampler_backward(tensor self, tensor grid, tensor grad_output);
tensor *atg_cudnn_grid_sampler_backward_out(tensor out0, tensor out1, tensor self, tensor grid, tensor grad_output);
tensor atg_cudnn_grid_sampler_out(tensor out, tensor self, tensor grid);
int atg_cudnn_is_acceptable(tensor self);
tensor *atg_cummax(tensor self, int64_t dim);
tensor *atg_cummax_out(tensor values, tensor indices, tensor self, int64_t dim);
tensor atg_cummaxmin_backward(tensor grad, tensor input, tensor indices, int64_t dim);
tensor *atg_cummin(tensor self, int64_t dim);
tensor *atg_cummin_out(tensor values, tensor indices, tensor self, int64_t dim);
tensor atg_cumprod(tensor self, int64_t dim, int dtype);
tensor atg_cumprod_(tensor self, int64_t dim, int dtype);
tensor atg_cumprod_backward(tensor grad, tensor input, int64_t dim, tensor output);
tensor atg_cumprod_out(tensor out, tensor self, int64_t dim, int dtype);
tensor atg_cumsum(tensor self, int64_t dim, int dtype);
tensor atg_cumsum_(tensor self, int64_t dim, int dtype);
tensor atg_cumsum_out(tensor out, tensor self, int64_t dim, int dtype);
tensor atg_cumulative_trapezoid(tensor y, int64_t dim);
tensor atg_cumulative_trapezoid_x(tensor y, tensor x, int64_t dim);
tensor atg_data(tensor self);
tensor atg_deg2rad(tensor self);
tensor atg_deg2rad_(tensor self);
tensor atg_deg2rad_out(tensor out, tensor self);
int64_t atg_dense_dim(tensor self);
tensor atg_dequantize(tensor self);
tensor *atg_dequantize_tensors(tensor *tensors_data, int tensors_len);
tensor atg_det(tensor self);
tensor atg_detach(tensor self);
tensor atg_detach_(tensor self);
tensor atg_detach_copy(tensor self);
tensor atg_detach_copy_out(tensor out, tensor self);
tensor atg_diag(tensor self, int64_t diagonal);
tensor atg_diag_embed(tensor self, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diag_embed_out(tensor out, tensor self, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diag_out(tensor out, tensor self, int64_t diagonal);
tensor atg_diagflat(tensor self, int64_t offset);
tensor atg_diagonal(tensor self, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diagonal_backward(tensor grad_output, int64_t *input_sizes_data, int input_sizes_len, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diagonal_backward_out(tensor out, tensor grad_output, int64_t *input_sizes_data, int input_sizes_len, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diagonal_copy(tensor self, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diagonal_copy_out(tensor out, tensor self, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diagonal_scatter(tensor self, tensor src, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diagonal_scatter_out(tensor out, tensor self, tensor src, int64_t offset, int64_t dim1, int64_t dim2);
tensor atg_diff(tensor self, int64_t n, int64_t dim, tensor prepend, tensor append);
tensor atg_diff_out(tensor out, tensor self, int64_t n, int64_t dim, tensor prepend, tensor append);
tensor atg_digamma(tensor self);
tensor atg_digamma_(tensor self);
tensor atg_digamma_out(tensor out, tensor self);
tensor atg_dist(tensor self, tensor other);
tensor atg_dist_out(tensor out, tensor self, tensor other);
tensor atg_div(tensor self, tensor other);
tensor atg_div_(tensor self, tensor other);
tensor atg_div_out(tensor out, tensor self, tensor other);
tensor atg_div_out_mode(tensor out, tensor self, tensor other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_div_scalar(tensor self, scalar other);
tensor atg_div_scalar_(tensor self, scalar other);
tensor atg_div_scalar_mode(tensor self, scalar other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_div_scalar_mode_(tensor self, scalar other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_div_scalar_mode_out(tensor out, tensor self, scalar other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_div_scalar_out(tensor out, tensor self, scalar other);
tensor atg_div_tensor_mode(tensor self, tensor other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_div_tensor_mode_(tensor self, tensor other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_divide(tensor self, tensor other);
tensor atg_divide_(tensor self, tensor other);
tensor atg_divide_out(tensor out, tensor self, tensor other);
tensor atg_divide_out_mode(tensor out, tensor self, tensor other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_divide_scalar(tensor self, scalar other);
tensor atg_divide_scalar_(tensor self, scalar other);
tensor atg_divide_scalar_mode(tensor self, scalar other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_divide_scalar_mode_(tensor self, scalar other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_divide_tensor_mode(tensor self, tensor other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_divide_tensor_mode_(tensor self, tensor other, char* rounding_mode_ptr, int rounding_mode_len);
tensor atg_dot(tensor self, tensor tensor);
tensor atg_dot_out(tensor out, tensor self, tensor tensor);
tensor atg_dropout(tensor input, double p, int train);
tensor atg_dropout_(tensor self, double p, int train);
tensor *atg_dsplit(tensor self, int64_t sections);
tensor *atg_dsplit_array(tensor self, int64_t *indices_data, int indices_len);
tensor atg_dstack(tensor *tensors_data, int tensors_len);
tensor atg_dstack_out(tensor out, tensor *tensors_data, int tensors_len);
tensor atg_einsum(char* equation_ptr, int equation_len, tensor *tensors_data, int tensors_len, int64_t *path_data, int path_len);
tensor atg_elu(tensor self);
tensor atg_elu_(tensor self);
tensor atg_elu_backward(tensor grad_output, scalar alpha, scalar scale, scalar input_scale, int is_result, tensor self_or_result);
tensor atg_elu_backward_grad_input(tensor grad_input, tensor grad_output, scalar alpha, scalar scale, scalar input_scale, int is_result, tensor self_or_result);
tensor atg_elu_out(tensor out, tensor self);
tensor atg_embedding(tensor weight, tensor indices, int64_t padding_idx, int scale_grad_by_freq, int sparse);
tensor atg_embedding_backward(tensor grad, tensor indices, int64_t num_weights, int64_t padding_idx, int scale_grad_by_freq, int sparse);
tensor *atg_embedding_bag(tensor weight, tensor indices, tensor offsets, int scale_grad_by_freq, int64_t mode, int sparse, tensor per_sample_weights, int include_last_offset);
tensor *atg_embedding_bag_padding_idx(tensor weight, tensor indices, tensor offsets, int scale_grad_by_freq, int64_t mode, int sparse, tensor per_sample_weights, int include_last_offset, int64_t padding_idx_v, uint8_t padding_idx_null);
tensor atg_embedding_dense_backward(tensor grad_output, tensor indices, int64_t num_weights, int64_t padding_idx, int scale_grad_by_freq);
tensor atg_embedding_dense_backward_out(tensor out, tensor grad_output, tensor indices, int64_t num_weights, int64_t padding_idx, int scale_grad_by_freq);
tensor atg_embedding_out(tensor out, tensor weight, tensor indices, int64_t padding_idx, int scale_grad_by_freq, int sparse);
tensor atg_embedding_renorm(tensor self, tensor indices, double max_norm, double norm_type);
tensor atg_embedding_renorm_(tensor self, tensor indices, double max_norm, double norm_type);
tensor atg_embedding_renorm_out(tensor out, tensor self, tensor indices, double max_norm, double norm_type);
tensor atg_embedding_sparse_backward(tensor grad, tensor indices, int64_t num_weights, int64_t padding_idx, int scale_grad_by_freq);
tensor atg_empty(int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_empty_like(tensor self);
tensor atg_empty_like_out(tensor out, tensor self);
tensor atg_empty_out(tensor out, int64_t *size_data, int size_len);
tensor atg_empty_permuted(int64_t *size_data, int size_len, int64_t *physical_layout_data, int physical_layout_len, int options_kind, int options_device);
tensor atg_empty_permuted_out(tensor out, int64_t *size_data, int size_len, int64_t *physical_layout_data, int physical_layout_len);
tensor atg_empty_quantized(int64_t *size_data, int size_len, tensor qtensor, int options_kind, int options_device);
tensor atg_empty_quantized_out(tensor out, int64_t *size_data, int size_len, tensor qtensor);
tensor atg_empty_strided(int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int options_kind, int options_device);
tensor atg_empty_strided_out(tensor out, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len);
tensor atg_eq(tensor self, scalar other);
tensor atg_eq_(tensor self, scalar other);
tensor atg_eq_scalar_out(tensor out, tensor self, scalar other);
tensor atg_eq_tensor(tensor self, tensor other);
tensor atg_eq_tensor_(tensor self, tensor other);
tensor atg_eq_tensor_out(tensor out, tensor self, tensor other);
int atg_equal(tensor self, tensor other);
tensor atg_erf(tensor self);
tensor atg_erf_(tensor self);
tensor atg_erf_out(tensor out, tensor self);
tensor atg_erfc(tensor self);
tensor atg_erfc_(tensor self);
tensor atg_erfc_out(tensor out, tensor self);
tensor atg_erfinv(tensor self);
tensor atg_erfinv_(tensor self);
tensor atg_erfinv_out(tensor out, tensor self);
tensor atg_exp(tensor self);
tensor atg_exp2(tensor self);
tensor atg_exp2_(tensor self);
tensor atg_exp2_out(tensor out, tensor self);
tensor atg_exp_(tensor self);
tensor atg_exp_out(tensor out, tensor self);
tensor atg_expand(tensor self, int64_t *size_data, int size_len, int implicit);
tensor atg_expand_as(tensor self, tensor other);
tensor atg_expand_copy(tensor self, int64_t *size_data, int size_len, int implicit);
tensor atg_expand_copy_out(tensor out, tensor self, int64_t *size_data, int size_len, int implicit);
tensor atg_expm1(tensor self);
tensor atg_expm1_(tensor self);
tensor atg_expm1_out(tensor out, tensor self);
tensor atg_exponential(tensor self, double lambd);
tensor atg_exponential_(tensor self, double lambd);
tensor atg_exponential_out(tensor out, tensor self, double lambd);
tensor atg_eye(int64_t n, int options_kind, int options_device);
tensor atg_eye_m(int64_t n, int64_t m, int options_kind, int options_device);
tensor atg_eye_m_out(tensor out, int64_t n, int64_t m);
tensor atg_eye_out(tensor out, int64_t n);
tensor atg_fake_quantize_per_channel_affine(tensor self, tensor scale, tensor zero_point, int64_t axis, int64_t quant_min, int64_t quant_max);
tensor *atg_fake_quantize_per_channel_affine_cachemask(tensor self, tensor scale, tensor zero_point, int64_t axis, int64_t quant_min, int64_t quant_max);
tensor atg_fake_quantize_per_channel_affine_cachemask_backward(tensor grad, tensor mask);
tensor *atg_fake_quantize_per_channel_affine_cachemask_out(tensor out0, tensor out1, tensor self, tensor scale, tensor zero_point, int64_t axis, int64_t quant_min, int64_t quant_max);
tensor atg_fake_quantize_per_tensor_affine(tensor self, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max);
tensor *atg_fake_quantize_per_tensor_affine_cachemask(tensor self, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max);
tensor atg_fake_quantize_per_tensor_affine_cachemask_backward(tensor grad, tensor mask);
tensor *atg_fake_quantize_per_tensor_affine_cachemask_out(tensor out0, tensor out1, tensor self, double scale, int64_t zero_point, int64_t quant_min, int64_t quant_max);
tensor atg_fake_quantize_per_tensor_affine_tensor_qparams(tensor self, tensor scale, tensor zero_point, int64_t quant_min, int64_t quant_max);
tensor atg_fbgemm_linear_fp16_weight(tensor input, tensor packed_weight, tensor bias);
tensor atg_fbgemm_linear_fp16_weight_fp32_activation(tensor input, tensor packed_weight, tensor bias);
tensor atg_fbgemm_linear_int8_weight(tensor input, tensor weight, tensor packed, tensor col_offsets, scalar weight_scale, scalar weight_zero_point, tensor bias);
tensor atg_fbgemm_linear_int8_weight_fp32_activation(tensor input, tensor weight, tensor packed, tensor col_offsets, scalar weight_scale, scalar weight_zero_point, tensor bias);
tensor atg_fbgemm_pack_gemm_matrix_fp16(tensor input);
tensor atg_fbgemm_pack_quantized_matrix(tensor input);
tensor atg_fbgemm_pack_quantized_matrix_kn(tensor input, int64_t K, int64_t n);
tensor atg_feature_alpha_dropout(tensor input, double p, int train);
tensor atg_feature_alpha_dropout_(tensor self, double p, int train);
tensor atg_feature_dropout(tensor input, double p, int train);
tensor atg_feature_dropout_(tensor self, double p, int train);
tensor atg_fft_fft(tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_fft2(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_fft2_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_fft_out(tensor out, tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_fftfreq(int64_t n, double d, int options_kind, int options_device);
tensor atg_fft_fftfreq_out(tensor out, int64_t n, double d);
tensor atg_fft_fftn(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_fftn_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_fftshift(tensor self, int64_t *dim_data, int dim_len);
tensor atg_fft_hfft(tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_hfft2(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_hfft2_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_hfft_out(tensor out, tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_hfftn(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_hfftn_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_ifft(tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_ifft2(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_ifft2_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_ifft_out(tensor out, tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_ifftn(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_ifftn_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_ifftshift(tensor self, int64_t *dim_data, int dim_len);
tensor atg_fft_ihfft(tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_ihfft2(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_ihfft2_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_ihfft_out(tensor out, tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_ihfftn(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_ihfftn_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_irfft(tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_irfft2(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_irfft2_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_irfft_out(tensor out, tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_irfftn(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_irfftn_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_rfft(tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_rfft2(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_rfft2_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_rfft_out(tensor out, tensor self, int64_t n_v, uint8_t n_null, int64_t dim, char* norm_ptr, int norm_len);
tensor atg_fft_rfftfreq(int64_t n, double d, int options_kind, int options_device);
tensor atg_fft_rfftfreq_out(tensor out, int64_t n, double d);
tensor atg_fft_rfftn(tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fft_rfftn_out(tensor out, tensor self, int64_t *s_data, int s_len, int64_t *dim_data, int dim_len, char* norm_ptr, int norm_len);
tensor atg_fill(tensor self, scalar value);
tensor atg_fill_(tensor self, scalar value);
tensor atg_fill_diagonal_(tensor self, scalar fill_value, int wrap);
tensor atg_fill_scalar_out(tensor out, tensor self, scalar value);
tensor atg_fill_tensor(tensor self, tensor value);
tensor atg_fill_tensor_(tensor self, tensor value);
tensor atg_fill_tensor_out(tensor out, tensor self, tensor value);
tensor atg_fix(tensor self);
tensor atg_fix_(tensor self);
tensor atg_fix_out(tensor out, tensor self);
tensor atg_flatten(tensor self, int64_t start_dim, int64_t end_dim);
tensor atg_flatten_dense_tensors(tensor *tensors_data, int tensors_len);
tensor atg_flip(tensor self, int64_t *dims_data, int dims_len);
tensor atg_flip_out(tensor out, tensor self, int64_t *dims_data, int dims_len);
tensor atg_fliplr(tensor self);
tensor atg_flipud(tensor self);
tensor atg_float_power(tensor self, tensor exponent);
tensor atg_float_power_(tensor self, scalar exponent);
tensor atg_float_power_scalar(scalar self_scalar, tensor exponent);
tensor atg_float_power_scalar_out(tensor out, scalar self_scalar, tensor exponent);
tensor atg_float_power_tensor_(tensor self, tensor exponent);
tensor atg_float_power_tensor_scalar(tensor self, scalar exponent);
tensor atg_float_power_tensor_scalar_out(tensor out, tensor self, scalar exponent);
tensor atg_float_power_tensor_tensor_out(tensor out, tensor self, tensor exponent);
tensor atg_floor(tensor self);
tensor atg_floor_(tensor self);
tensor atg_floor_divide(tensor self, tensor other);
tensor atg_floor_divide_(tensor self, tensor other);
tensor atg_floor_divide_out(tensor out, tensor self, tensor other);
tensor atg_floor_divide_scalar(tensor self, scalar other);
tensor atg_floor_divide_scalar_(tensor self, scalar other);
tensor atg_floor_out(tensor out, tensor self);
tensor atg_fmax(tensor self, tensor other);
tensor atg_fmax_out(tensor out, tensor self, tensor other);
tensor atg_fmin(tensor self, tensor other);
tensor atg_fmin_out(tensor out, tensor self, tensor other);
tensor atg_fmod(tensor self, scalar other);
tensor atg_fmod_(tensor self, scalar other);
tensor atg_fmod_scalar_out(tensor out, tensor self, scalar other);
tensor atg_fmod_tensor(tensor self, tensor other);
tensor atg_fmod_tensor_(tensor self, tensor other);
tensor atg_fmod_tensor_out(tensor out, tensor self, tensor other);
tensor atg_frac(tensor self);
tensor atg_frac_(tensor self);
tensor atg_frac_out(tensor out, tensor self);
tensor *atg_fractional_max_pool2d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor random_samples);
tensor atg_fractional_max_pool2d_backward(tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor indices);
tensor atg_fractional_max_pool2d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor indices);
tensor *atg_fractional_max_pool2d_output(tensor output, tensor indices, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor random_samples);
tensor *atg_fractional_max_pool3d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor random_samples);
tensor atg_fractional_max_pool3d_backward(tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor indices);
tensor atg_fractional_max_pool3d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor indices);
tensor *atg_fractional_max_pool3d_output(tensor output, tensor indices, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor random_samples);
tensor *atg_frexp(tensor self);
tensor *atg_frexp_tensor_out(tensor mantissa, tensor exponent, tensor self);
tensor atg_frobenius_norm(tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_frobenius_norm_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_from_file(char* filename_ptr, int filename_len, int shared, int64_t size_v, uint8_t size_null, int options_kind, int options_device);
tensor atg_from_file_out(tensor out, char* filename_ptr, int filename_len, int shared, int64_t size_v, uint8_t size_null);
tensor atg_full(int64_t *size_data, int size_len, scalar fill_value, int options_kind, int options_device);
tensor atg_full_like(tensor self, scalar fill_value);
tensor atg_full_like_out(tensor out, tensor self, scalar fill_value);
tensor atg_full_out(tensor out, int64_t *size_data, int size_len, scalar fill_value);
tensor atg_fused_moving_avg_obs_fake_quant(tensor self, tensor observer_on, tensor fake_quant_on, tensor running_min, tensor running_max, tensor scale, tensor zero_point, double averaging_const, int64_t quant_min, int64_t quant_max, int64_t ch_axis, int per_row_fake_quant, int symmetric_quant);
tensor atg_gather(tensor self, int64_t dim, tensor index, int sparse_grad);
tensor atg_gather_backward(tensor grad, tensor self, int64_t dim, tensor index, int sparse_grad);
tensor atg_gather_out(tensor out, tensor self, int64_t dim, tensor index, int sparse_grad);
tensor atg_gcd(tensor self, tensor other);
tensor atg_gcd_(tensor self, tensor other);
tensor atg_gcd_out(tensor out, tensor self, tensor other);
tensor atg_ge(tensor self, scalar other);
tensor atg_ge_(tensor self, scalar other);
tensor atg_ge_scalar_out(tensor out, tensor self, scalar other);
tensor atg_ge_tensor(tensor self, tensor other);
tensor atg_ge_tensor_(tensor self, tensor other);
tensor atg_ge_tensor_out(tensor out, tensor self, tensor other);
tensor atg_gelu(tensor self, char* approximate_ptr, int approximate_len);
tensor atg_gelu_(tensor self, char* approximate_ptr, int approximate_len);
tensor atg_gelu_backward(tensor grad_output, tensor self, char* approximate_ptr, int approximate_len);
tensor atg_gelu_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, char* approximate_ptr, int approximate_len);
tensor atg_gelu_out(tensor out, tensor self, char* approximate_ptr, int approximate_len);
tensor atg_geometric(tensor self, double p);
tensor atg_geometric_(tensor self, double p);
tensor atg_geometric_out(tensor out, tensor self, double p);
tensor *atg_geqrf(tensor self);
tensor *atg_geqrf_a(tensor a, tensor tau, tensor self);
tensor atg_ger(tensor self, tensor vec2);
tensor atg_ger_out(tensor out, tensor self, tensor vec2);
tensor atg_glu(tensor self, int64_t dim);
tensor atg_glu_backward(tensor grad_output, tensor self, int64_t dim);
tensor atg_glu_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t dim);
tensor atg_glu_backward_jvp(tensor grad_x, tensor grad_glu, tensor x, tensor dgrad_glu, tensor dx, int64_t dim);
tensor atg_glu_backward_jvp_out(tensor out, tensor grad_x, tensor grad_glu, tensor x, tensor dgrad_glu, tensor dx, int64_t dim);
tensor atg_glu_jvp(tensor glu, tensor x, tensor dx, int64_t dim);
tensor atg_glu_jvp_out(tensor out, tensor glu, tensor x, tensor dx, int64_t dim);
tensor atg_glu_out(tensor out, tensor self, int64_t dim);
tensor atg_grad(tensor self);
tensor atg_greater(tensor self, scalar other);
tensor atg_greater_(tensor self, scalar other);
tensor atg_greater_equal(tensor self, scalar other);
tensor atg_greater_equal_(tensor self, scalar other);
tensor atg_greater_equal_scalar_out(tensor out, tensor self, scalar other);
tensor atg_greater_equal_tensor(tensor self, tensor other);
tensor atg_greater_equal_tensor_(tensor self, tensor other);
tensor atg_greater_equal_tensor_out(tensor out, tensor self, tensor other);
tensor atg_greater_scalar_out(tensor out, tensor self, scalar other);
tensor atg_greater_tensor(tensor self, tensor other);
tensor atg_greater_tensor_(tensor self, tensor other);
tensor atg_greater_tensor_out(tensor out, tensor self, tensor other);
tensor atg_grid_sampler(tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode, int align_corners);
tensor atg_grid_sampler_2d(tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode, int align_corners);
tensor atg_grid_sampler_2d_out(tensor out, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode, int align_corners);
tensor atg_grid_sampler_3d(tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode, int align_corners);
tensor atg_grid_sampler_3d_out(tensor out, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode, int align_corners);
tensor atg_group_norm(tensor input, int64_t num_groups, tensor weight, tensor bias, double eps, int cudnn_enabled);
tensor *atg_gru(tensor input, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
tensor atg_gru_cell(tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh);
tensor *atg_gru_data(tensor data, tensor batch_sizes, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional);
tensor atg_gt(tensor self, scalar other);
tensor atg_gt_(tensor self, scalar other);
tensor atg_gt_scalar_out(tensor out, tensor self, scalar other);
tensor atg_gt_tensor(tensor self, tensor other);
tensor atg_gt_tensor_(tensor self, tensor other);
tensor atg_gt_tensor_out(tensor out, tensor self, tensor other);
tensor atg_hamming_window(int64_t window_length, int options_kind, int options_device);
tensor atg_hamming_window_out(tensor out, int64_t window_length);
tensor atg_hamming_window_periodic(int64_t window_length, int periodic, int options_kind, int options_device);
tensor atg_hamming_window_periodic_alpha(int64_t window_length, int periodic, double alpha, int options_kind, int options_device);
tensor atg_hamming_window_periodic_alpha_beta(int64_t window_length, int periodic, double alpha, double beta, int options_kind, int options_device);
tensor atg_hamming_window_periodic_alpha_beta_out(tensor out, int64_t window_length, int periodic, double alpha, double beta);
tensor atg_hamming_window_periodic_alpha_out(tensor out, int64_t window_length, int periodic, double alpha);
tensor atg_hamming_window_periodic_out(tensor out, int64_t window_length, int periodic);
tensor atg_hann_window(int64_t window_length, int options_kind, int options_device);
tensor atg_hann_window_out(tensor out, int64_t window_length);
tensor atg_hann_window_periodic(int64_t window_length, int periodic, int options_kind, int options_device);
tensor atg_hann_window_periodic_out(tensor out, int64_t window_length, int periodic);
tensor atg_hardshrink(tensor self);
tensor atg_hardshrink_backward(tensor grad_out, tensor self, scalar lambd);
tensor atg_hardshrink_backward_grad_input(tensor grad_input, tensor grad_out, tensor self, scalar lambd);
tensor atg_hardshrink_out(tensor out, tensor self);
tensor atg_hardsigmoid(tensor self);
tensor atg_hardsigmoid_(tensor self);
tensor atg_hardsigmoid_backward(tensor grad_output, tensor self);
tensor atg_hardsigmoid_backward_grad_input(tensor grad_input, tensor grad_output, tensor self);
tensor atg_hardsigmoid_out(tensor out, tensor self);
tensor atg_hardswish(tensor self);
tensor atg_hardswish_(tensor self);
tensor atg_hardswish_backward(tensor grad_output, tensor self);
tensor atg_hardswish_backward_out(tensor out, tensor grad_output, tensor self);
tensor atg_hardswish_out(tensor out, tensor self);
tensor atg_hardtanh(tensor self);
tensor atg_hardtanh_(tensor self);
tensor atg_hardtanh_backward(tensor grad_output, tensor self, scalar min_val, scalar max_val);
tensor atg_hardtanh_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, scalar min_val, scalar max_val);
tensor atg_hardtanh_out(tensor out, tensor self);
tensor atg_heaviside(tensor self, tensor values);
tensor atg_heaviside_(tensor self, tensor values);
tensor atg_heaviside_out(tensor out, tensor self, tensor values);
tensor atg_hinge_embedding_loss(tensor self, tensor target, double margin, int64_t reduction);
tensor atg_histc(tensor self, int64_t bins);
tensor atg_histc_out(tensor out, tensor self, int64_t bins);
tensor *atg_hsplit(tensor self, int64_t sections);
tensor *atg_hsplit_array(tensor self, int64_t *indices_data, int indices_len);
tensor atg_hspmm(tensor mat1, tensor mat2);
tensor atg_hspmm_out(tensor out, tensor mat1, tensor mat2);
tensor atg_hstack(tensor *tensors_data, int tensors_len);
tensor atg_hstack_out(tensor out, tensor *tensors_data, int tensors_len);
tensor atg_huber_loss(tensor self, tensor target, int64_t reduction, double delta);
tensor atg_huber_loss_backward(tensor grad_output, tensor self, tensor target, int64_t reduction, double delta);
tensor atg_huber_loss_backward_out(tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction, double delta);
tensor atg_huber_loss_out(tensor out, tensor self, tensor target, int64_t reduction, double delta);
tensor atg_hypot(tensor self, tensor other);
tensor atg_hypot_(tensor self, tensor other);
tensor atg_hypot_out(tensor out, tensor self, tensor other);
tensor atg_i0(tensor self);
tensor atg_i0_(tensor self);
tensor atg_i0_out(tensor out, tensor self);
tensor atg_igamma(tensor self, tensor other);
tensor atg_igamma_(tensor self, tensor other);
tensor atg_igamma_out(tensor out, tensor self, tensor other);
tensor atg_igammac(tensor self, tensor other);
tensor atg_igammac_(tensor self, tensor other);
tensor atg_igammac_out(tensor out, tensor self, tensor other);
tensor atg_im2col(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *dilation_data, int dilation_len, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len);
tensor atg_im2col_out(tensor out, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *dilation_data, int dilation_len, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len);
tensor atg_imag(tensor self);
tensor atg_index(tensor self, tensor *indices_data, int indices_len);
tensor atg_index_add(tensor self, int64_t dim, tensor index, tensor source);
tensor atg_index_add_(tensor self, int64_t dim, tensor index, tensor source);
tensor atg_index_add_out(tensor out, tensor self, int64_t dim, tensor index, tensor source);
tensor atg_index_copy(tensor self, int64_t dim, tensor index, tensor source);
tensor atg_index_copy_(tensor self, int64_t dim, tensor index, tensor source);
tensor atg_index_copy_out(tensor out, tensor self, int64_t dim, tensor index, tensor source);
tensor atg_index_fill(tensor self, int64_t dim, tensor index, scalar value);
tensor atg_index_fill_(tensor self, int64_t dim, tensor index, scalar value);
tensor atg_index_fill_int_scalar_out(tensor out, tensor self, int64_t dim, tensor index, scalar value);
tensor atg_index_fill_int_tensor(tensor self, int64_t dim, tensor index, tensor value);
tensor atg_index_fill_int_tensor_(tensor self, int64_t dim, tensor index, tensor value);
tensor atg_index_fill_int_tensor_out(tensor out, tensor self, int64_t dim, tensor index, tensor value);
tensor atg_index_put(tensor self, tensor *indices_data, int indices_len, tensor values, int accumulate);
tensor atg_index_put_(tensor self, tensor *indices_data, int indices_len, tensor values, int accumulate);
tensor atg_index_put_out(tensor out, tensor self, tensor *indices_data, int indices_len, tensor values, int accumulate);
tensor atg_index_reduce(tensor self, int64_t dim, tensor index, tensor source, char* reduce_ptr, int reduce_len, int include_self);
tensor atg_index_reduce_(tensor self, int64_t dim, tensor index, tensor source, char* reduce_ptr, int reduce_len, int include_self);
tensor atg_index_reduce_out(tensor out, tensor self, int64_t dim, tensor index, tensor source, char* reduce_ptr, int reduce_len, int include_self);
tensor atg_index_select(tensor self, int64_t dim, tensor index);
tensor atg_index_select_backward(tensor grad, int64_t *self_sizes_data, int self_sizes_len, int64_t dim, tensor index);
tensor atg_index_select_out(tensor out, tensor self, int64_t dim, tensor index);
tensor atg_index_tensor_out(tensor out, tensor self, tensor *indices_data, int indices_len);
tensor atg_indices(tensor self);
tensor atg_indices_copy(tensor self);
tensor atg_indices_copy_out(tensor out, tensor self);
tensor atg_infinitely_differentiable_gelu_backward(tensor grad, tensor self);
tensor atg_inner(tensor self, tensor other);
tensor atg_inner_out(tensor out, tensor self, tensor other);
tensor atg_instance_norm(tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int use_input_stats, double momentum, double eps, int cudnn_enabled);
tensor atg_int_repr(tensor self);
tensor atg_int_repr_out(tensor out, tensor self);
tensor atg_inverse(tensor self);
tensor atg_inverse_out(tensor out, tensor self);
int atg_is_coalesced(tensor self);
int atg_is_complex(tensor self);
int atg_is_conj(tensor self);
int atg_is_distributed(tensor self);
int atg_is_floating_point(tensor self);
int atg_is_inference(tensor self);
int atg_is_leaf(tensor self);
int atg_is_neg(tensor self);
int atg_is_nonzero(tensor self);
int atg_is_pinned(tensor self, int device);
int atg_is_same_size(tensor self, tensor other);
int atg_is_set_to(tensor self, tensor tensor);
int atg_is_signed(tensor self);
int atg_is_vulkan_available();
tensor atg_isclose(tensor self, tensor other, double rtol, double atol, int equal_nan);
tensor atg_isfinite(tensor self);
tensor atg_isin(tensor elements, tensor test_elements, int assume_unique, int invert);
tensor atg_isin_scalar_tensor(scalar element, tensor test_elements, int assume_unique, int invert);
tensor atg_isin_scalar_tensor_out(tensor out, scalar element, tensor test_elements, int assume_unique, int invert);
tensor atg_isin_tensor_scalar(tensor elements, scalar test_element, int assume_unique, int invert);
tensor atg_isin_tensor_scalar_out(tensor out, tensor elements, scalar test_element, int assume_unique, int invert);
tensor atg_isin_tensor_tensor_out(tensor out, tensor elements, tensor test_elements, int assume_unique, int invert);
tensor atg_isinf(tensor self);
tensor atg_isinf_out(tensor out, tensor self);
tensor atg_isnan(tensor self);
tensor atg_isnan_out(tensor out, tensor self);
tensor atg_isneginf(tensor self);
tensor atg_isneginf_out(tensor out, tensor self);
tensor atg_isposinf(tensor self);
tensor atg_isposinf_out(tensor out, tensor self);
tensor atg_isreal(tensor self);
tensor atg_istft(tensor self, int64_t n_fft, int64_t hop_length_v, uint8_t hop_length_null, int64_t win_length_v, uint8_t win_length_null, tensor window, int center, int normalized, int onesided, int64_t length_v, uint8_t length_null, int return_complex);
tensor atg_kaiser_window(int64_t window_length, int options_kind, int options_device);
tensor atg_kaiser_window_beta(int64_t window_length, int periodic, double beta, int options_kind, int options_device);
tensor atg_kaiser_window_beta_out(tensor out, int64_t window_length, int periodic, double beta);
tensor atg_kaiser_window_out(tensor out, int64_t window_length);
tensor atg_kaiser_window_periodic(int64_t window_length, int periodic, int options_kind, int options_device);
tensor atg_kaiser_window_periodic_out(tensor out, int64_t window_length, int periodic);
tensor atg_kl_div(tensor self, tensor target, int64_t reduction, int log_target);
tensor atg_kron(tensor self, tensor other);
tensor atg_kron_out(tensor out, tensor self, tensor other);
tensor *atg_kthvalue(tensor self, int64_t k, int64_t dim, int keepdim);
tensor *atg_kthvalue_values(tensor values, tensor indices, tensor self, int64_t k, int64_t dim, int keepdim);
tensor atg_l1_loss(tensor self, tensor target, int64_t reduction);
tensor atg_layer_norm(tensor input, int64_t *normalized_shape_data, int normalized_shape_len, tensor weight, tensor bias, double eps, int cudnn_enable);
tensor atg_lcm(tensor self, tensor other);
tensor atg_lcm_(tensor self, tensor other);
tensor atg_lcm_out(tensor out, tensor self, tensor other);
tensor atg_ldexp(tensor self, tensor other);
tensor atg_ldexp_(tensor self, tensor other);
tensor atg_ldexp_out(tensor out, tensor self, tensor other);
tensor atg_le(tensor self, scalar other);
tensor atg_le_(tensor self, scalar other);
tensor atg_le_scalar_out(tensor out, tensor self, scalar other);
tensor atg_le_tensor(tensor self, tensor other);
tensor atg_le_tensor_(tensor self, tensor other);
tensor atg_le_tensor_out(tensor out, tensor self, tensor other);
tensor atg_leaky_relu(tensor self);
tensor atg_leaky_relu_(tensor self);
tensor atg_leaky_relu_backward(tensor grad_output, tensor self, scalar negative_slope, int self_is_result);
tensor atg_leaky_relu_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, scalar negative_slope, int self_is_result);
tensor atg_leaky_relu_out(tensor out, tensor self);
tensor atg_lerp(tensor self, tensor end, scalar weight);
tensor atg_lerp_(tensor self, tensor end, scalar weight);
tensor atg_lerp_scalar_out(tensor out, tensor self, tensor end, scalar weight);
tensor atg_lerp_tensor(tensor self, tensor end, tensor weight);
tensor atg_lerp_tensor_(tensor self, tensor end, tensor weight);
tensor atg_lerp_tensor_out(tensor out, tensor self, tensor end, tensor weight);
tensor atg_less(tensor self, scalar other);
tensor atg_less_(tensor self, scalar other);
tensor atg_less_equal(tensor self, scalar other);
tensor atg_less_equal_(tensor self, scalar other);
tensor atg_less_equal_scalar_out(tensor out, tensor self, scalar other);
tensor atg_less_equal_tensor(tensor self, tensor other);
tensor atg_less_equal_tensor_(tensor self, tensor other);
tensor atg_less_equal_tensor_out(tensor out, tensor self, tensor other);
tensor atg_less_scalar_out(tensor out, tensor self, scalar other);
tensor atg_less_tensor(tensor self, tensor other);
tensor atg_less_tensor_(tensor self, tensor other);
tensor atg_less_tensor_out(tensor out, tensor self, tensor other);
tensor atg_lgamma(tensor self);
tensor atg_lgamma_(tensor self);
tensor atg_lgamma_out(tensor out, tensor self);
tensor atg_lift(tensor self);
tensor atg_lift_fresh(tensor self);
tensor atg_lift_fresh_copy(tensor self);
tensor atg_lift_fresh_copy_out(tensor out, tensor self);
tensor atg_lift_out(tensor out, tensor self);
tensor atg_linalg_cholesky(tensor self, int upper);
tensor *atg_linalg_cholesky_ex(tensor self, int upper, int check_errors);
tensor *atg_linalg_cholesky_ex_l(tensor L, tensor info, tensor self, int upper, int check_errors);
tensor atg_linalg_cholesky_out(tensor out, tensor self, int upper);
tensor atg_linalg_cond(tensor self, scalar p);
tensor atg_linalg_cond_out(tensor out, tensor self, scalar p);
tensor atg_linalg_cond_p_str(tensor self, char* p_ptr, int p_len);
tensor atg_linalg_cond_p_str_out(tensor out, tensor self, char* p_ptr, int p_len);
tensor atg_linalg_cross(tensor self, tensor other, int64_t dim);
tensor atg_linalg_cross_out(tensor out, tensor self, tensor other, int64_t dim);
tensor atg_linalg_det(tensor A);
tensor atg_linalg_det_out(tensor out, tensor A);
tensor atg_linalg_diagonal(tensor A, int64_t offset, int64_t dim1, int64_t dim2);
tensor *atg_linalg_eig(tensor self);
tensor *atg_linalg_eig_out(tensor eigenvalues, tensor eigenvectors, tensor self);
tensor *atg_linalg_eigh(tensor self, char* UPLO_ptr, int UPLO_len);
tensor *atg_linalg_eigh_eigvals(tensor eigvals, tensor eigvecs, tensor self, char* UPLO_ptr, int UPLO_len);
tensor atg_linalg_eigvals(tensor self);
tensor atg_linalg_eigvals_out(tensor out, tensor self);
tensor atg_linalg_eigvalsh(tensor self, char* UPLO_ptr, int UPLO_len);
tensor atg_linalg_eigvalsh_out(tensor out, tensor self, char* UPLO_ptr, int UPLO_len);
tensor atg_linalg_householder_product(tensor input, tensor tau);
tensor atg_linalg_householder_product_out(tensor out, tensor input, tensor tau);
tensor atg_linalg_inv(tensor A);
tensor *atg_linalg_inv_ex(tensor A, int check_errors);
tensor *atg_linalg_inv_ex_inverse(tensor inverse, tensor info, tensor A, int check_errors);
tensor atg_linalg_inv_out(tensor out, tensor A);
tensor *atg_linalg_ldl_factor(tensor self, int hermitian);
tensor *atg_linalg_ldl_factor_ex(tensor self, int hermitian, int check_errors);
tensor *atg_linalg_ldl_factor_ex_out(tensor LD, tensor pivots, tensor info, tensor self, int hermitian, int check_errors);
tensor *atg_linalg_ldl_factor_out(tensor LD, tensor pivots, tensor self, int hermitian);
tensor atg_linalg_ldl_solve(tensor LD, tensor pivots, tensor B, int hermitian);
tensor atg_linalg_ldl_solve_out(tensor out, tensor LD, tensor pivots, tensor B, int hermitian);
tensor *atg_linalg_lstsq(tensor self, tensor b, double rcond_v, uint8_t rcond_null, char* driver_ptr, int driver_len);
tensor *atg_linalg_lstsq_out(tensor solution, tensor residuals, tensor rank, tensor singular_values, tensor self, tensor b, double rcond_v, uint8_t rcond_null, char* driver_ptr, int driver_len);
tensor *atg_linalg_lu(tensor A, int pivot);
tensor *atg_linalg_lu_factor(tensor A, int pivot);
tensor *atg_linalg_lu_factor_ex(tensor A, int pivot, int check_errors);
tensor *atg_linalg_lu_factor_ex_out(tensor LU, tensor pivots, tensor info, tensor A, int pivot, int check_errors);
tensor *atg_linalg_lu_factor_out(tensor LU, tensor pivots, tensor A, int pivot);
tensor *atg_linalg_lu_out(tensor P, tensor L, tensor U, tensor A, int pivot);
tensor atg_linalg_lu_solve(tensor LU, tensor pivots, tensor B, int left, int adjoint);
tensor atg_linalg_lu_solve_out(tensor out, tensor LU, tensor pivots, tensor B, int left, int adjoint);
tensor atg_linalg_matmul(tensor self, tensor other);
tensor atg_linalg_matmul_out(tensor out, tensor self, tensor other);
tensor atg_linalg_matrix_exp(tensor self);
tensor atg_linalg_matrix_exp_out(tensor out, tensor self);
tensor atg_linalg_matrix_power(tensor self, int64_t n);
tensor atg_linalg_matrix_power_out(tensor out, tensor self, int64_t n);
tensor atg_linalg_matrix_rank(tensor self, double tol, int hermitian);
tensor atg_linalg_matrix_rank_atol_rtol_float(tensor self, double atol_v, uint8_t atol_null, double rtol_v, uint8_t rtol_null, int hermitian);
tensor atg_linalg_matrix_rank_atol_rtol_float_out(tensor out, tensor self, double atol_v, uint8_t atol_null, double rtol_v, uint8_t rtol_null, int hermitian);
tensor atg_linalg_matrix_rank_atol_rtol_tensor(tensor input, tensor atol, tensor rtol, int hermitian);
tensor atg_linalg_matrix_rank_atol_rtol_tensor_out(tensor out, tensor input, tensor atol, tensor rtol, int hermitian);
tensor atg_linalg_matrix_rank_out(tensor out, tensor self, double tol, int hermitian);
tensor atg_linalg_matrix_rank_out_tol_tensor(tensor out, tensor input, tensor tol, int hermitian);
tensor atg_linalg_matrix_rank_tol_tensor(tensor input, tensor tol, int hermitian);
tensor atg_linalg_multi_dot(tensor *tensors_data, int tensors_len);
tensor atg_linalg_multi_dot_out(tensor out, tensor *tensors_data, int tensors_len);
tensor atg_linalg_norm(tensor self, scalar ord, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_linalg_norm_ord_str(tensor self, char* ord_ptr, int ord_len, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_linalg_norm_ord_str_out(tensor out, tensor self, char* ord_ptr, int ord_len, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_linalg_norm_out(tensor out, tensor self, scalar ord, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_linalg_pinv(tensor self, double rcond, int hermitian);
tensor atg_linalg_pinv_atol_rtol_float(tensor self, double atol_v, uint8_t atol_null, double rtol_v, uint8_t rtol_null, int hermitian);
tensor atg_linalg_pinv_atol_rtol_float_out(tensor out, tensor self, double atol_v, uint8_t atol_null, double rtol_v, uint8_t rtol_null, int hermitian);
tensor atg_linalg_pinv_atol_rtol_tensor(tensor self, tensor atol, tensor rtol, int hermitian);
tensor atg_linalg_pinv_atol_rtol_tensor_out(tensor out, tensor self, tensor atol, tensor rtol, int hermitian);
tensor atg_linalg_pinv_out(tensor out, tensor self, double rcond, int hermitian);
tensor atg_linalg_pinv_out_rcond_tensor(tensor out, tensor self, tensor rcond, int hermitian);
tensor atg_linalg_pinv_rcond_tensor(tensor self, tensor rcond, int hermitian);
tensor *atg_linalg_qr(tensor A, char* mode_ptr, int mode_len);
tensor *atg_linalg_qr_out(tensor Q, tensor R, tensor A, char* mode_ptr, int mode_len);
tensor *atg_linalg_slogdet(tensor A);
tensor *atg_linalg_slogdet_out(tensor sign, tensor logabsdet, tensor A);
tensor atg_linalg_solve(tensor A, tensor B, int left);
tensor *atg_linalg_solve_ex(tensor A, tensor B, int left, int check_errors);
tensor *atg_linalg_solve_ex_out(tensor result, tensor info, tensor A, tensor B, int left, int check_errors);
tensor atg_linalg_solve_out(tensor out, tensor A, tensor B, int left);
tensor atg_linalg_solve_triangular(tensor self, tensor B, int upper, int left, int unitriangular);
tensor atg_linalg_solve_triangular_out(tensor out, tensor self, tensor B, int upper, int left, int unitriangular);
tensor *atg_linalg_svd(tensor A, int full_matrices, char* driver_ptr, int driver_len);
tensor *atg_linalg_svd_u(tensor U, tensor S, tensor Vh, tensor A, int full_matrices, char* driver_ptr, int driver_len);
tensor atg_linalg_svdvals(tensor A, char* driver_ptr, int driver_len);
tensor atg_linalg_svdvals_out(tensor out, tensor A, char* driver_ptr, int driver_len);
tensor atg_linalg_tensorinv(tensor self, int64_t ind);
tensor atg_linalg_tensorinv_out(tensor out, tensor self, int64_t ind);
tensor atg_linalg_tensorsolve(tensor self, tensor other, int64_t *dims_data, int dims_len);
tensor atg_linalg_tensorsolve_out(tensor out, tensor self, tensor other, int64_t *dims_data, int dims_len);
tensor atg_linalg_vander(tensor x, int64_t n_v, uint8_t n_null);
tensor atg_linalg_vecdot(tensor x, tensor y, int64_t dim);
tensor atg_linalg_vecdot_out(tensor out, tensor x, tensor y, int64_t dim);
tensor atg_linear(tensor input, tensor weight, tensor bias);
tensor atg_linear_out(tensor out, tensor input, tensor weight, tensor bias);
tensor atg_linspace(scalar start, scalar end, int64_t steps, int options_kind, int options_device);
tensor atg_linspace_out(tensor out, scalar start, scalar end, int64_t steps);
tensor atg_log(tensor self);
tensor atg_log10(tensor self);
tensor atg_log10_(tensor self);
tensor atg_log10_out(tensor out, tensor self);
tensor atg_log1p(tensor self);
tensor atg_log1p_(tensor self);
tensor atg_log1p_out(tensor out, tensor self);
tensor atg_log2(tensor self);
tensor atg_log2_(tensor self);
tensor atg_log2_out(tensor out, tensor self);
tensor atg_log_(tensor self);
tensor atg_log_normal(tensor self, double mean, double std);
tensor atg_log_normal_(tensor self, double mean, double std);
tensor atg_log_normal_out(tensor out, tensor self, double mean, double std);
tensor atg_log_out(tensor out, tensor self);
tensor atg_log_sigmoid(tensor self);
tensor atg_log_sigmoid_backward(tensor grad_output, tensor self, tensor buffer);
tensor atg_log_sigmoid_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor buffer);
tensor atg_log_sigmoid_out(tensor out, tensor self);
tensor atg_log_softmax(tensor self, int64_t dim, int dtype);
tensor atg_log_softmax_int_out(tensor out, tensor self, int64_t dim, int dtype);
tensor atg_logaddexp(tensor self, tensor other);
tensor atg_logaddexp2(tensor self, tensor other);
tensor atg_logaddexp2_out(tensor out, tensor self, tensor other);
tensor atg_logaddexp_out(tensor out, tensor self, tensor other);
tensor atg_logcumsumexp(tensor self, int64_t dim);
tensor atg_logcumsumexp_out(tensor out, tensor self, int64_t dim);
tensor atg_logdet(tensor self);
tensor atg_logical_and(tensor self, tensor other);
tensor atg_logical_and_(tensor self, tensor other);
tensor atg_logical_and_out(tensor out, tensor self, tensor other);
tensor atg_logical_not(tensor self);
tensor atg_logical_not_(tensor self);
tensor atg_logical_not_out(tensor out, tensor self);
tensor atg_logical_or(tensor self, tensor other);
tensor atg_logical_or_(tensor self, tensor other);
tensor atg_logical_or_out(tensor out, tensor self, tensor other);
tensor atg_logical_xor(tensor self, tensor other);
tensor atg_logical_xor_(tensor self, tensor other);
tensor atg_logical_xor_out(tensor out, tensor self, tensor other);
tensor atg_logit(tensor self, double eps_v, uint8_t eps_null);
tensor atg_logit_(tensor self, double eps_v, uint8_t eps_null);
tensor atg_logit_backward(tensor grad_output, tensor self, double eps_v, uint8_t eps_null);
tensor atg_logit_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, double eps_v, uint8_t eps_null);
tensor atg_logit_out(tensor out, tensor self, double eps_v, uint8_t eps_null);
tensor atg_logspace(scalar start, scalar end, int64_t steps, double base, int options_kind, int options_device);
tensor atg_logspace_out(tensor out, scalar start, scalar end, int64_t steps, double base);
tensor atg_logsumexp(tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_logsumexp_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor *atg_lstm(tensor input, tensor *hx_data, int hx_len, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
tensor *atg_lstm_cell(tensor input, tensor *hx_data, int hx_len, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh);
tensor *atg_lstm_data(tensor data, tensor batch_sizes, tensor *hx_data, int hx_len, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional);
tensor atg_lt(tensor self, scalar other);
tensor atg_lt_(tensor self, scalar other);
tensor atg_lt_scalar_out(tensor out, tensor self, scalar other);
tensor atg_lt_tensor(tensor self, tensor other);
tensor atg_lt_tensor_(tensor self, tensor other);
tensor atg_lt_tensor_out(tensor out, tensor self, tensor other);
tensor atg_lu_solve(tensor self, tensor LU_data, tensor LU_pivots);
tensor atg_lu_solve_out(tensor out, tensor self, tensor LU_data, tensor LU_pivots);
tensor *atg_lu_unpack(tensor LU_data, tensor LU_pivots, int unpack_data, int unpack_pivots);
tensor *atg_lu_unpack_out(tensor P, tensor L, tensor U, tensor LU_data, tensor LU_pivots, int unpack_data, int unpack_pivots);
tensor atg_margin_ranking_loss(tensor input1, tensor input2, tensor target, double margin, int64_t reduction);
tensor atg_masked_fill(tensor self, tensor mask, scalar value);
tensor atg_masked_fill_(tensor self, tensor mask, scalar value);
tensor atg_masked_fill_scalar_out(tensor out, tensor self, tensor mask, scalar value);
tensor atg_masked_fill_tensor(tensor self, tensor mask, tensor value);
tensor atg_masked_fill_tensor_(tensor self, tensor mask, tensor value);
tensor atg_masked_fill_tensor_out(tensor out, tensor self, tensor mask, tensor value);
tensor atg_masked_scatter(tensor self, tensor mask, tensor source);
tensor atg_masked_scatter_(tensor self, tensor mask, tensor source);
tensor atg_masked_scatter_out(tensor out, tensor self, tensor mask, tensor source);
tensor atg_masked_select(tensor self, tensor mask);
tensor atg_masked_select_backward(tensor grad, tensor input, tensor mask);
tensor atg_masked_select_out(tensor out, tensor self, tensor mask);
tensor atg_matmul(tensor self, tensor other);
tensor atg_matmul_out(tensor out, tensor self, tensor other);
tensor atg_matrix_exp(tensor self);
tensor atg_matrix_exp_backward(tensor self, tensor grad);
tensor atg_matrix_h(tensor self);
tensor atg_matrix_power(tensor self, int64_t n);
tensor atg_matrix_power_out(tensor out, tensor self, int64_t n);
tensor atg_max(tensor self);
tensor *atg_max_dim(tensor self, int64_t dim, int keepdim);
tensor *atg_max_dim_max(tensor max, tensor max_values, tensor self, int64_t dim, int keepdim);
tensor atg_max_other(tensor self, tensor other);
tensor atg_max_out(tensor out, tensor self, tensor other);
tensor atg_max_pool1d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor *atg_max_pool1d_with_indices(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_max_pool2d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_max_pool2d_backward(tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_max_pool2d_backward_out(tensor out, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor *atg_max_pool2d_with_indices(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_max_pool2d_with_indices_backward(tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode, tensor indices);
tensor atg_max_pool2d_with_indices_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode, tensor indices);
tensor *atg_max_pool2d_with_indices_out(tensor out, tensor indices, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_max_pool3d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor *atg_max_pool3d_with_indices(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_max_pool3d_with_indices_backward(tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode, tensor indices);
tensor atg_max_pool3d_with_indices_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode, tensor indices);
tensor *atg_max_pool3d_with_indices_out(tensor out, tensor indices, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_max_unary_out(tensor out, tensor self);
tensor atg_max_unpool2d(tensor self, tensor indices, int64_t *output_size_data, int output_size_len);
tensor atg_max_unpool2d_out(tensor out, tensor self, tensor indices, int64_t *output_size_data, int output_size_len);
tensor atg_max_unpool3d(tensor self, tensor indices, int64_t *output_size_data, int output_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
tensor atg_max_unpool3d_out(tensor out, tensor self, tensor indices, int64_t *output_size_data, int output_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
tensor atg_maximum(tensor self, tensor other);
tensor atg_maximum_out(tensor out, tensor self, tensor other);
tensor atg_mean(tensor self, int dtype);
tensor atg_mean_dim(tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_mean_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_median(tensor self);
tensor *atg_median_dim(tensor self, int64_t dim, int keepdim);
tensor *atg_median_dim_values(tensor values, tensor indices, tensor self, int64_t dim, int keepdim);
tensor atg_median_out(tensor out, tensor self);
tensor *atg_meshgrid(tensor *tensors_data, int tensors_len);
tensor *atg_meshgrid_indexing(tensor *tensors_data, int tensors_len, char* indexing_ptr, int indexing_len);
tensor atg_mh(tensor self);
tensor atg_min(tensor self);
tensor *atg_min_dim(tensor self, int64_t dim, int keepdim);
tensor *atg_min_dim_min(tensor min, tensor min_indices, tensor self, int64_t dim, int keepdim);
tensor atg_min_other(tensor self, tensor other);
tensor atg_min_out(tensor out, tensor self, tensor other);
tensor atg_min_unary_out(tensor out, tensor self);
tensor atg_minimum(tensor self, tensor other);
tensor atg_minimum_out(tensor out, tensor self, tensor other);
tensor *atg_miopen_batch_norm(tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double exponential_average_factor, double epsilon);
tensor *atg_miopen_batch_norm_backward(tensor input, tensor grad_output, tensor weight, tensor running_mean, tensor running_var, tensor save_mean, tensor save_var, double epsilon);
tensor *atg_miopen_batch_norm_backward_out(tensor out0, tensor out1, tensor out2, tensor input, tensor grad_output, tensor weight, tensor running_mean, tensor running_var, tensor save_mean, tensor save_var, double epsilon);
tensor *atg_miopen_batch_norm_out(tensor out0, tensor out1, tensor out2, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double exponential_average_factor, double epsilon);
tensor atg_miopen_convolution(tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
tensor atg_miopen_convolution_add_relu(tensor self, tensor weight, tensor z, scalar alpha, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_miopen_convolution_out(tensor out, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
tensor atg_miopen_convolution_relu(tensor self, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_miopen_convolution_transpose(tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
tensor atg_miopen_convolution_transpose_out(tensor out, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
tensor atg_miopen_depthwise_convolution(tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
tensor atg_miopen_depthwise_convolution_out(tensor out, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
tensor *atg_miopen_rnn(tensor input, tensor *weight_data, int weight_len, int64_t weight_stride0, tensor hx, tensor cx, int64_t mode, int64_t hidden_size, int64_t num_layers, int batch_first, double dropout, int train, int bidirectional, int64_t *batch_sizes_data, int batch_sizes_len, tensor dropout_state);
tensor *atg_miopen_rnn_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor out4, tensor input, tensor *weight_data, int weight_len, int64_t weight_stride0, tensor hx, tensor cx, int64_t mode, int64_t hidden_size, int64_t num_layers, int batch_first, double dropout, int train, int bidirectional, int64_t *batch_sizes_data, int batch_sizes_len, tensor dropout_state);
tensor atg_mish(tensor self);
tensor atg_mish_(tensor self);
tensor atg_mish_backward(tensor grad_output, tensor self);
tensor atg_mish_out(tensor out, tensor self);
tensor atg_mkldnn_adaptive_avg_pool2d(tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_mkldnn_adaptive_avg_pool2d_backward(tensor grad_output, tensor self);
tensor atg_mkldnn_adaptive_avg_pool2d_backward_out(tensor out, tensor grad_output, tensor self);
tensor atg_mkldnn_adaptive_avg_pool2d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len);
tensor atg_mkldnn_convolution(tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_mkldnn_convolution_out(tensor out, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_mkldnn_linear(tensor self, tensor weight, tensor bias);
tensor atg_mkldnn_linear_backward_input(int64_t *input_size_data, int input_size_len, tensor grad_output, tensor weight);
tensor atg_mkldnn_linear_backward_input_out(tensor out, int64_t *input_size_data, int input_size_len, tensor grad_output, tensor weight);
tensor *atg_mkldnn_linear_backward_weights(tensor grad_output, tensor input, tensor weight, int bias_defined);
tensor *atg_mkldnn_linear_backward_weights_out(tensor out0, tensor out1, tensor grad_output, tensor input, tensor weight, int bias_defined);
tensor atg_mkldnn_linear_out(tensor out, tensor self, tensor weight, tensor bias);
tensor atg_mkldnn_max_pool2d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_mkldnn_max_pool2d_backward(tensor grad_output, tensor output, tensor input, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_mkldnn_max_pool2d_backward_out(tensor out, tensor grad_output, tensor output, tensor input, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_mkldnn_max_pool2d_out(tensor out, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_mkldnn_max_pool3d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_mkldnn_max_pool3d_backward(tensor grad_output, tensor output, tensor input, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_mkldnn_max_pool3d_backward_out(tensor out, tensor grad_output, tensor output, tensor input, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_mkldnn_max_pool3d_out(tensor out, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_mkldnn_reorder_conv2d_weight(tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int64_t *input_size_data, int input_size_len);
tensor atg_mkldnn_reorder_conv2d_weight_out(tensor out, tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int64_t *input_size_data, int input_size_len);
tensor atg_mkldnn_reorder_conv3d_weight(tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor atg_mkldnn_reorder_conv3d_weight_out(tensor out, tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
tensor *atg_mkldnn_rnn_layer(tensor input, tensor weight0, tensor weight1, tensor weight2, tensor weight3, tensor hx_, tensor cx_, int reverse, int64_t *batch_sizes_data, int batch_sizes_len, int64_t mode, int64_t hidden_size, int64_t num_layers, int has_biases, int bidirectional, int batch_first, int train);
tensor *atg_mkldnn_rnn_layer_backward(tensor input, tensor weight1, tensor weight2, tensor weight3, tensor weight4, tensor hx_, tensor cx_tmp, tensor output, tensor hy_, tensor cy_, tensor grad_output, tensor grad_hy, tensor grad_cy, int reverse, int64_t mode, int64_t hidden_size, int64_t num_layers, int has_biases, int train, int bidirectional, int64_t *batch_sizes_data, int batch_sizes_len, int batch_first, tensor workspace);
tensor *atg_mkldnn_rnn_layer_backward_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor out4, tensor out5, tensor out6, tensor input, tensor weight1, tensor weight2, tensor weight3, tensor weight4, tensor hx_, tensor cx_tmp, tensor output, tensor hy_, tensor cy_, tensor grad_output, tensor grad_hy, tensor grad_cy, int reverse, int64_t mode, int64_t hidden_size, int64_t num_layers, int has_biases, int train, int bidirectional, int64_t *batch_sizes_data, int batch_sizes_len, int batch_first, tensor workspace);
tensor *atg_mkldnn_rnn_layer_out(tensor out0, tensor out1, tensor out2, tensor out3, tensor input, tensor weight0, tensor weight1, tensor weight2, tensor weight3, tensor hx_, tensor cx_, int reverse, int64_t *batch_sizes_data, int batch_sizes_len, int64_t mode, int64_t hidden_size, int64_t num_layers, int has_biases, int bidirectional, int batch_first, int train);
tensor atg_mm(tensor self, tensor mat2);
tensor atg_mm_out(tensor out, tensor self, tensor mat2);
tensor *atg_mode(tensor self, int64_t dim, int keepdim);
tensor *atg_mode_values(tensor values, tensor indices, tensor self, int64_t dim, int keepdim);
tensor atg_moveaxis(tensor self, int64_t *source_data, int source_len, int64_t *destination_data, int destination_len);
tensor atg_moveaxis_int(tensor self, int64_t source, int64_t destination);
tensor atg_movedim(tensor self, int64_t *source_data, int source_len, int64_t *destination_data, int destination_len);
tensor atg_movedim_int(tensor self, int64_t source, int64_t destination);
tensor atg_mse_loss(tensor self, tensor target, int64_t reduction);
tensor atg_mse_loss_backward(tensor grad_output, tensor self, tensor target, int64_t reduction);
tensor atg_mse_loss_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction);
tensor atg_mse_loss_out(tensor out, tensor self, tensor target, int64_t reduction);
tensor atg_msort(tensor self);
tensor atg_msort_out(tensor out, tensor self);
tensor atg_mt(tensor self);
tensor atg_mul(tensor self, tensor other);
tensor atg_mul_(tensor self, tensor other);
tensor atg_mul_out(tensor out, tensor self, tensor other);
tensor atg_mul_scalar(tensor self, scalar other);
tensor atg_mul_scalar_(tensor self, scalar other);
tensor atg_mul_scalar_out(tensor out, tensor self, scalar other);
tensor atg_multi_margin_loss_backward(tensor grad_output, tensor self, tensor target, scalar p, scalar margin, tensor weight, int64_t reduction);
tensor atg_multi_margin_loss_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor target, scalar p, scalar margin, tensor weight, int64_t reduction);
tensor atg_multilabel_margin_loss(tensor self, tensor target, int64_t reduction);
tensor atg_multilabel_margin_loss_backward(tensor grad_output, tensor self, tensor target, int64_t reduction, tensor is_target);
tensor atg_multilabel_margin_loss_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction, tensor is_target);
tensor atg_multilabel_margin_loss_out(tensor out, tensor self, tensor target, int64_t reduction);
tensor atg_multinomial(tensor self, int64_t num_samples, int replacement);
tensor atg_multinomial_out(tensor out, tensor self, int64_t num_samples, int replacement);
tensor atg_multiply(tensor self, tensor other);
tensor atg_multiply_(tensor self, tensor other);
tensor atg_multiply_out(tensor out, tensor self, tensor other);
tensor atg_multiply_scalar(tensor self, scalar other);
tensor atg_multiply_scalar_(tensor self, scalar other);
tensor atg_mv(tensor self, tensor vec);
tensor atg_mv_out(tensor out, tensor self, tensor vec);
tensor atg_mvlgamma(tensor self, int64_t p);
tensor atg_mvlgamma_(tensor self, int64_t p);
tensor atg_mvlgamma_out(tensor out, tensor self, int64_t p);
tensor atg_nan_to_num(tensor self, double nan_v, uint8_t nan_null, double posinf_v, uint8_t posinf_null, double neginf_v, uint8_t neginf_null);
tensor atg_nan_to_num_(tensor self, double nan_v, uint8_t nan_null, double posinf_v, uint8_t posinf_null, double neginf_v, uint8_t neginf_null);
tensor atg_nan_to_num_out(tensor out, tensor self, double nan_v, uint8_t nan_null, double posinf_v, uint8_t posinf_null, double neginf_v, uint8_t neginf_null);
tensor atg_nanmean(tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_nanmean_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_nanmedian(tensor self);
tensor *atg_nanmedian_dim(tensor self, int64_t dim, int keepdim);
tensor *atg_nanmedian_dim_values(tensor values, tensor indices, tensor self, int64_t dim, int keepdim);
tensor atg_nanmedian_out(tensor out, tensor self);
tensor atg_nanquantile(tensor self, tensor q, int64_t dim_v, uint8_t dim_null, int keepdim, char* interpolation_ptr, int interpolation_len);
tensor atg_nanquantile_out(tensor out, tensor self, tensor q, int64_t dim_v, uint8_t dim_null, int keepdim, char* interpolation_ptr, int interpolation_len);
tensor atg_nanquantile_scalar(tensor self, double q, int64_t dim_v, uint8_t dim_null, int keepdim, char* interpolation_ptr, int interpolation_len);
tensor atg_nanquantile_scalar_out(tensor out, tensor self, double q, int64_t dim_v, uint8_t dim_null, int keepdim, char* interpolation_ptr, int interpolation_len);
tensor atg_nansum(tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_nansum_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_narrow(tensor self, int64_t dim, int64_t start, int64_t length);
tensor atg_narrow_copy(tensor self, int64_t dim, int64_t start, int64_t length);
tensor atg_narrow_copy_out(tensor out, tensor self, int64_t dim, int64_t start, int64_t length);
tensor atg_narrow_tensor(tensor self, int64_t dim, tensor start, int64_t length);
tensor *atg_native_batch_norm(tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double momentum, double eps);
tensor *atg_native_batch_norm_out(tensor out, tensor save_mean, tensor save_invstd, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double momentum, double eps);
tensor atg_native_channel_shuffle(tensor self, int64_t groups);
tensor *atg_native_dropout(tensor input, double p, int train);
tensor atg_native_dropout_backward(tensor grad_output, tensor mask, double scale);
tensor atg_native_dropout_backward_out(tensor out, tensor grad_output, tensor mask, double scale);
tensor *atg_native_dropout_out(tensor out0, tensor out1, tensor input, double p, int train);
tensor *atg_native_group_norm(tensor input, tensor weight, tensor bias, int64_t n, int64_t C, int64_t HxW, int64_t group, double eps);
tensor *atg_native_group_norm_out(tensor out0, tensor out1, tensor out2, tensor input, tensor weight, tensor bias, int64_t n, int64_t C, int64_t HxW, int64_t group, double eps);
tensor *atg_native_layer_norm(tensor input, int64_t *normalized_shape_data, int normalized_shape_len, tensor weight, tensor bias, double eps);
tensor *atg_native_layer_norm_out(tensor out0, tensor out1, tensor out2, tensor input, int64_t *normalized_shape_data, int normalized_shape_len, tensor weight, tensor bias, double eps);
tensor atg_native_norm(tensor self);
tensor atg_native_norm_out(tensor out, tensor self);
tensor atg_native_norm_scalaropt_dim_dtype(tensor self, scalar p, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_native_norm_scalaropt_dim_dtype_out(tensor out, tensor self, scalar p, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_ne(tensor self, scalar other);
tensor atg_ne_(tensor self, scalar other);
tensor atg_ne_scalar_out(tensor out, tensor self, scalar other);
tensor atg_ne_tensor(tensor self, tensor other);
tensor atg_ne_tensor_(tensor self, tensor other);
tensor atg_ne_tensor_out(tensor out, tensor self, tensor other);
tensor atg_neg(tensor self);
tensor atg_neg_(tensor self);
tensor atg_neg_out(tensor out, tensor self);
tensor atg_negative(tensor self);
tensor atg_negative_(tensor self);
tensor atg_negative_out(tensor out, tensor self);
tensor atg_nested_to_padded_tensor(tensor self, double padding, int64_t *output_size_data, int output_size_len);
tensor atg_new_empty(tensor self, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_new_empty_out(tensor out, tensor self, int64_t *size_data, int size_len);
tensor atg_new_empty_strided(tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int options_kind, int options_device);
tensor atg_new_empty_strided_out(tensor out, tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len);
tensor atg_new_full(tensor self, int64_t *size_data, int size_len, scalar fill_value, int options_kind, int options_device);
tensor atg_new_full_out(tensor out, tensor self, int64_t *size_data, int size_len, scalar fill_value);
tensor atg_new_ones(tensor self, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_new_ones_out(tensor out, tensor self, int64_t *size_data, int size_len);
tensor atg_new_zeros(tensor self, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_new_zeros_out(tensor out, tensor self, int64_t *size_data, int size_len);
tensor atg_nextafter(tensor self, tensor other);
tensor atg_nextafter_(tensor self, tensor other);
tensor atg_nextafter_out(tensor out, tensor self, tensor other);
tensor atg_nll_loss(tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
tensor atg_nll_loss2d(tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
tensor atg_nll_loss2d_backward(tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, tensor total_weight);
tensor atg_nll_loss2d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, tensor total_weight);
tensor atg_nll_loss2d_out(tensor out, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
tensor atg_nll_loss_backward(tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, tensor total_weight);
tensor atg_nll_loss_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, tensor total_weight);
tensor atg_nll_loss_nd(tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
tensor atg_nll_loss_out(tensor out, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
tensor atg_nonzero(tensor self);
tensor *atg_nonzero_numpy(tensor self);
tensor atg_nonzero_out(tensor out, tensor self);
tensor atg_nonzero_static(tensor self, int64_t size, int64_t fill_value);
tensor atg_nonzero_static_out(tensor out, tensor self, int64_t size, int64_t fill_value);
tensor atg_norm(tensor self);
tensor atg_norm_dtype_out(tensor out, tensor self, scalar p, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_norm_except_dim(tensor v, int64_t pow, int64_t dim);
tensor atg_norm_out(tensor out, tensor self, scalar p, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_norm_scalar_out(tensor out, tensor self);
tensor atg_norm_scalaropt_dim(tensor self, scalar p, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_norm_scalaropt_dim_dtype(tensor self, scalar p, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_norm_scalaropt_dtype(tensor self, scalar p, int dtype);
tensor atg_norm_scalaropt_dtype_out(tensor out, tensor self, scalar p, int dtype);
tensor atg_normal_(tensor self, double mean, double std);
tensor atg_normal_functional(tensor self, double mean, double std);
tensor atg_not_equal(tensor self, scalar other);
tensor atg_not_equal_(tensor self, scalar other);
tensor atg_not_equal_scalar_out(tensor out, tensor self, scalar other);
tensor atg_not_equal_tensor(tensor self, tensor other);
tensor atg_not_equal_tensor_(tensor self, tensor other);
tensor atg_not_equal_tensor_out(tensor out, tensor self, tensor other);
tensor atg_nuclear_norm(tensor self, int keepdim);
tensor atg_nuclear_norm_dim(tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_nuclear_norm_dim_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_nuclear_norm_out(tensor out, tensor self, int keepdim);
tensor atg_numpy_t(tensor self);
tensor atg_one_hot(tensor self, int64_t num_classes);
tensor atg_ones(int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_ones_like(tensor self);
tensor atg_ones_like_out(tensor out, tensor self);
tensor atg_ones_out(tensor out, int64_t *size_data, int size_len);
tensor atg_orgqr(tensor self, tensor input2);
tensor atg_orgqr_out(tensor out, tensor self, tensor input2);
tensor atg_ormqr(tensor self, tensor input2, tensor input3, int left, int transpose);
tensor atg_ormqr_out(tensor out, tensor self, tensor input2, tensor input3, int left, int transpose);
tensor atg_outer(tensor self, tensor vec2);
tensor atg_outer_out(tensor out, tensor self, tensor vec2);
int64_t atg_output_nr(tensor self);
tensor atg_pad(tensor self, int64_t *pad_data, int pad_len, char* mode_ptr, int mode_len, double value_v, uint8_t value_null);
tensor atg_pad_sequence(tensor *sequences_data, int sequences_len, int batch_first, double padding_value);
tensor atg_pairwise_distance(tensor x1, tensor x2, double p, double eps, int keepdim);
tensor atg_pdist(tensor self, double p);
tensor atg_permute(tensor self, int64_t *dims_data, int dims_len);
tensor atg_permute_copy(tensor self, int64_t *dims_data, int dims_len);
tensor atg_permute_copy_out(tensor out, tensor self, int64_t *dims_data, int dims_len);
tensor atg_pin_memory(tensor self, int device);
tensor atg_pinverse(tensor self, double rcond);
tensor atg_pixel_shuffle(tensor self, int64_t upscale_factor);
tensor atg_pixel_shuffle_out(tensor out, tensor self, int64_t upscale_factor);
tensor atg_pixel_unshuffle(tensor self, int64_t downscale_factor);
tensor atg_pixel_unshuffle_out(tensor out, tensor self, int64_t downscale_factor);
tensor atg_poisson(tensor self);
tensor atg_poisson_nll_loss(tensor input, tensor target, int log_input, int full, double eps, int64_t reduction);
tensor atg_poisson_out(tensor out, tensor self);
tensor atg_polar(tensor abs, tensor angle);
tensor atg_polar_out(tensor out, tensor abs, tensor angle);
tensor atg_polygamma(int64_t n, tensor self);
tensor atg_polygamma_(tensor self, int64_t n);
tensor atg_polygamma_out(tensor out, int64_t n, tensor self);
tensor atg_positive(tensor self);
tensor atg_pow(tensor self, tensor exponent);
tensor atg_pow_(tensor self, scalar exponent);
tensor atg_pow_scalar(scalar self_scalar, tensor exponent);
tensor atg_pow_scalar_out(tensor out, scalar self_scalar, tensor exponent);
tensor atg_pow_tensor_(tensor self, tensor exponent);
tensor atg_pow_tensor_scalar(tensor self, scalar exponent);
tensor atg_pow_tensor_scalar_out(tensor out, tensor self, scalar exponent);
tensor atg_pow_tensor_tensor_out(tensor out, tensor self, tensor exponent);
tensor atg_prelu(tensor self, tensor weight);
tensor atg_prod(tensor self, int dtype);
tensor atg_prod_dim_int(tensor self, int64_t dim, int keepdim, int dtype);
tensor atg_prod_int_out(tensor out, tensor self, int64_t dim, int keepdim, int dtype);
tensor atg_prod_out(tensor out, tensor self, int dtype);
tensor atg_put(tensor self, tensor index, tensor source, int accumulate);
tensor atg_put_(tensor self, tensor index, tensor source, int accumulate);
tensor atg_put_out(tensor out, tensor self, tensor index, tensor source, int accumulate);
int64_t atg_q_per_channel_axis(tensor self);
tensor atg_q_per_channel_scales(tensor self);
tensor atg_q_per_channel_scales_out(tensor out, tensor self);
tensor atg_q_per_channel_zero_points(tensor self);
tensor atg_q_per_channel_zero_points_out(tensor out, tensor self);
double atg_q_scale(tensor self);
int64_t atg_q_zero_point(tensor self);
tensor *atg_qr(tensor self, int some);
tensor *atg_qr_q(tensor Q, tensor R, tensor self, int some);
tensor atg_quantile(tensor self, tensor q, int64_t dim_v, uint8_t dim_null, int keepdim, char* interpolation_ptr, int interpolation_len);
tensor atg_quantile_out(tensor out, tensor self, tensor q, int64_t dim_v, uint8_t dim_null, int keepdim, char* interpolation_ptr, int interpolation_len);
tensor atg_quantile_scalar(tensor self, double q, int64_t dim_v, uint8_t dim_null, int keepdim, char* interpolation_ptr, int interpolation_len);
tensor atg_quantile_scalar_out(tensor out, tensor self, double q, int64_t dim_v, uint8_t dim_null, int keepdim, char* interpolation_ptr, int interpolation_len);
tensor atg_quantize_per_channel(tensor self, tensor scales, tensor zero_points, int64_t axis, int dtype);
tensor atg_quantize_per_channel_out(tensor out, tensor self, tensor scales, tensor zero_points, int64_t axis, int dtype);
tensor atg_quantize_per_tensor(tensor self, double scale, int64_t zero_point, int dtype);
tensor atg_quantize_per_tensor_dynamic(tensor self, int dtype, int reduce_range);
tensor atg_quantize_per_tensor_dynamic_out(tensor out, tensor self, int dtype, int reduce_range);
tensor atg_quantize_per_tensor_tensor_qparams(tensor self, tensor scale, tensor zero_point, int dtype);
tensor *atg_quantize_per_tensor_tensors(tensor *tensors_data, int tensors_len, tensor scales, tensor zero_points, int dtype);
tensor atg_quantized_batch_norm(tensor input, tensor weight, tensor bias, tensor mean, tensor var, double eps, double output_scale, int64_t output_zero_point);
tensor atg_quantized_batch_norm_out(tensor out, tensor input, tensor weight, tensor bias, tensor mean, tensor var, double eps, double output_scale, int64_t output_zero_point);
tensor atg_quantized_gru_cell(tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh, tensor packed_ih, tensor packed_hh, tensor col_offsets_ih, tensor col_offsets_hh, scalar scale_ih, scalar scale_hh, scalar zero_point_ih, scalar zero_point_hh);
tensor *atg_quantized_lstm_cell(tensor input, tensor *hx_data, int hx_len, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh, tensor packed_ih, tensor packed_hh, tensor col_offsets_ih, tensor col_offsets_hh, scalar scale_ih, scalar scale_hh, scalar zero_point_ih, scalar zero_point_hh);
tensor atg_quantized_max_pool1d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_quantized_max_pool1d_out(tensor out, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_quantized_max_pool2d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_quantized_max_pool2d_out(tensor out, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_quantized_max_pool3d(tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_quantized_max_pool3d_out(tensor out, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
tensor atg_quantized_rnn_relu_cell(tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh, tensor packed_ih, tensor packed_hh, tensor col_offsets_ih, tensor col_offsets_hh, scalar scale_ih, scalar scale_hh, scalar zero_point_ih, scalar zero_point_hh);
tensor atg_quantized_rnn_tanh_cell(tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh, tensor packed_ih, tensor packed_hh, tensor col_offsets_ih, tensor col_offsets_hh, scalar scale_ih, scalar scale_hh, scalar zero_point_ih, scalar zero_point_hh);
tensor atg_rad2deg(tensor self);
tensor atg_rad2deg_(tensor self);
tensor atg_rad2deg_out(tensor out, tensor self);
tensor atg_rand(int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_rand_like(tensor self);
tensor atg_rand_like_out(tensor out, tensor self);
tensor atg_rand_out(tensor out, int64_t *size_data, int size_len);
tensor atg_randint(int64_t high, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_randint_like(tensor self, int64_t high);
tensor atg_randint_like_low_dtype(tensor self, int64_t low, int64_t high);
tensor atg_randint_like_low_dtype_out(tensor out, tensor self, int64_t low, int64_t high);
tensor atg_randint_like_out(tensor out, tensor self, int64_t high);
tensor atg_randint_low(int64_t low, int64_t high, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_randint_low_out(tensor out, int64_t low, int64_t high, int64_t *size_data, int size_len);
tensor atg_randint_out(tensor out, int64_t high, int64_t *size_data, int size_len);
tensor atg_randn(int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_randn_like(tensor self);
tensor atg_randn_like_out(tensor out, tensor self);
tensor atg_randn_out(tensor out, int64_t *size_data, int size_len);
tensor atg_random(tensor self);
tensor atg_random_(tensor self);
tensor atg_random_from(tensor self, int64_t from, int64_t to_v, uint8_t to_null);
tensor atg_random_from_(tensor self, int64_t from, int64_t to_v, uint8_t to_null);
tensor atg_random_from_out(tensor out, tensor self, int64_t from, int64_t to_v, uint8_t to_null);
tensor atg_random_out(tensor out, tensor self);
tensor atg_random_to(tensor self, int64_t to);
tensor atg_random_to_(tensor self, int64_t to);
tensor atg_random_to_out(tensor out, tensor self, int64_t to);
tensor atg_randperm(int64_t n, int options_kind, int options_device);
tensor atg_randperm_out(tensor out, int64_t n);
tensor atg_range(scalar start, scalar end, int options_kind, int options_device);
tensor atg_range_out(tensor out, scalar start, scalar end);
tensor atg_range_out_(tensor out, scalar start, scalar end);
tensor atg_range_step(scalar start, scalar end, int options_kind, int options_device);
tensor atg_ravel(tensor self);
tensor atg_real(tensor self);
tensor atg_reciprocal(tensor self);
tensor atg_reciprocal_(tensor self);
tensor atg_reciprocal_out(tensor out, tensor self);
tensor atg_reflection_pad1d(tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad1d_backward(tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad1d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad1d_out(tensor out, tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad2d(tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad2d_backward(tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad2d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad2d_out(tensor out, tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad3d(tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad3d_backward(tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad3d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_reflection_pad3d_out(tensor out, tensor self, int64_t *padding_data, int padding_len);
tensor atg_relu(tensor self);
tensor atg_relu6(tensor self);
tensor atg_relu6_(tensor self);
tensor atg_relu_(tensor self);
tensor atg_relu_out(tensor out, tensor self);
tensor atg_remainder(tensor self, scalar other);
tensor atg_remainder_(tensor self, scalar other);
tensor atg_remainder_scalar_out(tensor out, tensor self, scalar other);
tensor atg_remainder_scalar_tensor(scalar self_scalar, tensor other);
tensor atg_remainder_scalar_tensor_out(tensor out, scalar self_scalar, tensor other);
tensor atg_remainder_tensor(tensor self, tensor other);
tensor atg_remainder_tensor_(tensor self, tensor other);
tensor atg_remainder_tensor_out(tensor out, tensor self, tensor other);
tensor atg_renorm(tensor self, scalar p, int64_t dim, scalar maxnorm);
tensor atg_renorm_(tensor self, scalar p, int64_t dim, scalar maxnorm);
tensor atg_renorm_out(tensor out, tensor self, scalar p, int64_t dim, scalar maxnorm);
tensor atg_repeat(tensor self, int64_t *repeats_data, int repeats_len);
tensor atg_repeat_interleave(tensor repeats, int64_t output_size_v, uint8_t output_size_null);
tensor atg_repeat_interleave_self_int(tensor self, int64_t repeats, int64_t dim_v, uint8_t dim_null, int64_t output_size_v, uint8_t output_size_null);
tensor atg_repeat_interleave_self_tensor(tensor self, tensor repeats, int64_t dim_v, uint8_t dim_null, int64_t output_size_v, uint8_t output_size_null);
tensor atg_repeat_interleave_tensor_out(tensor out, tensor repeats, int64_t output_size_v, uint8_t output_size_null);
tensor atg_repeat_out(tensor out, tensor self, int64_t *repeats_data, int repeats_len);
tensor atg_replication_pad1d(tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad1d_backward(tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad1d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad1d_out(tensor out, tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad2d(tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad2d_backward(tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad2d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad2d_out(tensor out, tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad3d(tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad3d_backward(tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad3d_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
tensor atg_replication_pad3d_out(tensor out, tensor self, int64_t *padding_data, int padding_len);
tensor atg_requires_grad_(tensor self, int requires_grad);
tensor atg_reshape(tensor self, int64_t *shape_data, int shape_len);
tensor atg_reshape_as(tensor self, tensor other);
tensor atg_resize(tensor self, int64_t *size_data, int size_len);
tensor atg_resize_(tensor self, int64_t *size_data, int size_len);
tensor atg_resize_as(tensor self, tensor the_template);
tensor atg_resize_as_(tensor self, tensor the_template);
tensor atg_resize_as_out(tensor out, tensor self, tensor the_template);
tensor atg_resize_as_sparse(tensor self, tensor the_template);
tensor atg_resize_as_sparse_(tensor self, tensor the_template);
tensor atg_resize_as_sparse_out(tensor out, tensor self, tensor the_template);
tensor atg_resize_out(tensor out, tensor self, int64_t *size_data, int size_len);
tensor atg_resolve_conj(tensor self);
tensor atg_resolve_neg(tensor self);
int atg_retains_grad(tensor self);
tensor *atg_rnn_relu(tensor input, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
tensor atg_rnn_relu_cell(tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh);
tensor *atg_rnn_relu_data(tensor data, tensor batch_sizes, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional);
tensor *atg_rnn_tanh(tensor input, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
tensor atg_rnn_tanh_cell(tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh);
tensor *atg_rnn_tanh_data(tensor data, tensor batch_sizes, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional);
tensor atg_roll(tensor self, int64_t *shifts_data, int shifts_len, int64_t *dims_data, int dims_len);
tensor atg_roll_out(tensor out, tensor self, int64_t *shifts_data, int shifts_len, int64_t *dims_data, int dims_len);
tensor atg_rot90(tensor self, int64_t k, int64_t *dims_data, int dims_len);
tensor atg_rot90_out(tensor out, tensor self, int64_t k, int64_t *dims_data, int dims_len);
tensor atg_round(tensor self);
tensor atg_round_(tensor self);
tensor atg_round_decimals(tensor self, int64_t decimals);
tensor atg_round_decimals_(tensor self, int64_t decimals);
tensor atg_round_decimals_out(tensor out, tensor self, int64_t decimals);
tensor atg_round_out(tensor out, tensor self);
tensor atg_row_indices(tensor self);
tensor atg_row_indices_copy(tensor self);
tensor atg_row_indices_copy_out(tensor out, tensor self);
tensor atg_row_stack(tensor *tensors_data, int tensors_len);
tensor atg_row_stack_out(tensor out, tensor *tensors_data, int tensors_len);
tensor atg_rrelu(tensor self, int training);
tensor atg_rrelu_(tensor self, int training);
tensor atg_rrelu_with_noise(tensor self, tensor noise, int training);
tensor atg_rrelu_with_noise_(tensor self, tensor noise, int training);
tensor atg_rrelu_with_noise_backward(tensor grad_output, tensor self, tensor noise, scalar lower, scalar upper, int training, int self_is_result);
tensor atg_rrelu_with_noise_backward_out(tensor out, tensor grad_output, tensor self, tensor noise, scalar lower, scalar upper, int training, int self_is_result);
tensor atg_rrelu_with_noise_out(tensor out, tensor self, tensor noise, int training);
tensor atg_rsqrt(tensor self);
tensor atg_rsqrt_(tensor self);
tensor atg_rsqrt_out(tensor out, tensor self);
tensor atg_rsub(tensor self, tensor other);
tensor atg_rsub_scalar(tensor self, scalar other);
tensor atg_rsub_scalar_out(tensor out, tensor self, scalar other);
tensor atg_rsub_tensor_out(tensor out, tensor self, tensor other);
tensor atg_scalar_tensor(scalar s, int options_kind, int options_device);
tensor atg_scalar_tensor_out(tensor out, scalar s);
tensor atg_scaled_dot_product_attention(tensor query, tensor key, tensor value, tensor attn_mask, double dropout_p, int is_causal, double scale_v, uint8_t scale_null);
tensor atg_scatter(tensor self, int64_t dim, tensor index, tensor src);
tensor atg_scatter_(tensor self, int64_t dim, tensor index, tensor src);
tensor atg_scatter_add(tensor self, int64_t dim, tensor index, tensor src);
tensor atg_scatter_add_(tensor self, int64_t dim, tensor index, tensor src);
tensor atg_scatter_add_out(tensor out, tensor self, int64_t dim, tensor index, tensor src);
tensor atg_scatter_reduce(tensor self, int64_t dim, tensor index, tensor src, char* reduce_ptr, int reduce_len);
tensor atg_scatter_reduce_(tensor self, int64_t dim, tensor index, tensor src, char* reduce_ptr, int reduce_len);
tensor atg_scatter_reduce_out(tensor out, tensor self, int64_t dim, tensor index, tensor src, char* reduce_ptr, int reduce_len);
tensor atg_scatter_src_out(tensor out, tensor self, int64_t dim, tensor index, tensor src);
tensor atg_scatter_value(tensor self, int64_t dim, tensor index, scalar value);
tensor atg_scatter_value_(tensor self, int64_t dim, tensor index, scalar value);
tensor atg_scatter_value_out(tensor out, tensor self, int64_t dim, tensor index, scalar value);
tensor atg_scatter_value_reduce(tensor self, int64_t dim, tensor index, scalar value, char* reduce_ptr, int reduce_len);
tensor atg_scatter_value_reduce_(tensor self, int64_t dim, tensor index, scalar value, char* reduce_ptr, int reduce_len);
tensor atg_scatter_value_reduce_out(tensor out, tensor self, int64_t dim, tensor index, scalar value, char* reduce_ptr, int reduce_len);
tensor atg_searchsorted(tensor sorted_sequence, tensor self, int out_int32, int right, char* side_ptr, int side_len, tensor sorter);
tensor atg_searchsorted_scalar(tensor sorted_sequence, scalar self_scalar, int out_int32, int right, char* side_ptr, int side_len, tensor sorter);
tensor atg_searchsorted_scalar_out(tensor out, tensor sorted_sequence, scalar self_scalar, int out_int32, int right, char* side_ptr, int side_len, tensor sorter);
tensor atg_searchsorted_tensor_out(tensor out, tensor sorted_sequence, tensor self, int out_int32, int right, char* side_ptr, int side_len, tensor sorter);
tensor atg_segment_reduce(tensor data, char* reduce_ptr, int reduce_len, tensor lengths, tensor indices, tensor offsets, int64_t axis, int unsafe, scalar initial);
tensor atg_segment_reduce_out(tensor out, tensor data, char* reduce_ptr, int reduce_len, tensor lengths, tensor indices, tensor offsets, int64_t axis, int unsafe, scalar initial);
tensor atg_select(tensor self, int64_t dim, int64_t index);
tensor atg_select_backward(tensor grad_output, int64_t *input_sizes_data, int input_sizes_len, int64_t dim, int64_t index);
tensor atg_select_backward_out(tensor out, tensor grad_output, int64_t *input_sizes_data, int input_sizes_len, int64_t dim, int64_t index);
tensor atg_select_copy(tensor self, int64_t dim, int64_t index);
tensor atg_select_copy_int_out(tensor out, tensor self, int64_t dim, int64_t index);
tensor atg_select_scatter(tensor self, tensor src, int64_t dim, int64_t index);
tensor atg_select_scatter_out(tensor out, tensor self, tensor src, int64_t dim, int64_t index);
tensor atg_selu(tensor self);
tensor atg_selu_(tensor self);
tensor atg_set(tensor self);
tensor atg_set_(tensor self);
tensor atg_set_out(tensor out, tensor self);
tensor atg_set_requires_grad(tensor self, int r);
tensor atg_set_source_tensor(tensor self, tensor source);
tensor atg_set_source_tensor_(tensor self, tensor source);
tensor atg_set_source_tensor_out(tensor out, tensor self, tensor source);
tensor atg_set_source_tensor_storage_offset_(tensor self, tensor source, int64_t storage_offset, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len);
tensor atg_sgn(tensor self);
tensor atg_sgn_(tensor self);
tensor atg_sgn_out(tensor out, tensor self);
tensor atg_sigmoid(tensor self);
tensor atg_sigmoid_(tensor self);
tensor atg_sigmoid_backward(tensor grad_output, tensor output);
tensor atg_sigmoid_backward_grad_input(tensor grad_input, tensor grad_output, tensor output);
tensor atg_sigmoid_out(tensor out, tensor self);
tensor atg_sign(tensor self);
tensor atg_sign_(tensor self);
tensor atg_sign_out(tensor out, tensor self);
tensor atg_signbit(tensor self);
tensor atg_signbit_out(tensor out, tensor self);
tensor atg_silu(tensor self);
tensor atg_silu_(tensor self);
tensor atg_silu_backward(tensor grad_output, tensor self);
tensor atg_silu_backward_grad_input(tensor grad_input, tensor grad_output, tensor self);
tensor atg_silu_out(tensor out, tensor self);
tensor atg_sin(tensor self);
tensor atg_sin_(tensor self);
tensor atg_sin_out(tensor out, tensor self);
tensor atg_sinc(tensor self);
tensor atg_sinc_(tensor self);
tensor atg_sinc_out(tensor out, tensor self);
tensor atg_sinh(tensor self);
tensor atg_sinh_(tensor self);
tensor atg_sinh_out(tensor out, tensor self);
tensor atg_slice(tensor self, int64_t dim, int64_t start_v, uint8_t start_null, int64_t end_v, uint8_t end_null, int64_t step);
tensor atg_slice_backward(tensor grad_output, int64_t *input_sizes_data, int input_sizes_len, int64_t dim, int64_t start, int64_t end, int64_t step);
tensor atg_slice_backward_out(tensor out, tensor grad_output, int64_t *input_sizes_data, int input_sizes_len, int64_t dim, int64_t start, int64_t end, int64_t step);
tensor atg_slice_copy(tensor self, int64_t dim, int64_t start_v, uint8_t start_null, int64_t end_v, uint8_t end_null, int64_t step);
tensor atg_slice_copy_tensor_out(tensor out, tensor self, int64_t dim, int64_t start_v, uint8_t start_null, int64_t end_v, uint8_t end_null, int64_t step);
tensor atg_slice_scatter(tensor self, tensor src, int64_t dim, int64_t start_v, uint8_t start_null, int64_t end_v, uint8_t end_null, int64_t step);
tensor atg_slice_scatter_out(tensor out, tensor self, tensor src, int64_t dim, int64_t start_v, uint8_t start_null, int64_t end_v, uint8_t end_null, int64_t step);
tensor *atg_slogdet(tensor self);
tensor *atg_slogdet_out(tensor sign, tensor logabsdet, tensor self);
tensor atg_slow_conv3d(tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
tensor atg_slow_conv3d_out(tensor out, tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
tensor atg_slow_conv_dilated2d(tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_slow_conv_dilated2d_out(tensor out, tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_slow_conv_dilated3d(tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_slow_conv_dilated3d_out(tensor out, tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_slow_conv_transpose2d(tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_slow_conv_transpose2d_out(tensor out, tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_slow_conv_transpose3d(tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_slow_conv_transpose3d_out(tensor out, tensor self, tensor weight, int64_t *kernel_size_data, int kernel_size_len, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *dilation_data, int dilation_len);
tensor atg_smm(tensor self, tensor mat2);
tensor atg_smooth_l1_loss(tensor self, tensor target, int64_t reduction, double beta);
tensor atg_smooth_l1_loss_backward(tensor grad_output, tensor self, tensor target, int64_t reduction, double beta);
tensor atg_smooth_l1_loss_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction, double beta);
tensor atg_smooth_l1_loss_out(tensor out, tensor self, tensor target, int64_t reduction, double beta);
tensor atg_soft_margin_loss(tensor self, tensor target, int64_t reduction);
tensor atg_soft_margin_loss_backward(tensor grad_output, tensor self, tensor target, int64_t reduction);
tensor atg_soft_margin_loss_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction);
tensor atg_soft_margin_loss_out(tensor out, tensor self, tensor target, int64_t reduction);
tensor atg_softmax(tensor self, int64_t dim, int dtype);
tensor atg_softmax_int_out(tensor out, tensor self, int64_t dim, int dtype);
tensor atg_softplus(tensor self);
tensor atg_softplus_backward(tensor grad_output, tensor self, scalar beta, scalar threshold);
tensor atg_softplus_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, scalar beta, scalar threshold);
tensor atg_softplus_out(tensor out, tensor self);
tensor atg_softshrink(tensor self);
tensor atg_softshrink_backward(tensor grad_output, tensor self, scalar lambd);
tensor atg_softshrink_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, scalar lambd);
tensor atg_softshrink_out(tensor out, tensor self);
tensor *atg_sort(tensor self, int64_t dim, int descending);
tensor *atg_sort_stable(tensor self, int stable, int64_t dim, int descending);
tensor *atg_sort_values(tensor values, tensor indices, tensor self, int64_t dim, int descending);
tensor *atg_sort_values_stable(tensor values, tensor indices, tensor self, int stable, int64_t dim, int descending);
tensor atg_sparse_bsc_tensor(tensor ccol_indices, tensor row_indices, tensor values, int options_kind, int options_device);
tensor atg_sparse_bsc_tensor_ccol_row_value_size(tensor ccol_indices, tensor row_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_sparse_bsr_tensor(tensor crow_indices, tensor col_indices, tensor values, int options_kind, int options_device);
tensor atg_sparse_bsr_tensor_crow_col_value_size(tensor crow_indices, tensor col_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_sparse_compressed_tensor(tensor compressed_indices, tensor plain_indices, tensor values, int options_kind, int options_device);
tensor atg_sparse_compressed_tensor_comp_plain_value_size(tensor compressed_indices, tensor plain_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_sparse_coo_tensor(int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_sparse_coo_tensor_indices(tensor indices, tensor values, int options_kind, int options_device, int is_coalesced);
tensor atg_sparse_coo_tensor_indices_size(tensor indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device, int is_coalesced);
tensor atg_sparse_coo_tensor_size_out(tensor out, int64_t *size_data, int size_len);
tensor atg_sparse_csc_tensor(tensor ccol_indices, tensor row_indices, tensor values, int options_kind, int options_device);
tensor atg_sparse_csc_tensor_ccol_row_value_size(tensor ccol_indices, tensor row_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_sparse_csr_tensor(tensor crow_indices, tensor col_indices, tensor values, int options_kind, int options_device);
tensor atg_sparse_csr_tensor_crow_col_value_size(tensor crow_indices, tensor col_indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
int64_t atg_sparse_dim(tensor self);
tensor atg_sparse_mask(tensor self, tensor mask);
tensor atg_sparse_mask_out(tensor out, tensor self, tensor mask);
tensor atg_sparse_resize(tensor self, int64_t *size_data, int size_len, int64_t sparse_dim, int64_t dense_dim);
tensor atg_sparse_resize_(tensor self, int64_t *size_data, int size_len, int64_t sparse_dim, int64_t dense_dim);
tensor atg_sparse_resize_and_clear(tensor self, int64_t *size_data, int size_len, int64_t sparse_dim, int64_t dense_dim);
tensor atg_sparse_resize_and_clear_(tensor self, int64_t *size_data, int size_len, int64_t sparse_dim, int64_t dense_dim);
tensor atg_sparse_resize_and_clear_out(tensor out, tensor self, int64_t *size_data, int size_len, int64_t sparse_dim, int64_t dense_dim);
tensor atg_sparse_resize_out(tensor out, tensor self, int64_t *size_data, int size_len, int64_t sparse_dim, int64_t dense_dim);
tensor atg_sparse_sampled_addmm(tensor self, tensor mat1, tensor mat2);
tensor atg_sparse_sampled_addmm_out(tensor out, tensor self, tensor mat1, tensor mat2);
tensor atg_special_airy_ai(tensor x);
tensor atg_special_airy_ai_out(tensor out, tensor x);
tensor atg_special_bessel_j0(tensor self);
tensor atg_special_bessel_j0_out(tensor out, tensor self);
tensor atg_special_bessel_j1(tensor self);
tensor atg_special_bessel_j1_out(tensor out, tensor self);
tensor atg_special_bessel_y0(tensor self);
tensor atg_special_bessel_y0_out(tensor out, tensor self);
tensor atg_special_bessel_y1(tensor self);
tensor atg_special_bessel_y1_out(tensor out, tensor self);
tensor atg_special_chebyshev_polynomial_t(tensor x, tensor n);
tensor atg_special_chebyshev_polynomial_t_n_scalar(tensor x, scalar n);
tensor atg_special_chebyshev_polynomial_t_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_chebyshev_polynomial_t_out(tensor out, tensor x, tensor n);
tensor atg_special_chebyshev_polynomial_t_x_scalar(scalar x, tensor n);
tensor atg_special_chebyshev_polynomial_t_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_chebyshev_polynomial_u(tensor x, tensor n);
tensor atg_special_chebyshev_polynomial_u_n_scalar(tensor x, scalar n);
tensor atg_special_chebyshev_polynomial_u_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_chebyshev_polynomial_u_out(tensor out, tensor x, tensor n);
tensor atg_special_chebyshev_polynomial_u_x_scalar(scalar x, tensor n);
tensor atg_special_chebyshev_polynomial_u_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_chebyshev_polynomial_v(tensor x, tensor n);
tensor atg_special_chebyshev_polynomial_v_n_scalar(tensor x, scalar n);
tensor atg_special_chebyshev_polynomial_v_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_chebyshev_polynomial_v_out(tensor out, tensor x, tensor n);
tensor atg_special_chebyshev_polynomial_v_x_scalar(scalar x, tensor n);
tensor atg_special_chebyshev_polynomial_v_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_chebyshev_polynomial_w(tensor x, tensor n);
tensor atg_special_chebyshev_polynomial_w_n_scalar(tensor x, scalar n);
tensor atg_special_chebyshev_polynomial_w_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_chebyshev_polynomial_w_out(tensor out, tensor x, tensor n);
tensor atg_special_chebyshev_polynomial_w_x_scalar(scalar x, tensor n);
tensor atg_special_chebyshev_polynomial_w_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_digamma(tensor self);
tensor atg_special_digamma_out(tensor out, tensor self);
tensor atg_special_entr(tensor self);
tensor atg_special_entr_out(tensor out, tensor self);
tensor atg_special_erf(tensor self);
tensor atg_special_erf_out(tensor out, tensor self);
tensor atg_special_erfc(tensor self);
tensor atg_special_erfc_out(tensor out, tensor self);
tensor atg_special_erfcx(tensor self);
tensor atg_special_erfcx_out(tensor out, tensor self);
tensor atg_special_erfinv(tensor self);
tensor atg_special_erfinv_out(tensor out, tensor self);
tensor atg_special_exp2(tensor self);
tensor atg_special_exp2_out(tensor out, tensor self);
tensor atg_special_expit(tensor self);
tensor atg_special_expit_out(tensor out, tensor self);
tensor atg_special_expm1(tensor self);
tensor atg_special_expm1_out(tensor out, tensor self);
tensor atg_special_gammainc(tensor self, tensor other);
tensor atg_special_gammainc_out(tensor out, tensor self, tensor other);
tensor atg_special_gammaincc(tensor self, tensor other);
tensor atg_special_gammaincc_out(tensor out, tensor self, tensor other);
tensor atg_special_gammaln(tensor self);
tensor atg_special_gammaln_out(tensor out, tensor self);
tensor atg_special_hermite_polynomial_h(tensor x, tensor n);
tensor atg_special_hermite_polynomial_h_n_scalar(tensor x, scalar n);
tensor atg_special_hermite_polynomial_h_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_hermite_polynomial_h_out(tensor out, tensor x, tensor n);
tensor atg_special_hermite_polynomial_h_x_scalar(scalar x, tensor n);
tensor atg_special_hermite_polynomial_h_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_hermite_polynomial_he(tensor x, tensor n);
tensor atg_special_hermite_polynomial_he_n_scalar(tensor x, scalar n);
tensor atg_special_hermite_polynomial_he_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_hermite_polynomial_he_out(tensor out, tensor x, tensor n);
tensor atg_special_hermite_polynomial_he_x_scalar(scalar x, tensor n);
tensor atg_special_hermite_polynomial_he_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_i0(tensor self);
tensor atg_special_i0_out(tensor out, tensor self);
tensor atg_special_i0e(tensor self);
tensor atg_special_i0e_out(tensor out, tensor self);
tensor atg_special_i1(tensor self);
tensor atg_special_i1_out(tensor out, tensor self);
tensor atg_special_i1e(tensor self);
tensor atg_special_i1e_out(tensor out, tensor self);
tensor atg_special_laguerre_polynomial_l(tensor x, tensor n);
tensor atg_special_laguerre_polynomial_l_n_scalar(tensor x, scalar n);
tensor atg_special_laguerre_polynomial_l_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_laguerre_polynomial_l_out(tensor out, tensor x, tensor n);
tensor atg_special_laguerre_polynomial_l_x_scalar(scalar x, tensor n);
tensor atg_special_laguerre_polynomial_l_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_legendre_polynomial_p(tensor x, tensor n);
tensor atg_special_legendre_polynomial_p_n_scalar(tensor x, scalar n);
tensor atg_special_legendre_polynomial_p_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_legendre_polynomial_p_out(tensor out, tensor x, tensor n);
tensor atg_special_legendre_polynomial_p_x_scalar(scalar x, tensor n);
tensor atg_special_legendre_polynomial_p_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_log1p(tensor self);
tensor atg_special_log1p_out(tensor out, tensor self);
tensor atg_special_log_ndtr(tensor self);
tensor atg_special_log_ndtr_out(tensor out, tensor self);
tensor atg_special_log_softmax(tensor self, int64_t dim, int dtype);
tensor atg_special_logit(tensor self, double eps_v, uint8_t eps_null);
tensor atg_special_logit_out(tensor out, tensor self, double eps_v, uint8_t eps_null);
tensor atg_special_logsumexp(tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_special_logsumexp_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim);
tensor atg_special_modified_bessel_i0(tensor self);
tensor atg_special_modified_bessel_i0_out(tensor out, tensor self);
tensor atg_special_modified_bessel_i1(tensor self);
tensor atg_special_modified_bessel_i1_out(tensor out, tensor self);
tensor atg_special_modified_bessel_k0(tensor self);
tensor atg_special_modified_bessel_k0_out(tensor out, tensor self);
tensor atg_special_modified_bessel_k1(tensor self);
tensor atg_special_modified_bessel_k1_out(tensor out, tensor self);
tensor atg_special_multigammaln(tensor self, int64_t p);
tensor atg_special_multigammaln_out(tensor out, tensor self, int64_t p);
tensor atg_special_ndtr(tensor self);
tensor atg_special_ndtr_out(tensor out, tensor self);
tensor atg_special_ndtri(tensor self);
tensor atg_special_ndtri_out(tensor out, tensor self);
tensor atg_special_polygamma(int64_t n, tensor self);
tensor atg_special_polygamma_out(tensor out, int64_t n, tensor self);
tensor atg_special_psi(tensor self);
tensor atg_special_psi_out(tensor out, tensor self);
tensor atg_special_round(tensor self, int64_t decimals);
tensor atg_special_round_out(tensor out, tensor self, int64_t decimals);
tensor atg_special_scaled_modified_bessel_k0(tensor x);
tensor atg_special_scaled_modified_bessel_k0_out(tensor out, tensor x);
tensor atg_special_scaled_modified_bessel_k1(tensor x);
tensor atg_special_scaled_modified_bessel_k1_out(tensor out, tensor x);
tensor atg_special_shifted_chebyshev_polynomial_t(tensor x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_t_n_scalar(tensor x, scalar n);
tensor atg_special_shifted_chebyshev_polynomial_t_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_shifted_chebyshev_polynomial_t_out(tensor out, tensor x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_t_x_scalar(scalar x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_t_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_u(tensor x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_u_n_scalar(tensor x, scalar n);
tensor atg_special_shifted_chebyshev_polynomial_u_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_shifted_chebyshev_polynomial_u_out(tensor out, tensor x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_u_x_scalar(scalar x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_u_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_v(tensor x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_v_n_scalar(tensor x, scalar n);
tensor atg_special_shifted_chebyshev_polynomial_v_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_shifted_chebyshev_polynomial_v_out(tensor out, tensor x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_v_x_scalar(scalar x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_v_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_w(tensor x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_w_n_scalar(tensor x, scalar n);
tensor atg_special_shifted_chebyshev_polynomial_w_n_scalar_out(tensor out, tensor x, scalar n);
tensor atg_special_shifted_chebyshev_polynomial_w_out(tensor out, tensor x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_w_x_scalar(scalar x, tensor n);
tensor atg_special_shifted_chebyshev_polynomial_w_x_scalar_out(tensor out, scalar x, tensor n);
tensor atg_special_sinc(tensor self);
tensor atg_special_sinc_out(tensor out, tensor self);
tensor atg_special_softmax(tensor self, int64_t dim, int dtype);
tensor atg_special_spherical_bessel_j0(tensor x);
tensor atg_special_spherical_bessel_j0_out(tensor out, tensor x);
tensor atg_special_xlog1py(tensor self, tensor other);
tensor atg_special_xlog1py_other_scalar(tensor self, scalar other);
tensor atg_special_xlog1py_other_scalar_out(tensor out, tensor self, scalar other);
tensor atg_special_xlog1py_out(tensor out, tensor self, tensor other);
tensor atg_special_xlog1py_self_scalar(scalar self_scalar, tensor other);
tensor atg_special_xlog1py_self_scalar_out(tensor out, scalar self_scalar, tensor other);
tensor atg_special_xlogy(tensor self, tensor other);
tensor atg_special_xlogy_other_scalar(tensor self, scalar other);
tensor atg_special_xlogy_other_scalar_out(tensor out, tensor self, scalar other);
tensor atg_special_xlogy_out(tensor out, tensor self, tensor other);
tensor atg_special_xlogy_self_scalar(scalar self_scalar, tensor other);
tensor atg_special_xlogy_self_scalar_out(tensor out, scalar self_scalar, tensor other);
tensor atg_special_zeta(tensor self, tensor other);
tensor atg_special_zeta_other_scalar(tensor self, scalar other);
tensor atg_special_zeta_other_scalar_out(tensor out, tensor self, scalar other);
tensor atg_special_zeta_out(tensor out, tensor self, tensor other);
tensor atg_special_zeta_self_scalar(scalar self_scalar, tensor other);
tensor atg_special_zeta_self_scalar_out(tensor out, scalar self_scalar, tensor other);
tensor *atg_split(tensor self, int64_t split_size, int64_t dim);
tensor *atg_split_copy(tensor self, int64_t split_size, int64_t dim);
tensor *atg_split_sizes(tensor self, int64_t *split_size_data, int split_size_len, int64_t dim);
tensor *atg_split_with_sizes(tensor self, int64_t *split_sizes_data, int split_sizes_len, int64_t dim);
tensor *atg_split_with_sizes_copy(tensor self, int64_t *split_sizes_data, int split_sizes_len, int64_t dim);
tensor atg_sqrt(tensor self);
tensor atg_sqrt_(tensor self);
tensor atg_sqrt_out(tensor out, tensor self);
tensor atg_square(tensor self);
tensor atg_square_(tensor self);
tensor atg_square_out(tensor out, tensor self);
tensor atg_squeeze(tensor self);
tensor atg_squeeze_(tensor self);
tensor atg_squeeze_copy(tensor self);
tensor atg_squeeze_copy_dim(tensor self, int64_t dim);
tensor atg_squeeze_copy_dim_out(tensor out, tensor self, int64_t dim);
tensor atg_squeeze_copy_dims(tensor self, int64_t *dim_data, int dim_len);
tensor atg_squeeze_copy_dims_out(tensor out, tensor self, int64_t *dim_data, int dim_len);
tensor atg_squeeze_copy_out(tensor out, tensor self);
tensor atg_squeeze_dim(tensor self, int64_t dim);
tensor atg_squeeze_dim_(tensor self, int64_t dim);
tensor atg_squeeze_dims(tensor self, int64_t *dim_data, int dim_len);
tensor atg_squeeze_dims_(tensor self, int64_t *dim_data, int dim_len);
tensor atg_sspaddmm(tensor self, tensor mat1, tensor mat2);
tensor atg_sspaddmm_out(tensor out, tensor self, tensor mat1, tensor mat2);
tensor atg_stack(tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg_stack_out(tensor out, tensor *tensors_data, int tensors_len, int64_t dim);
tensor atg_std(tensor self, int unbiased);
tensor atg_std_correction(tensor self, int64_t *dim_data, int dim_len, scalar correction, int keepdim);
tensor atg_std_correction_out(tensor out, tensor self, int64_t *dim_data, int dim_len, scalar correction, int keepdim);
tensor atg_std_dim(tensor self, int64_t *dim_data, int dim_len, int unbiased, int keepdim);
tensor *atg_std_mean(tensor self, int unbiased);
tensor *atg_std_mean_correction(tensor self, int64_t *dim_data, int dim_len, scalar correction, int keepdim);
tensor *atg_std_mean_correction_out(tensor out0, tensor out1, tensor self, int64_t *dim_data, int dim_len, scalar correction, int keepdim);
tensor *atg_std_mean_dim(tensor self, int64_t *dim_data, int dim_len, int unbiased, int keepdim);
tensor atg_std_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int unbiased, int keepdim);
tensor atg_stft(tensor self, int64_t n_fft, int64_t hop_length_v, uint8_t hop_length_null, int64_t win_length_v, uint8_t win_length_null, tensor window, int normalized, int onesided, int return_complex);
tensor atg_stft_center(tensor self, int64_t n_fft, int64_t hop_length_v, uint8_t hop_length_null, int64_t win_length_v, uint8_t win_length_null, tensor window, int center, char* pad_mode_ptr, int pad_mode_len, int normalized, int onesided, int return_complex);
tensor atg_sub(tensor self, tensor other);
tensor atg_sub_(tensor self, tensor other);
tensor atg_sub_out(tensor out, tensor self, tensor other);
tensor atg_sub_scalar(tensor self, scalar other);
tensor atg_sub_scalar_(tensor self, scalar other);
tensor atg_sub_scalar_out(tensor out, tensor self, scalar other);
tensor atg_subtract(tensor self, tensor other);
tensor atg_subtract_(tensor self, tensor other);
tensor atg_subtract_out(tensor out, tensor self, tensor other);
tensor atg_subtract_scalar(tensor self, scalar other);
tensor atg_subtract_scalar_(tensor self, scalar other);
tensor atg_sum(tensor self, int dtype);
tensor atg_sum_dim_intlist(tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_sum_intlist_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
tensor atg_sum_out(tensor out, tensor self, int dtype);
tensor atg_sum_to_size(tensor self, int64_t *size_data, int size_len);
tensor *atg_svd(tensor self, int some, int compute_uv);
tensor *atg_svd_u(tensor U, tensor S, tensor V, tensor self, int some, int compute_uv);
tensor atg_swapaxes(tensor self, int64_t axis0, int64_t axis1);
tensor atg_swapaxes_(tensor self, int64_t axis0, int64_t axis1);
tensor atg_swapdims(tensor self, int64_t dim0, int64_t dim1);
tensor atg_swapdims_(tensor self, int64_t dim0, int64_t dim1);
void atg_sym_constrain_range(scalar size, int64_t min_v, uint8_t min_null, int64_t max_v, uint8_t max_null);
void atg_sym_constrain_range_for_size(scalar size, int64_t min_v, uint8_t min_null, int64_t max_v, uint8_t max_null);
tensor atg_t(tensor self);
tensor atg_t_(tensor self);
tensor atg_t_copy(tensor self);
tensor atg_t_copy_out(tensor out, tensor self);
tensor atg_take(tensor self, tensor index);
tensor atg_take_along_dim(tensor self, tensor indices, int64_t dim_v, uint8_t dim_null);
tensor atg_take_along_dim_out(tensor out, tensor self, tensor indices, int64_t dim_v, uint8_t dim_null);
tensor atg_take_out(tensor out, tensor self, tensor index);
tensor atg_tan(tensor self);
tensor atg_tan_(tensor self);
tensor atg_tan_out(tensor out, tensor self);
tensor atg_tanh(tensor self);
tensor atg_tanh_(tensor self);
tensor atg_tanh_backward(tensor grad_output, tensor output);
tensor atg_tanh_backward_grad_input(tensor grad_input, tensor grad_output, tensor output);
tensor atg_tanh_out(tensor out, tensor self);
tensor *atg_tensor_split(tensor self, int64_t sections, int64_t dim);
tensor *atg_tensor_split_indices(tensor self, int64_t *indices_data, int indices_len, int64_t dim);
tensor *atg_tensor_split_tensor_indices_or_sections(tensor self, tensor tensor_indices_or_sections, int64_t dim);
tensor atg_tensordot(tensor self, tensor other, int64_t *dims_self_data, int dims_self_len, int64_t *dims_other_data, int dims_other_len);
tensor atg_tensordot_out(tensor out, tensor self, tensor other, int64_t *dims_self_data, int dims_self_len, int64_t *dims_other_data, int dims_other_len);
tensor atg_threshold(tensor self, scalar threshold, scalar value);
tensor atg_threshold_(tensor self, scalar threshold, scalar value);
tensor atg_threshold_backward(tensor grad_output, tensor self, scalar threshold);
tensor atg_threshold_backward_grad_input(tensor grad_input, tensor grad_output, tensor self, scalar threshold);
tensor atg_threshold_out(tensor out, tensor self, scalar threshold, scalar value);
tensor atg_tile(tensor self, int64_t *dims_data, int dims_len);
tensor atg_to(tensor self, int device);
tensor atg_to_dense(tensor self, int dtype, int masked_grad);
tensor atg_to_dense_backward(tensor grad, tensor input, int masked_grad);
tensor atg_to_device(tensor self, int device, int dtype, int non_blocking, int copy);
tensor atg_to_dtype(tensor self, int dtype, int non_blocking, int copy);
tensor atg_to_dtype_layout(tensor self, int options_kind, int options_device, int non_blocking, int copy);
tensor atg_to_mkldnn(tensor self, int dtype);
tensor atg_to_mkldnn_backward(tensor grad, tensor input);
tensor atg_to_mkldnn_out(tensor out, tensor self, int dtype);
tensor atg_to_other(tensor self, tensor other, int non_blocking, int copy);
tensor atg_to_padded_tensor(tensor self, double padding, int64_t *output_size_data, int output_size_len);
tensor atg_to_padded_tensor_out(tensor out, tensor self, double padding, int64_t *output_size_data, int output_size_len);
tensor atg_to_sparse(tensor self, int8_t layout, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg_to_sparse_bsc(tensor self, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg_to_sparse_bsr(tensor self, int64_t *blocksize_data, int blocksize_len, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg_to_sparse_csc(tensor self, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg_to_sparse_csr(tensor self, int64_t dense_dim_v, uint8_t dense_dim_null);
tensor atg_to_sparse_sparse_dim(tensor self, int64_t sparse_dim);
tensor *atg_topk(tensor self, int64_t k, int64_t dim, int largest, int sorted);
tensor *atg_topk_values(tensor values, tensor indices, tensor self, int64_t k, int64_t dim, int largest, int sorted);
tensor atg_totype(tensor self, int scalar_type);
tensor atg_trace(tensor self);
tensor atg_trace_backward(tensor grad, int64_t *sizes_data, int sizes_len);
tensor atg_trace_out(tensor out, tensor self);
tensor atg_transpose(tensor self, int64_t dim0, int64_t dim1);
tensor atg_transpose_(tensor self, int64_t dim0, int64_t dim1);
tensor atg_transpose_copy(tensor self, int64_t dim0, int64_t dim1);
tensor atg_transpose_copy_int_out(tensor out, tensor self, int64_t dim0, int64_t dim1);
tensor atg_trapezoid(tensor y, int64_t dim);
tensor atg_trapezoid_x(tensor y, tensor x, int64_t dim);
tensor atg_trapz(tensor y, tensor x, int64_t dim);
tensor atg_trapz_dx(tensor y, double dx, int64_t dim);
tensor *atg_triangular_solve(tensor self, tensor A, int upper, int transpose, int unitriangular);
tensor *atg_triangular_solve_x(tensor X, tensor M, tensor self, tensor A, int upper, int transpose, int unitriangular);
tensor atg_tril(tensor self, int64_t diagonal);
tensor atg_tril_(tensor self, int64_t diagonal);
tensor atg_tril_indices(int64_t row, int64_t col, int64_t offset, int options_kind, int options_device);
tensor atg_tril_indices_out(tensor out, int64_t row, int64_t col, int64_t offset);
tensor atg_tril_out(tensor out, tensor self, int64_t diagonal);
tensor atg_triplet_margin_loss(tensor anchor, tensor positive, tensor negative, double margin, double p, double eps, int swap, int64_t reduction);
tensor atg_triu(tensor self, int64_t diagonal);
tensor atg_triu_(tensor self, int64_t diagonal);
tensor atg_triu_indices(int64_t row, int64_t col, int64_t offset, int options_kind, int options_device);
tensor atg_triu_indices_out(tensor out, int64_t row, int64_t col, int64_t offset);
tensor atg_triu_out(tensor out, tensor self, int64_t diagonal);
tensor atg_true_divide(tensor self, tensor other);
tensor atg_true_divide_(tensor self, tensor other);
tensor atg_true_divide_out(tensor out, tensor self, tensor other);
tensor atg_true_divide_scalar(tensor self, scalar other);
tensor atg_true_divide_scalar_(tensor self, scalar other);
tensor atg_trunc(tensor self);
tensor atg_trunc_(tensor self);
tensor atg_trunc_out(tensor out, tensor self);
tensor atg_type_as(tensor self, tensor other);
tensor *atg_unbind(tensor self, int64_t dim);
tensor *atg_unbind_copy(tensor self, int64_t dim);
tensor atg_unflatten(tensor self, int64_t dim, int64_t *sizes_data, int sizes_len);
tensor *atg_unflatten_dense_tensors(tensor flat, tensor *tensors_data, int tensors_len);
tensor atg_unfold(tensor self, int64_t dimension, int64_t size, int64_t step);
tensor atg_unfold_backward(tensor grad_in, int64_t *input_sizes_data, int input_sizes_len, int64_t dim, int64_t size, int64_t step);
tensor atg_unfold_backward_out(tensor out, tensor grad_in, int64_t *input_sizes_data, int input_sizes_len, int64_t dim, int64_t size, int64_t step);
tensor atg_unfold_copy(tensor self, int64_t dimension, int64_t size, int64_t step);
tensor atg_unfold_copy_out(tensor out, tensor self, int64_t dimension, int64_t size, int64_t step);
tensor atg_uniform(tensor self, double from, double to);
tensor atg_uniform_(tensor self, double from, double to);
tensor atg_uniform_out(tensor out, tensor self, double from, double to);
tensor *atg_unique_consecutive(tensor self, int return_inverse, int return_counts, int64_t dim_v, uint8_t dim_null);
tensor *atg_unique_consecutive_out(tensor out0, tensor out1, tensor out2, tensor self, int return_inverse, int return_counts, int64_t dim_v, uint8_t dim_null);
tensor *atg_unique_dim(tensor self, int64_t dim, int sorted, int return_inverse, int return_counts);
tensor *atg_unique_dim_consecutive(tensor self, int64_t dim, int return_inverse, int return_counts);
tensor *atg_unique_dim_consecutive_out(tensor out0, tensor out1, tensor out2, tensor self, int64_t dim, int return_inverse, int return_counts);
tensor *atg_unique_dim_out(tensor out0, tensor out1, tensor out2, tensor self, int64_t dim, int sorted, int return_inverse, int return_counts);
tensor *atg_unsafe_chunk(tensor self, int64_t chunks, int64_t dim);
tensor *atg_unsafe_split(tensor self, int64_t split_size, int64_t dim);
tensor *atg_unsafe_split_with_sizes(tensor self, int64_t *split_sizes_data, int split_sizes_len, int64_t dim);
tensor atg_unsqueeze(tensor self, int64_t dim);
tensor atg_unsqueeze_(tensor self, int64_t dim);
tensor atg_unsqueeze_copy(tensor self, int64_t dim);
tensor atg_unsqueeze_copy_out(tensor out, tensor self, int64_t dim);
tensor atg_upsample_bicubic2d(tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_bicubic2d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_bicubic2d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_bicubic2d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_bicubic2d_vec(tensor input, int64_t *output_size_data, int output_size_len, int align_corners, double *scale_factors_data, int scale_factors_len);
tensor atg_upsample_bilinear2d(tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_bilinear2d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_bilinear2d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_bilinear2d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_bilinear2d_vec(tensor input, int64_t *output_size_data, int output_size_len, int align_corners, double *scale_factors_data, int scale_factors_len);
tensor atg_upsample_linear1d(tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_v, uint8_t scales_null);
tensor atg_upsample_linear1d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_v, uint8_t scales_null);
tensor atg_upsample_linear1d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_v, uint8_t scales_null);
tensor atg_upsample_linear1d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_v, uint8_t scales_null);
tensor atg_upsample_linear1d_vec(tensor input, int64_t *output_size_data, int output_size_len, int align_corners, double *scale_factors_data, int scale_factors_len);
tensor atg_upsample_nearest1d(tensor self, int64_t *output_size_data, int output_size_len, double scales_v, uint8_t scales_null);
tensor atg_upsample_nearest1d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_v, uint8_t scales_null);
tensor atg_upsample_nearest1d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_v, uint8_t scales_null);
tensor atg_upsample_nearest1d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, double scales_v, uint8_t scales_null);
tensor atg_upsample_nearest1d_vec(tensor input, int64_t *output_size_data, int output_size_len, double *scale_factors_data, int scale_factors_len);
tensor atg_upsample_nearest2d(tensor self, int64_t *output_size_data, int output_size_len, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_nearest2d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_nearest2d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_nearest2d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_nearest2d_vec(tensor input, int64_t *output_size_data, int output_size_len, double *scale_factors_data, int scale_factors_len);
tensor atg_upsample_nearest3d(tensor self, int64_t *output_size_data, int output_size_len, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_nearest3d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_nearest3d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_nearest3d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_nearest3d_vec(tensor input, int64_t *output_size_data, int output_size_len, double *scale_factors_data, int scale_factors_len);
tensor atg_upsample_trilinear3d(tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_trilinear3d_backward(tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_trilinear3d_backward_grad_input(tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_trilinear3d_out(tensor out, tensor self, int64_t *output_size_data, int output_size_len, int align_corners, double scales_d_v, uint8_t scales_d_null, double scales_h_v, uint8_t scales_h_null, double scales_w_v, uint8_t scales_w_null);
tensor atg_upsample_trilinear3d_vec(tensor input, int64_t *output_size_data, int output_size_len, int align_corners, double *scale_factors_data, int scale_factors_len);
tensor atg_value_selecting_reduction_backward(tensor grad, int64_t dim, tensor indices, int64_t *sizes_data, int sizes_len, int keepdim);
tensor atg_values(tensor self);
tensor atg_values_copy(tensor self);
tensor atg_values_copy_out(tensor out, tensor self);
tensor atg_vander(tensor x, int64_t n_v, uint8_t n_null, int increasing);
tensor atg_var(tensor self, int unbiased);
tensor atg_var_correction(tensor self, int64_t *dim_data, int dim_len, scalar correction, int keepdim);
tensor atg_var_correction_out(tensor out, tensor self, int64_t *dim_data, int dim_len, scalar correction, int keepdim);
tensor atg_var_dim(tensor self, int64_t *dim_data, int dim_len, int unbiased, int keepdim);
tensor *atg_var_mean(tensor self, int unbiased);
tensor *atg_var_mean_correction(tensor self, int64_t *dim_data, int dim_len, scalar correction, int keepdim);
tensor *atg_var_mean_correction_out(tensor out0, tensor out1, tensor self, int64_t *dim_data, int dim_len, scalar correction, int keepdim);
tensor *atg_var_mean_dim(tensor self, int64_t *dim_data, int dim_len, int unbiased, int keepdim);
tensor atg_var_out(tensor out, tensor self, int64_t *dim_data, int dim_len, int unbiased, int keepdim);
tensor atg_vdot(tensor self, tensor other);
tensor atg_vdot_out(tensor out, tensor self, tensor other);
tensor atg_view(tensor self, int64_t *size_data, int size_len);
tensor atg_view_as(tensor self, tensor other);
tensor atg_view_as_complex(tensor self);
tensor atg_view_as_complex_copy(tensor self);
tensor atg_view_as_complex_copy_out(tensor out, tensor self);
tensor atg_view_as_real(tensor self);
tensor atg_view_as_real_copy(tensor self);
tensor atg_view_as_real_copy_out(tensor out, tensor self);
tensor atg_view_copy(tensor self, int64_t *size_data, int size_len);
tensor atg_view_copy_dtype(tensor self, int dtype);
tensor atg_view_copy_dtype_out(tensor out, tensor self, int dtype);
tensor atg_view_copy_out(tensor out, tensor self, int64_t *size_data, int size_len);
tensor atg_view_dtype(tensor self, int dtype);
tensor *atg_vsplit(tensor self, int64_t sections);
tensor *atg_vsplit_array(tensor self, int64_t *indices_data, int indices_len);
tensor atg_vstack(tensor *tensors_data, int tensors_len);
tensor atg_vstack_out(tensor out, tensor *tensors_data, int tensors_len);
tensor *atg_where(tensor condition);
tensor atg_where_scalar(tensor condition, scalar self_scalar, scalar other);
tensor atg_where_scalarother(tensor condition, tensor self, scalar other);
tensor atg_where_scalarself(tensor condition, scalar self_scalar, tensor other);
tensor atg_where_self(tensor condition, tensor self, tensor other);
tensor atg_where_self_out(tensor out, tensor condition, tensor self, tensor other);
tensor atg_xlogy(tensor self, tensor other);
tensor atg_xlogy_(tensor self, tensor other);
tensor atg_xlogy_outscalar_other(tensor out, tensor self, scalar other);
tensor atg_xlogy_outscalar_self(tensor out, scalar self_scalar, tensor other);
tensor atg_xlogy_outtensor(tensor out, tensor self, tensor other);
tensor atg_xlogy_scalar_other(tensor self, scalar other);
tensor atg_xlogy_scalar_other_(tensor self, scalar other);
tensor atg_xlogy_scalar_self(scalar self_scalar, tensor other);
tensor atg_zero(tensor self);
tensor atg_zero_(tensor self);
tensor atg_zero_out(tensor out, tensor self);
tensor atg_zeros(int64_t *size_data, int size_len, int options_kind, int options_device);
tensor atg_zeros_like(tensor self);
tensor atg_zeros_like_out(tensor out, tensor self);
tensor atg_zeros_out(tensor out, int64_t *size_data, int size_len);
